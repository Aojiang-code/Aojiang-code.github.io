太好，这条路线的野心我喜欢：**把 AKI 从“跑通”做到“做到极致”**。
下面这份就是你要的——**路线 A 的详细实施方案**，以后我们就按这个清单一个节点一个节点啃。

我分成 7 个阶段，每个阶段都写：**目标 / 先决条件 / 主要任务 / 产出物 / 验证方式**。

> 说明：所有名字、目录只是建议，可以微调，但尽量保持一致，方便后面自动化和扩展到别的疾病。

---

## A0 准备与文档搭建

### 🎯 目标

* 把“AKI 深化路线”的总体目标、定义和约定写清楚。
* 在代码结构和文档结构上预留好位置，后面都往里面填。

### ✅ 先决条件

* 目前的 AKI v0.1 完整可跑（你已经完成）。
* 仓库结构大致为：

  * `backend/aki/`
  * `backend/sql/aki/`
  * `frontend/`
  * `docs/aki/`

### 📌 主要任务

1. **补文档骨架**

   * 在 `docs/aki/` 新建：

     * `03_kdigo_definition.md`

       * 章节建议：

         * KDIGO 定义回顾（Scr + UO 阈值 & 时间窗）
         * 本项目中的实现方案（基线 Scr 算法、时间粒度等）
         * 限制与假设
     * `04_modeling_plan.md`

       * 章节建议：

         * 预测任务（Task 1, Task 2, …）
         * 特征大类（人口学 / 既往病史 / 实验室 / 生命体征 / KDIGO 表型）
         * 模型层级（回归 → ML → 轨迹）
         * 评估指标 & 交叉验证策略

2. **规划目录结构**

   * `backend/sql/aki/`

     * `aki_scr_timeseries.sql`
     * `aki_uo_timeseries.sql`
     * `aki_kdigo_labels.sql`
     * `aki_feature_views.sql`（后面建建模视图用）
   * `backend/aki/`

     * `kdigo_timeseries.py`
     * `kdigo_labels.py`
     * `features.py`
     * `models_logistic.py`
     * `models_ml.py`
     * `models_trajectory.py`
     * `run_aki_kdigo_pipeline.py`（可选：与 v0.1 pipeline 平行）

3. **约定命名规范**

   * ID：统一使用 `subject_id / hadm_id / stay_id`。
   * 时间列命名：`charttime`、`intime`、`aki_onset_time` 等。
   * KDIGO 字段：`kdigo_stage_max`、`kdigo_stage_first`、`kdigo_onset_time`、`kdigo_progression` 等。

### 📦 产出物

* `docs/aki/03_kdigo_definition.md`（有结构的草稿）
* `docs/aki/04_modeling_plan.md`（任务和模型列表）
* 新建的 Python/SQL 空文件或只含 TODO 的文件。

### 🔍 验证方式

* 打开 docs 文件，你能一眼看出来：

  * 我们打算怎么定义 KDIGO。
  * 接下来要做哪些模型。
* `git status` 显示新增的这些文件。

---

## A1 KDIGO 数据基础：Scr & 尿量时间序列

### 🎯 目标

* 为 KDIGO 提供高质量的基础数据：

  * 每个 AKI ICU stay 的 **Scr 时间序列**（住院+ICU）
  * ICU 期间的 **尿量时间序列**

### ✅ 先决条件

* `mimiciv_hosp.labevents`、`mimiciv_icu.outputevents` 数据已导入。
* 已有 `aki_cohort`（18309 个 stay）。

### 📌 主要任务

1. **确定 itemid 清单（写进 03 文档）**

   * Scr：你之前已用过 50912，可在文档中记录。
   * 尿量：列出所有尿量相关 itemid（来自官方代码书），写入：

     * `docs/aki/03_kdigo_definition.md` 的 “itemid 对照表” 章节。

2. **构造 Scr 时间序列视图：`aki_scr_timeseries`**

   * SQL 放在 `backend/sql/aki/aki_scr_timeseries.sql`。
   * 视图字段建议：

     * `stay_id`
     * `charttime`
     * `scr`（mg/dL 或 µmol/L，统一单位）
   * 数据来源：

     * 与 `aki_cohort` join（保证只取 AKI ICU 患者）。
     * `mimiciv_hosp.labevents` 过滤 Scr itemid。
   * 时间范围：

     * 建议：从 `admittime - 7天` 到 `dischtime + 1天`，以便找基线和恢复。

3. **构造尿量时间序列视图：`aki_uo_timeseries`**

   * SQL: `backend/sql/aki/aki_uo_timeseries.sql`
   * 视图字段建议：

     * `stay_id`
     * `charttime`
     * `urine_output`（ml，按单次记录）
   * 数据来源：

     * `mimiciv_icu.outputevents` 与 `aki_cohort` join。
   * 后续 KDIGO 会按 6h/12h/24h 汇总尿量。

4. **在数据库中创建物化视图或普通视图**

   * 在 `psql` 中执行：

     * `\i backend/sql/aki/aki_scr_timeseries.sql`
     * `\i backend/sql/aki/aki_uo_timeseries.sql`
   * 建议用 **物化视图**（数据大，后面可加索引）。

### 📦 产出物

* 物化视图：

  * `mimiciv_icu.aki_scr_timeseries`
  * `mimiciv_icu.aki_uo_timeseries`
* 文档更新：KDIGO itemid 表。

### 🔍 验证方式

* 简单查询：

  ```sql
  SELECT COUNT(*) FROM aki_scr_timeseries;
  SELECT COUNT(*) FROM aki_uo_timeseries;
  ```
* 抽样查看：

  ```sql
  SELECT * FROM aki_scr_timeseries ORDER BY stay_id, charttime LIMIT 50;
  ```

---

## A2 KDIGO 标签生成：阶段、起病时间、表型

### 🎯 目标

* 给每个 stay 算出 **KDIGO stage 随时间变化** 和多个 summary 指标。
* 输出一个 `aki_kdigo_summary` 表/物化视图，后续建模都可以直接用。

### ✅ 先决条件

* A1 中的 Scr/UO 时间序列可用。
* 文档中已明确 KDIGO 阈值和实现细节（至少草稿）。

### 📌 主要任务

1. **定义基线 Scr 算法**

   * 在 `03_kdigo_definition.md` 中写清楚优先顺序，例如：

     1. 入院前 7 天内的最低 Scr。
     2. 无则住院期间（ICU 前）最低 Scr。
     3. 再无，则使用 ICU 前第一份 Scr。
   * 决定 **暂不使用 MDRD 反推 eGFR**（可以后续扩展）。

2. **在 Python 中实现 KDIGO 逻辑（推荐）**

   * 在 `backend/aki/kdigo_timeseries.py` 中：

     * 函数 1：从数据库拉取 `aki_scr_timeseries`、`aki_uo_timeseries`。
     * 函数 2：按 stay_id 计算：

       * baseline Scr
       * 每个时间点的 Scr 相对 baseline 的变化（绝对值 & 倍数）。
     * 函数 3：应用 KDIGO 规则，得到时间序列：

       * `kdigo_stage(t)` ∈ {0,1,2,3}
   * 在 `backend/aki/kdigo_labels.py` 中：

     * 聚合到 stay 级别：

       * `kdigo_stage_max`
       * `kdigo_stage_first`
       * `kdigo_onset_time`（首次达到 stage≥1 的时间）
       * `kdigo_progression`（是否从1→2/3）
       * `kdigo_persistent`（是否持续 > 48/72h）

3. **把结果写回 PostgreSQL（可选）**

   * 使用 SQLAlchemy：

     * 写入一个新表 `mimiciv_icu.aki_kdigo_summary`。
   * 或者保留为 Parquet/CSV，由后端直接使用。

4. **增加简单的 sanity check**

   * 随机抽几个 stay：

     * 把 Scr 时间序列导出成 CSV，用 Python 画折线图；
     * 用颜色标注出 KDIGO stage 变化，看是否直观合理。
   * 在 docs 中截图，写下典型例子。

### 📦 产出物

* `backend/aki/kdigo_timeseries.py`
* `backend/aki/kdigo_labels.py`
* 表/物化视图 `aki_kdigo_summary`
* 文档：KDIGO 逻辑和若干案例图。

### 🔍 验证方式

* 检查行数：

  ```sql
  SELECT COUNT(*) FROM aki_kdigo_summary;
  ```

  应接近 18309（可能有少量 Scr 完全缺失而被排除）。
* 检查分布：

  ```sql
  SELECT kdigo_stage_max, COUNT(*) FROM aki_kdigo_summary GROUP BY kdigo_stage_max;
  ```

  观察是否有合理比例。

---

## A3 建模数据集构建（Feature Store v0）

### 🎯 目标

* 构造一个 **行 = stay，列 = 特征 & 结局** 的建模数据集：

  * `aki_ml_dataset`

### ✅ 先决条件

* `aki_cohort`
* `aki_labs_firstday`
* `aki_kdigo_summary`
* （可选）已有 comorbidity / vital signs 视图

### 📌 主要任务

1. **在文档中确定特征清单**

   * 在 `04_modeling_plan.md`：

     * 人口学：age, gender, race, insurance。
     * KDIGO：`kdigo_stage_max`、`kdigo_progression`、`onset_time - intime`。
     * 实验室：Scr/BUN/Na/K/WBC/Hb/PLT（首日 & 变化率）。
     * ICU 信息：first_careunit、icu_los_days。
     * 结局：ICU 死亡、住院死亡、RRT、有无机械通气等。

2. **写 SQL 或 Python 视图组合特征**

   * 方案 1（推荐）：在 Python 里用 pandas 合并：

     * `aki_cohort` + `aki_labs_firstday` + `aki_kdigo_summary` (+ 其他视图)。
   * 方案 2：写 SQL 视图 `aki_feature_view`：

     * 方便 debug，但可能比较长。

3. **在 `backend/aki/features.py` 中写统一入口**

   * 函数：

     * `load_aki_ml_dataset(engine, task='mortality', label_window='icu')`
   * 输出：

     * pandas DataFrame：

       * `X`：特征列
       * `y`：标签（例如 `icu_mortality`）

4. **处理缺失值 & 编码**

   * 记录在文档：

     * 连续变量：中位数填补 / 指示变量。
     * 类别变量：One-Hot 编码（或 target encoding）。
   * 把这些放在 `features.py` 中的函数里。

### 📦 产出物

* `backend/aki/features.py`
* 可直接用于建模的 `aki_ml_dataset.parquet` 或 CSV（输出到 `outputs/aki/`）

### 🔍 验证方式

* `df.shape` 合理（行数接近 18k，列数几十）。
* `df.isna().mean()` 合理（缺失率可接受，并在文档中说明）。

---

## A4 传统回归模型（基线）

### 🎯 目标

* 用最传统的统计模型建立“可解释的 baseline”：

  * Logistic 回归 / Cox 回归
* 这些结果可以写 paper，可以做基线比较。

### ✅ 先决条件

* A3 的建模数据集可用。

### 📌 主要任务

1. **在文档中明确模型公式**

   * `04_modeling_plan.md`：

     * 例如：

       * 模型 1：`logit(P(ICU 死亡)) = β0 + β1 age + β2 gender + …`
       * 模型 2：增加 KDIGO stage。
   * 决定是否做：

     * 调整后的模型 vs 未调整模型。

2. **在 `backend/aki/models_logistic.py` 中实现**

   * 使用 `statsmodels` 或 `scikit-learn`：

     * 拿 `aki_ml_dataset`；
     * 拆分 train/test；
     * 训练 logistic 回归；
     * 输出：

       * 系数、OR、95%CI、p 值。
   * 把结果保存为：

     * `outputs/aki/aki_logistic_results.csv/json`。

3. **（可选）Cox 回归**

   * 如果定义好随访时间：

     * `time_to_event` + `event`；
     * 使用 `lifelines` 等包。

### 📦 产出物

* `backend/aki/models_logistic.py`
* `outputs/aki/aki_logistic_results.json` / CSV
* 文档中新增“模型 1/2/3的结果表 + 简短解读”。

### 🔍 验证方式

* 模型能跑完、不报错。
* OR 方向大致符合临床常识（年龄大→死亡风险上升等）。

---

## A5 机器学习模型：RF / XGBoost / LightGBM

### 🎯 目标

* 在传统回归的基础上，训练多种 ML 模型，提升预测性能。
* 输出指标和特征重要性，为后续前端展示准备数据。

### ✅ 先决条件

* A3 的特征工程已完成，A4 logistic 模型已跑过。

### 📌 主要任务

1. **在文档中定义评估策略**

   * `04_modeling_plan.md`：

     * 数据划分（train/val/test 或 CV）。
     * 指标：

       * AUROC、AUPRC、F1、Brier、Calibration。
     * 是否做患者级别的分层（避免同一患者多次入院泄漏）。

2. **在 `backend/aki/models_ml.py` 中实现**

   * 模型列表：

     * RandomForestClassifier
     * XGBoost / LightGBM
   * 支持：

     * 网格搜索或简单一套预定义参数。
     * 返回：

       * 各模型在 val/test 上的指标。
       * 每个模型的 feature importance。

3. **结果写出到 JSON/CSV**

   * 如：

     * `outputs/aki/aki_ml_metrics.json`
     * `outputs/aki/aki_feature_importance_xgb.json`
   * 这些以后会被前端读取生成 ROC 图、条形图等。

### 📦 产出物

* `backend/aki/models_ml.py`
* 指标和重要性 JSON/CSV 文件

### 🔍 验证方式

* 模型训练过程中显存/内存可承受。
* 指标合理：ML 模型比 logistic 有一定提升，而不是离谱的 0.99。

---

## A6 轨迹模型 / 时间序列分析

### 🎯 目标

* 把 AKI 患者按 Scr/尿量轨迹分型，形成 AKI 表型亚组。
* 将亚组信息反馈到建模和前端展示。

### ✅ 先决条件

* A2 中已经完成 Scr & UO 时间序列和 KDIGO 时序。

### 📌 主要任务

1. **在文档中定义轨迹问题**

   * `03_kdigo_definition.md` / `04_modeling_plan.md`：

     * 轨迹时间窗：如 ICU 前 7 天。
     * 时间粒度：如每 12 小时一次。
     * 处理缺失的方法（插值 / LOCF / 删除）。

2. **构造均匀时间网格**

   * 在 `backend/aki/trajectory_prep.py`：

     * 读 `aki_scr_timeseries`；
     * 对每个 stay 做 resample（到固定间隔）；
     * 组成一个 `N × T` 的矩阵（或 `N × T × variables`）。

3. **聚类/轨迹方法**

   * 第一版（简单可行）：

     * 标准化后，用 KMeans 或层次聚类。
     * 每个 stay 得到一个 `trajectory_cluster ∈ {1..K}`。
   * 后续可迭代：

     * 使用 DTW + 聚类。
     * 或在 R 中用 GBTM。

4. **把轨迹结果写回 summary 表**

   * 在 `aki_kdigo_summary` 或新的 `aki_trajectory_summary` 中加：

     * `trajectory_cluster`
     * 轨迹的一些 summary（例如早峰型、晚峰型等）。

5. **分析不同轨迹和结局的关系**

   * 简单交叉表：

     ```sql
     SELECT trajectory_cluster, kdigo_stage_max, ICU_mortality, COUNT(*)
     FROM aki_cohort JOIN aki_trajectory_summary USING (stay_id)
     GROUP BY trajectory_cluster, kdigo_stage_max, ICU_mortality;
     ```

### 📦 产出物

* `backend/aki/trajectory_prep.py`
* `backend/aki/models_trajectory.py`
* 新的表/视图：`aki_trajectory_summary`
* 若干轨迹图（输出到 `outputs/aki/plots/`）

### 🔍 验证方式

* 轨迹聚类数量 K 合理（3–6 个分群）。
* 各群体样本数不过于悬殊。
* 分群间结局分布有差异，说明有实际意义。

---

## A7 实验管理 & 汇总文档

### 🎯 目标

* 把路线 A 的所有成果整理清楚，方便以后复现 & 写论文 & 扩展到其他疾病。

### ✅ 先决条件

* A0–A6 均已至少完成一版可用实现。

### 📌 主要任务

1. **统一实验配置管理**

   * 在 `experiments/aki/` 下存放：

     * 每次实验的 config（YAML/JSON）：

       * 使用的特征集、模型、参数。
     * 对应的结果文件路径。
   * 简单的话可以用一个 CSV 清单记录。

2. **补全文档**

   * `03_kdigo_definition.md`：定稿版 KDIGO 实现。
   * `04_modeling_plan.md`：

     * 更新为 “实际模型 + 实际结果”，而不是纯计划。
   * `README.md` 中增加：

     * AKI v0.2 / v0.3 的里程碑说明。

3. **形成一篇“技术说明书”**

   * 用于将来写论文方法部分：

     * Cohort 定义。
     * KDIGO 实现。
     * 建模流程。
     * 评估指标。

### 📦 产出物

* `experiments/aki/*`
* 完整更新后的 docs。

### 🔍 验证方式

* 你在几个月后仅看文档，就能：

  * 重建数据库视图；
  * 跑完 KDIGO + 模型；
  * 生成所有 JSON/CSV；
  * 复现关键图和表。

---

## 最后：如何使用这份实施计划？

建议的推进方式：

1. **现在先锁定 A0 + A1：**

   * 把文档骨架搭好；
   * 把 Scr/尿量时间序列视图建起来。

2. 然后依次推进：

   * A2 → KDIGO 标签
   * A3 → 建模数据集
   * A4 → logistic baseline
   * A5 → ML
   * A6 → 轨迹

3. 每做完一个大节点，就在 docs 里写一小段「阶段总结」。

---

如果你同意这份实施方案，下一步我建议我们从 **A0 + A1 的具体执行步骤** 开始：
比如先一起把 `03_kdigo_definition.md` 的目录结构写出来，然后写一个第一版 `aki_scr_timeseries.sql` 的草稿。
