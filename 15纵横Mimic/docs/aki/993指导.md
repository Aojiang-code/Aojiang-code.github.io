好，我们正式进入 **步骤 3：Python 分析**，而且完全按照你说的——**先写 `.py` 脚本，后面再“翻译”成 ipynb**。

接下来我会给你：

1. 推荐的 `backend` 目录结构
2. 每个 `.py` 文件的职责
3. 可以直接复制使用的示例代码（你只需要改数据库连接 & 实验室 itemid）

---

## 一、推荐的后端目录结构

在你的项目下建议这样放：

```text
backend/
  __init__.py              # 可空
  config.py                # 数据库配置（从环境变量读）
  paths.py                 # 输出路径等
  aki/
    __init__.py
    data_loader.py         # 只负责从数据库读数据 & 合并
    descriptive.py         # 负责描述性分析（生成统计结果）
    export_results.py      # 负责把结果写成 JSON / CSV
    run_aki_pipeline.py    # 一键跑通 AKI 描述性分析的主脚本
outputs/
  aki/
    # 这里会生成各种 csv/json，如：
    # aki_basic_stats.json
    # aki_age_distribution.json
    # aki_gender_distribution.json
    # aki_mortality.json
    # aki_table1_overall.csv
```

> 之后前端可以直接从 `outputs/aki/` 里取 JSON（或同步到 `frontend/public/data/aki/`）。

---

## 二、`backend/config.py`：数据库配置

```python
# backend/config.py

import os

# 建议在系统或 .env 中设置这些环境变量
DB_HOST = os.getenv("MIMIC_DB_HOST", "localhost")
DB_PORT = os.getenv("MIMIC_DB_PORT", "5432")
DB_NAME = os.getenv("MIMIC_DB_NAME", "mimiciv")
DB_USER = os.getenv("MIMIC_DB_USER", "postgres")
DB_PASSWORD = os.getenv("MIMIC_DB_PASSWORD", "your_password_here")  # TODO: 修改

# 如果你以后有多个数据库，可以在这里统一管理
```

---

## 三、`backend/paths.py`：统一输出路径

```python
# backend/paths.py

from pathlib import Path

# 项目根目录：假设 backend/ 与 docs/ 在同一层
BASE_DIR = Path(__file__).resolve().parent.parent

# 输出目录：outputs/aki/
OUTPUT_DIR_AKI = BASE_DIR / "outputs" / "aki"
OUTPUT_DIR_AKI.mkdir(parents=True, exist_ok=True)
```

---

## 四、`backend/aki/data_loader.py`：从数据库读取 AKI 数据

这个模块只做两件事：

* 建立数据库连接（SQLAlchemy）
* 读取 `aki_cohort` 和 `aki_labs_firstday`，并合并成一个 pandas DataFrame

```python
# backend/aki/data_loader.py

from typing import Optional
import pandas as pd
from sqlalchemy import create_engine
from sqlalchemy.engine import Engine

from backend.config import DB_HOST, DB_PORT, DB_NAME, DB_USER, DB_PASSWORD


def get_engine(echo: bool = False) -> Engine:
    """
    创建 SQLAlchemy Engine，用于连接 PostgreSQL.
    """
    url = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
    engine = create_engine(url, echo=echo)
    return engine


def load_aki_cohort(engine: Engine,
                    limit: Optional[int] = None) -> pd.DataFrame:
    """
    读取 aki_cohort 视图（步骤2中创建）.
    可选 limit 用于调试时只取一部分数据.
    """
    sql = "SELECT * FROM aki_cohort"
    if limit is not None:
        sql += f" LIMIT {int(limit)}"
    df = pd.read_sql(sql, engine)
    return df


def load_aki_labs_firstday(engine: Engine) -> pd.DataFrame:
    """
    读取 aki_labs_firstday 视图（步骤2中创建）.
    """
    sql = "SELECT * FROM aki_labs_firstday"
    df = pd.read_sql(sql, engine)
    return df


def load_aki_full_dataset(engine: Engine,
                          limit: Optional[int] = None) -> pd.DataFrame:
    """
    合并 aki_cohort 和 aki_labs_firstday，
    返回一个包含人口学、ICU信息、结局和首日实验室指标的 DataFrame.
    """
    cohort = load_aki_cohort(engine, limit=limit)
    labs = load_aki_labs_firstday(engine)

    # 根据 stay_id 合并（也可以用 subject_id + hadm_id + stay_id）
    merged = cohort.merge(
        labs,
        on=["subject_id", "hadm_id", "stay_id"],
        how="left",
        suffixes=("", "_lab")
    )

    return merged


if __name__ == "__main__":
    # 简单自测：打印样本量和几个字段
    engine = get_engine()
    df = load_aki_full_dataset(engine, limit=1000)
    print(df.head())
    print("Sample size (subset):", len(df))
```

---

## 五、`backend/aki/descriptive.py`：描述性分析逻辑

这里实现几个核心功能：

1. 计算整体基本信息（样本量、年龄均值、死亡率等）
2. 计算年龄分布（分组）
3. 计算性别分布
4. 计算 ICU/住院死亡率分布
5. 生成 Table 1（简单版：数值变量 + 分类变量）

```python
# backend/aki/descriptive.py

from typing import Dict, List
import numpy as np
import pandas as pd


def compute_basic_stats(df: pd.DataFrame) -> Dict:
    """
    计算一些整体性的描述指标：
    - 样本量
    - 年龄均值/中位数
    - ICU/住院死亡率
    - ICU/住院住院时间中位数
    """
    n = len(df)

    basic = {
        "n": int(n),
        "age_mean": float(df["age"].mean(skipna=True)),
        "age_median": float(df["age"].median(skipna=True)),
        "icu_mortality_rate": float(df["icu_mortality"].mean(skipna=True)),
        "hosp_mortality_rate": float(df["hosp_mortality"].mean(skipna=True)),
        "icu_los_median": float(df["icu_los_days"].median(skipna=True)),
        "hosp_los_median": float(df["hosp_los_days"].median(skipna=True)),
    }
    return basic


def age_group_distribution(df: pd.DataFrame,
                           bins: List[int] = None) -> Dict:
    """
    按年龄分组，生成直方图/条形图可用的数据结构.
    返回：
    {
      "age_groups": [...],
      "counts": [...],
      "proportions": [...],
      "n": int
    }
    """
    if bins is None:
        bins = [18, 30, 40, 50, 60, 70, 80, 120]

    labels = [
        "18–29",
        "30–39",
        "40–49",
        "50–59",
        "60–69",
        "70–79",
        "80+",
    ]

    df = df.copy()
    df["age_group"] = pd.cut(
        df["age"],
        bins=bins,
        labels=labels,
        right=False,
        include_lowest=True,
    )

    counts = df["age_group"].value_counts().sort_index()
    n = int(counts.sum())
    proportions = (counts / n).fillna(0.0)

    return {
        "age_groups": labels,
        "counts": [int(counts.get(label, 0)) for label in labels],
        "proportions": [float(proportions.get(label, 0.0)) for label in labels],
        "n": n,
    }


def categorical_distribution(df: pd.DataFrame,
                             column: str,
                             categories_order: List[str] = None,
                             display_map: Dict[str, str] = None) -> Dict:
    """
    通用的分类变量分布，用于性别、保险、种族等.

    返回：
    {
      "categories": [...],
      "display_categories": [...],
      "counts": [...],
      "proportions": [...],
      "n": int
    }
    """
    series = df[column].astype("category")

    if categories_order:
        series = series.cat.set_categories(categories_order)

    counts = series.value_counts().sort_index()
    n = int(counts.sum())
    proportions = (counts / n).fillna(0.0)

    # 显示名称映射（用于前端显示中文）
    categories = list(counts.index.astype(str))
    if display_map:
        display_categories = [display_map.get(c, c) for c in categories]
    else:
        display_categories = categories

    return {
        "categories": categories,
        "display_categories": display_categories,
        "counts": [int(c) for c in counts],
        "proportions": [float(p) for p in proportions],
        "n": n,
    }


def mortality_distribution(df: pd.DataFrame) -> Dict:
    """
    生成 ICU 和住院死亡率的简单结构：
    {
      "outcomes": ["ICU mortality", "Hospital mortality"],
      "rates": [0.xx, 0.xx]
    }
    """
    icu_rate = float(df["icu_mortality"].mean(skipna=True))
    hosp_rate = float(df["hosp_mortality"].mean(skipna=True))

    return {
        "outcomes": ["icu_mortality", "hosp_mortality"],
        "display_outcomes": ["ICU死亡率", "住院死亡率"],
        "rates": [icu_rate, hosp_rate],
    }


def generate_table1(df: pd.DataFrame,
                    numeric_vars: List[str],
                    categorical_vars: List[str]) -> pd.DataFrame:
    """
    简单版 Table 1：
    - 数值变量：给出 n, mean, std, median, Q1, Q3
    - 分类变量：给出每个类别的 count 与 proportion
    返回一个“长表”（长格式）的 DataFrame，方便写 csv / 用在网页里。
    """
    rows = []

    # 数值变量
    for var in numeric_vars:
        series = df[var]
        clean = series.dropna()
        if clean.empty:
            continue

        rows.append({
            "variable": var,
            "level": "",
            "type": "numeric",
            "n": int(clean.count()),
            "mean": float(clean.mean()),
            "std": float(clean.std()),
            "median": float(clean.median()),
            "q1": float(clean.quantile(0.25)),
            "q3": float(clean.quantile(0.75)),
            "count": np.nan,
            "proportion": np.nan,
        })

    # 分类变量
    for var in categorical_vars:
        series = df[var].astype("category")
        counts = series.value_counts(dropna=False)
        n = int(counts.sum())
        proportions = counts / n

        for level, count in counts.items():
            rows.append({
                "variable": var,
                "level": str(level),
                "type": "categorical",
                "n": n,
                "mean": np.nan,
                "std": np.nan,
                "median": np.nan,
                "q1": np.nan,
                "q3": np.nan,
                "count": int(count),
                "proportion": float(proportions[level]),
            })

    table1 = pd.DataFrame(rows)
    return table1
```

---

## 六、`backend/aki/export_results.py`：把结果写成 JSON / CSV

```python
# backend/aki/export_results.py

import json
from pathlib import Path
from typing import Dict

import pandas as pd

from backend.paths import OUTPUT_DIR_AKI


def save_json(data: Dict, filename: str) -> Path:
    """
    将 dict 保存为 JSON 文件到 outputs/aki/
    """
    path = OUTPUT_DIR_AKI / filename
    with path.open("w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"[OK] JSON saved to {path}")
    return path


def save_csv(df: pd.DataFrame, filename: str) -> Path:
    """
    将 DataFrame 保存为 CSV 文件到 outputs/aki/
    """
    path = OUTPUT_DIR_AKI / filename
    df.to_csv(path, index=False)
    print(f"[OK] CSV saved to {path}")
    return path
```

---

## 七、`backend/aki/run_aki_pipeline.py`：一键跑通 AKI 描述分析

这个脚本就是把前面的模块串起来：

```python
# backend/aki/run_aki_pipeline.py

from backend.aki.data_loader import get_engine, load_aki_full_dataset
from backend.aki.descriptive import (
    compute_basic_stats,
    age_group_distribution,
    categorical_distribution,
    mortality_distribution,
    generate_table1,
)
from backend.aki.export_results import save_json, save_csv


def main(limit=None):
    """
    运行 AKI 描述性分析的完整流程：
    1. 从数据库读取 aki_cohort + aki_labs_firstday 并合并
    2. 计算基本统计
    3. 生成年龄、性别、死亡率等分布
    4. 生成 Table 1
    5. 把所有结果导出到 outputs/aki/
    """
    print(">>> 连接数据库并加载 AKI 数据...")
    engine = get_engine()
    df = load_aki_full_dataset(engine, limit=limit)
    print(f"[INFO] AKI dataset loaded, n = {len(df)}")

    # 1. 基本统计
    print(">>> 计算基础统计指标...")
    basic_stats = compute_basic_stats(df)
    save_json(basic_stats, "aki_basic_stats.json")

    # 2. 年龄分布
    print(">>> 计算年龄分布...")
    age_dist = age_group_distribution(df)
    save_json(age_dist, "aki_age_distribution.json")

    # 3. 性别分布
    print(">>> 计算性别分布...")
    gender_display_map = {"M": "男", "F": "女"}
    gender_dist = categorical_distribution(
        df,
        column="gender",
        categories_order=["M", "F"],
        display_map=gender_display_map,
    )
    save_json(gender_dist, "aki_gender_distribution.json")

    # 4. 住院/ICU死亡率
    print(">>> 计算死亡率...")
    mort_dist = mortality_distribution(df)
    save_json(mort_dist, "aki_mortality.json")

    # 5. Table 1
    print(">>> 生成 Table 1（整体队列）...")
    numeric_vars = [
        "age",
        "icu_los_days",
        "hosp_los_days",
        # 如果你希望，也可以加上 scr_firstday, bun_firstday 等
        # "scr_firstday", "bun_firstday",
    ]
    categorical_vars = [
        "gender",
        "ethnicity",
        "insurance",
        "icu_mortality",
        "hosp_mortality",
    ]
    table1 = generate_table1(df, numeric_vars, categorical_vars)
    save_csv(table1, "aki_table1_overall.csv")

    print(">>> AKI 描述性分析流程完成 ✅")


if __name__ == "__main__":
    # 调试时可以设置 limit=1000，正式跑通后把 limit 改成 None
    main(limit=None)
```

---

## 接下来你可以怎么做？

1. 在项目里创建上述这些 `.py` 文件（注意目录结构）
2. 在系统中配置数据库环境变量（或临时在 `config.py` 里直接写死）
3. 在命令行里运行：

```bash
cd your_project_root
python -m backend.aki.run_aki_pipeline
```

如果一切正常，你会在 `outputs/aki/` 看到：

* `aki_basic_stats.json`
* `aki_age_distribution.json`
* `aki_gender_distribution.json`
* `aki_mortality.json`
* `aki_table1_overall.csv`

到这里，你的 **AKI 后端描述性分析就已经跑通了**，下一步前端只要读取这些 JSON/CSV 即可展示。

---

如果你愿意，下一步我们可以：

* 先检查一下你实际跑出来的几个 JSON/CSV 的字段结构是否符合你前端的预期
* 然后进入“前端步骤”：设计 `/nephrology/aki` 页面怎么调用这些文件，用 ECharts 画出图表。
