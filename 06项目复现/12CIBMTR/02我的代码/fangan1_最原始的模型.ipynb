{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70942,"databundleVersionId":10381525,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:38:01.197903Z","iopub.execute_input":"2025-02-08T13:38:01.198253Z","iopub.status.idle":"2025-02-08T13:38:01.207025Z","shell.execute_reply.started":"2025-02-08T13:38:01.198228Z","shell.execute_reply":"2025-02-08T13:38:01.205817Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\n/kaggle/input/equity-post-HCT-survival-predictions/data_dictionary.csv\n/kaggle/input/equity-post-HCT-survival-predictions/train.csv\n/kaggle/input/equity-post-HCT-survival-predictions/test.csv\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:38:01.208631Z","iopub.execute_input":"2025-02-08T13:38:01.209042Z","iopub.status.idle":"2025-02-08T13:38:01.373889Z","shell.execute_reply.started":"2025-02-08T13:38:01.209000Z","shell.execute_reply":"2025-02-08T13:38:01.372041Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/equity-post-HCT-survival-predictions\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"cd ../input/equity-post-HCT-survival-predictions/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:38:01.509897Z","iopub.execute_input":"2025-02-08T13:38:01.510269Z","iopub.status.idle":"2025-02-08T13:38:01.518700Z","shell.execute_reply.started":"2025-02-08T13:38:01.510242Z","shell.execute_reply":"2025-02-08T13:38:01.517528Z"}},"outputs":[{"name":"stdout","text":"[Errno 2] No such file or directory: '../input/equity-post-HCT-survival-predictions/'\n/kaggle/input/equity-post-HCT-survival-predictions\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:38:01.520182Z","iopub.execute_input":"2025-02-08T13:38:01.520509Z","iopub.status.idle":"2025-02-08T13:38:01.679041Z","shell.execute_reply.started":"2025-02-08T13:38:01.520482Z","shell.execute_reply":"2025-02-08T13:38:01.677580Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/equity-post-HCT-survival-predictions\n","output_type":"stream"}],"execution_count":74},{"cell_type":"markdown","source":"# 方案1","metadata":{}},{"cell_type":"markdown","source":"## 1. 数据加载与预处理\n首先，我们需要加载数据并进行预处理，包括处理缺失值、编码类别型特征、标准化数值型特征等。","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import roc_auc_score\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cb\n\n# 加载数据\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')\ndata_dict = pd.read_csv('data_dictionary.csv')\n\n# 查看数据\nprint(train.head())\nprint(test.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:38:01.681266Z","iopub.execute_input":"2025-02-08T13:38:01.681720Z","iopub.status.idle":"2025-02-08T13:38:02.028648Z","shell.execute_reply.started":"2025-02-08T13:38:01.681685Z","shell.execute_reply":"2025-02-08T13:38:02.026984Z"}},"outputs":[{"name":"stdout","text":"   ID                       dri_score psych_disturb    cyto_score diabetes  \\\n0   0  N/A - non-malignant indication            No           NaN       No   \n1   1                    Intermediate            No  Intermediate       No   \n2   2  N/A - non-malignant indication            No           NaN       No   \n3   3                            High            No  Intermediate       No   \n4   4                            High            No           NaN       No   \n\n   hla_match_c_high  hla_high_res_8          tbi_status arrhythmia  \\\n0               NaN             NaN              No TBI         No   \n1               2.0             8.0  TBI +- Other, >cGy         No   \n2               2.0             8.0              No TBI         No   \n3               2.0             8.0              No TBI         No   \n4               2.0             8.0              No TBI         No   \n\n   hla_low_res_6  ...          tce_div_match donor_related  \\\n0            6.0  ...                    NaN     Unrelated   \n1            6.0  ...  Permissive mismatched       Related   \n2            6.0  ...  Permissive mismatched       Related   \n3            6.0  ...  Permissive mismatched     Unrelated   \n4            6.0  ...  Permissive mismatched       Related   \n\n       melphalan_dose hla_low_res_8 cardiac  hla_match_drb1_high  \\\n0  N/A, Mel not given           8.0      No                  2.0   \n1  N/A, Mel not given           8.0      No                  2.0   \n2  N/A, Mel not given           8.0      No                  2.0   \n3  N/A, Mel not given           8.0      No                  2.0   \n4                 MEL           8.0      No                  2.0   \n\n  pulm_moderate  hla_low_res_10  efs efs_time  \n0            No            10.0  0.0   42.356  \n1           Yes            10.0  1.0    4.672  \n2            No            10.0  0.0   19.793  \n3            No            10.0  0.0  102.349  \n4            No            10.0  0.0   16.223  \n\n[5 rows x 60 columns]\n      ID                       dri_score psych_disturb    cyto_score diabetes  \\\n0  28800  N/A - non-malignant indication            No           NaN       No   \n1  28801                    Intermediate            No  Intermediate       No   \n2  28802  N/A - non-malignant indication            No           NaN       No   \n\n   hla_match_c_high  hla_high_res_8          tbi_status arrhythmia  \\\n0               NaN             NaN              No TBI         No   \n1               2.0             8.0  TBI +- Other, >cGy         No   \n2               2.0             8.0              No TBI         No   \n\n   hla_low_res_6  ... karnofsky_score hepatic_mild          tce_div_match  \\\n0            6.0  ...            90.0           No                    NaN   \n1            6.0  ...            90.0           No  Permissive mismatched   \n2            6.0  ...            90.0           No  Permissive mismatched   \n\n  donor_related      melphalan_dose  hla_low_res_8 cardiac  \\\n0     Unrelated  N/A, Mel not given            8.0      No   \n1       Related  N/A, Mel not given            8.0      No   \n2       Related  N/A, Mel not given            8.0      No   \n\n   hla_match_drb1_high  pulm_moderate hla_low_res_10  \n0                  2.0             No           10.0  \n1                  2.0            Yes           10.0  \n2                  2.0             No           10.0  \n\n[3 rows x 58 columns]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":75},{"cell_type":"markdown","source":"## 2. 数据预处理\n### 2.1 处理缺失值\n对于数值型特征，使用中位数填充；对于类别型特征，使用众数填充。","metadata":{}},{"cell_type":"code","source":"# 分离特征和目标变量\nX = train.drop(columns=['ID', 'efs', 'efs_time'])\ny = train['efs']\n\n\n# 定义数值型和类别型特征\nnumeric_features = X.select_dtypes(include=['int64', 'float64']).columns\ncategorical_features = X.select_dtypes(include=['object', 'category']).columns\n\n# 定义预处理管道\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ])\n\n# 应用预处理\nX_processed = preprocessor.fit_transform(X)\ntest_processed = preprocessor.transform(test.drop(columns=['ID']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:38:02.030491Z","iopub.execute_input":"2025-02-08T13:38:02.030920Z","iopub.status.idle":"2025-02-08T13:38:02.727994Z","shell.execute_reply.started":"2025-02-08T13:38:02.030890Z","shell.execute_reply":"2025-02-08T13:38:02.726825Z"}},"outputs":[],"execution_count":76},{"cell_type":"markdown","source":"### 2.2 数据探索","metadata":{}},{"cell_type":"code","source":"# # 统计分析\n# print(train_data.describe())\n\n# # 可视化分析\n# import seaborn as sns\n# import matplotlib.pyplot as plt\n\n# # 绘制特征分布图\n# for col in train_data.columns:\n#     if train_data[col].dtype == 'number':\n#         sns.histplot(train_data[col], kde=True)\n#         plt.title(f'Distribution of {col}')\n#         plt.show()\n\n# # 绘制相关性热力图\n# plt.figure(figsize=(10, 8))\n# sns.heatmap(train_data.corr(), annot=True, cmap='coolwarm')\n# plt.title('Correlation Heatmap')\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:38:02.730338Z","iopub.execute_input":"2025-02-08T13:38:02.730864Z","iopub.status.idle":"2025-02-08T13:38:02.735650Z","shell.execute_reply.started":"2025-02-08T13:38:02.730813Z","shell.execute_reply":"2025-02-08T13:38:02.734315Z"}},"outputs":[],"execution_count":77},{"cell_type":"markdown","source":"## 3. 模型训练与调优\n### 3.1 基线模型\n使用随机森林作为基线模型。","metadata":{}},{"cell_type":"code","source":"# 划分训练集和验证集\nX_train, X_val, y_train, y_val = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n\n# 训练随机森林模型\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\n\n# 验证集评估\ny_pred = rf.predict_proba(X_val)[:, 1]\nprint(f'Validation ROC AUC: {roc_auc_score(y_val, y_pred)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:38:02.737191Z","iopub.execute_input":"2025-02-08T13:38:02.737527Z","iopub.status.idle":"2025-02-08T13:38:08.163911Z","shell.execute_reply.started":"2025-02-08T13:38:02.737500Z","shell.execute_reply":"2025-02-08T13:38:08.162399Z"}},"outputs":[{"name":"stdout","text":"Validation ROC AUC: 0.7258494879409604\n","output_type":"stream"}],"execution_count":78},{"cell_type":"markdown","source":"### 3.2 高级模型\n使用XGBoost、LightGBM和CatBoost进行训练和调优。","metadata":{}},{"cell_type":"code","source":"# # XGBoost模型\n# xgb_model = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, random_state=42)\n# xgb_model.fit(X_train, y_train)\n# y_pred_xgb = xgb_model.predict_proba(X_val)[:, 1]\n# print(f'XGBoost Validation ROC AUC: {roc_auc_score(y_val, y_pred_xgb)}')\n\n# # LightGBM模型\n# lgb_model = lgb.LGBMClassifier(objective='binary', n_estimators=100, random_state=42)\n# lgb_model.fit(X_train, y_train)\n# y_pred_lgb = lgb_model.predict_proba(X_val)[:, 1]\n# print(f'LightGBM Validation ROC AUC: {roc_auc_score(y_val, y_pred_lgb)}')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:38:08.165218Z","iopub.execute_input":"2025-02-08T13:38:08.166046Z","iopub.status.idle":"2025-02-08T13:38:08.170730Z","shell.execute_reply.started":"2025-02-08T13:38:08.166015Z","shell.execute_reply":"2025-02-08T13:38:08.169311Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"# # 指定一个已存在的目录作为 train_dir\n# train_dir = '/kaggle/working/catboost_info'\n\n# # 确保目录存在\n# import os\n# if not os.path.exists(train_dir):\n#     os.makedirs(train_dir)\n\n# # 使用指定的 train_dir\n# cb_model = cb.CatBoostClassifier(random_state=42, verbose=0, train_dir=train_dir)\n# cb_model.fit(X_train, y_train)\n# y_pred_cb = cb_model.predict_proba(X_val)[:, 1]\n# print(f'CatBoost Validation ROC AUC: {roc_auc_score(y_val, y_pred_cb)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:38:08.171706Z","iopub.execute_input":"2025-02-08T13:38:08.172105Z","iopub.status.idle":"2025-02-08T13:38:08.192984Z","shell.execute_reply.started":"2025-02-08T13:38:08.172078Z","shell.execute_reply":"2025-02-08T13:38:08.191620Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# from sklearn.model_selection import train_test_split\n# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n# from sklearn.impute import SimpleImputer\n# from sklearn.compose import ColumnTransformer\n# from sklearn.pipeline import Pipeline\n# from sklearn.metrics import roc_auc_score\n# import xgboost as xgb\n# import lightgbm as lgb\n# import catboost as cb\n\n# # 加载数据\n# train = pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/train.csv')\n# test = pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/test.csv')\n\n# # 分离特征和目标变量\n# X = train.drop(columns=['ID', 'efs', 'efs_time'])\n# y = train['efs']\n\n# # 定义数值型和类别型特征\n# numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n# categorical_features = X.select_dtypes(include=['object', 'category']).columns\n\n# # 定义预处理管道\n# numeric_transformer = Pipeline(steps=[\n#     ('imputer', SimpleImputer(strategy='median')),\n#     ('scaler', StandardScaler())\n# ])\n\n# categorical_transformer = Pipeline(steps=[\n#     ('imputer', SimpleImputer(strategy='most_frequent')),\n#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n# ])\n\n# preprocessor = ColumnTransformer(\n#     transformers=[\n#         ('num', numeric_transformer, numeric_features),\n#         ('cat', categorical_transformer, categorical_features)\n#     ])\n\n# # 应用预处理\n# X_processed = preprocessor.fit_transform(X)\n# test_processed = preprocessor.transform(test.drop(columns=['ID']))\n\n# # 划分训练集和验证集\n# X_train, X_val, y_train, y_val = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n\n# 指定一个已存在的目录作为 train_dir\ntrain_dir = '/kaggle/working/catboost_info'\n\n# 确保目录存在\nimport os\nif not os.path.exists(train_dir):\n    os.makedirs(train_dir)\n\n# XGBoost模型\nxgb_model = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, random_state=42)\nxgb_model.fit(X_train, y_train)\ny_pred_xgb = xgb_model.predict_proba(X_val)[:, 1]\nprint(f'XGBoost Validation ROC AUC: {roc_auc_score(y_val, y_pred_xgb)}')\n\n# LightGBM模型\nlgb_model = lgb.LGBMClassifier(objective='binary', n_estimators=100, random_state=42)\nlgb_model.fit(X_train, y_train)\ny_pred_lgb = lgb_model.predict_proba(X_val)[:, 1]\nprint(f'LightGBM Validation ROC AUC: {roc_auc_score(y_val, y_pred_lgb)}')\n\n# CatBoost模型\ncb_model = cb.CatBoostClassifier(random_state=42, verbose=0, train_dir=train_dir)\ncb_model.fit(X_train, y_train)\ny_pred_cb = cb_model.predict_proba(X_val)[:, 1]\nprint(f'CatBoost Validation ROC AUC: {roc_auc_score(y_val, y_pred_cb)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:38:08.194208Z","iopub.execute_input":"2025-02-08T13:38:08.194623Z","iopub.status.idle":"2025-02-08T13:38:20.344347Z","shell.execute_reply.started":"2025-02-08T13:38:08.194591Z","shell.execute_reply":"2025-02-08T13:38:20.342905Z"}},"outputs":[{"name":"stdout","text":"XGBoost Validation ROC AUC: 0.7307544063168827\n[LightGBM] [Info] Number of positive: 12455, number of negative: 10585\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011795 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 943\n[LightGBM] [Info] Number of data points in the train set: 23040, number of used features: 178\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.540582 -> initscore=0.162684\n[LightGBM] [Info] Start training from score 0.162684\nLightGBM Validation ROC AUC: 0.7468795389694087\nCatBoost Validation ROC AUC: 0.7543280668821892\n","output_type":"stream"}],"execution_count":81},{"cell_type":"markdown","source":"### 4. 超参数调优\n使用GridSearchCV对XGBoost进行超参数调优。","metadata":{}},{"cell_type":"code","source":"param_grid = {\n    'max_depth': [3, 5, 7],\n    'learning_rate': [0.01, 0.1, 0.2],\n    'n_estimators': [100, 200, 300]\n}\n\ngrid_search = GridSearchCV(estimator=xgb.XGBClassifier(objective='binary:logistic', random_state=42),\n                           param_grid=param_grid,\n                           scoring='roc_auc',\n                           cv=5,\n                           verbose=1)\n\ngrid_search.fit(X_train, y_train)\nprint(f'Best parameters: {grid_search.best_params_}')\nprint(f'Best ROC AUC: {grid_search.best_score_}')\n\n# 使用最佳参数重新训练\nbest_xgb_model = grid_search.best_estimator_\ny_pred_best_xgb = best_xgb_model.predict_proba(X_val)[:, 1]\nprint(f'Best XGBoost Validation ROC AUC: {roc_auc_score(y_val, y_pred_best_xgb)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:38:20.347467Z","iopub.execute_input":"2025-02-08T13:38:20.347803Z","iopub.status.idle":"2025-02-08T13:40:35.142253Z","shell.execute_reply.started":"2025-02-08T13:38:20.347775Z","shell.execute_reply":"2025-02-08T13:40:35.141083Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 27 candidates, totalling 135 fits\nBest parameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\nBest ROC AUC: 0.7445535529227847\nBest XGBoost Validation ROC AUC: 0.7503479157337131\n","output_type":"stream"}],"execution_count":82},{"cell_type":"markdown","source":"## 5. 模型融合\n使用模型融合技术提高预测性能。","metadata":{}},{"cell_type":"code","source":"# 模型融合\nfrom sklearn.ensemble import VotingClassifier\n\nensemble_model = VotingClassifier(estimators=[\n    ('rf', rf),\n    ('xgb', best_xgb_model),\n    ('lgb', lgb_model),\n    ('cb', cb_model)\n], voting='soft')\n\nensemble_model.fit(X_train, y_train)\ny_pred_ensemble = ensemble_model.predict_proba(X_val)[:, 1]\nprint(f'Ensemble Validation ROC AUC: {roc_auc_score(y_val, y_pred_ensemble)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:40:35.143734Z","iopub.execute_input":"2025-02-08T13:40:35.144272Z","iopub.status.idle":"2025-02-08T13:40:52.772842Z","shell.execute_reply.started":"2025-02-08T13:40:35.144241Z","shell.execute_reply":"2025-02-08T13:40:52.771586Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 12455, number of negative: 10585\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011482 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 943\n[LightGBM] [Info] Number of data points in the train set: 23040, number of used features: 178\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.540582 -> initscore=0.162684\n[LightGBM] [Info] Start training from score 0.162684\nEnsemble Validation ROC AUC: 0.752519232117967\n","output_type":"stream"}],"execution_count":83},{"cell_type":"markdown","source":"## 6. 生成提交文件\n使用最佳模型对测试集进行预测，并生成提交文件。","metadata":{}},{"cell_type":"code","source":"# 使用最佳模型对测试集进行预测\ntest_predictions = ensemble_model.predict_proba(test_processed)[:, 1]\n\n# 生成提交文件\nsubmission = pd.DataFrame({'ID': test['ID'], 'prediction': test_predictions})\n\n# 确保保存到 /kaggle/working/ 目录\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\n\nprint('Submission file saved as /kaggle/working/submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:40:52.774018Z","iopub.execute_input":"2025-02-08T13:40:52.774465Z","iopub.status.idle":"2025-02-08T13:40:52.800258Z","shell.execute_reply.started":"2025-02-08T13:40:52.774420Z","shell.execute_reply":"2025-02-08T13:40:52.799064Z"}},"outputs":[{"name":"stdout","text":"Submission file saved as /kaggle/working/submission.csv\n","output_type":"stream"}],"execution_count":84},{"cell_type":"markdown","source":"## 7. 评估与优化\n根据比赛的评估指标（Stratified C-index），进一步优化模型。","metadata":{}},{"cell_type":"code","source":"# 计算分层一致性指数（Stratified C-index）\nfrom sklearn.metrics import roc_auc_score\n\n# 假设我们有一个函数来计算分层C-index\ndef stratified_c_index(y_true, y_pred, race_groups):\n    c_indices = []\n    for group in race_groups.unique():\n        group_mask = race_groups == group\n        c_index = roc_auc_score(y_true[group_mask], y_pred[group_mask])\n        c_indices.append(c_index)\n    mean_c_index = np.mean(c_indices)\n    std_c_index = np.std(c_indices)\n    return mean_c_index - std_c_index\n\n# 计算分层C-index\nrace_groups = train['race_group']\nstratified_c_index_score = stratified_c_index(y, ensemble_model.predict_proba(X_processed)[:, 1], race_groups)\nprint(f'Stratified C-index: {stratified_c_index_score}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:40:52.801346Z","iopub.execute_input":"2025-02-08T13:40:52.801692Z","iopub.status.idle":"2025-02-08T13:40:52.806283Z","shell.execute_reply.started":"2025-02-08T13:40:52.801663Z","shell.execute_reply":"2025-02-08T13:40:52.804981Z"}},"outputs":[],"execution_count":85},{"cell_type":"markdown","source":"## 下述是改进的内容","metadata":{}},{"cell_type":"code","source":"# !pip install lifelines","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:40:52.807623Z","iopub.execute_input":"2025-02-08T13:40:52.807939Z","iopub.status.idle":"2025-02-08T13:40:52.826113Z","shell.execute_reply.started":"2025-02-08T13:40:52.807902Z","shell.execute_reply":"2025-02-08T13:40:52.824834Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install lifelines\n# 终端rm -r catboost_info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T13:40:52.827356Z","iopub.execute_input":"2025-02-08T13:40:52.827719Z","iopub.status.idle":"2025-02-08T13:40:52.846987Z","shell.execute_reply.started":"2025-02-08T13:40:52.827692Z","shell.execute_reply":"2025-02-08T13:40:52.845893Z"}},"outputs":[],"execution_count":87}]}