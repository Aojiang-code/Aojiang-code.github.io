# 方案1
感谢你提供了详细的竞赛信息！根据这些信息，我为你制定了一份完整的参赛方案。这个方案将涵盖数据预处理、特征工程、模型选择、训练与调优、结果评估以及提交文件的准备。以下是详细的方案：
## 1. 数据预处理
### 1.1 数据加载
使用 Pandas 加载数据集（训练集和测试集）。
检查数据的基本信息，包括数据的形状、列名、数据类型等。
### 1.2 数据清洗
处理缺失值：检查每列的缺失值情况。对于数值型特征，可以用中位数或均值填充；对于类别型特征，可以用众数填充或使用特殊标记（如“Unknown”）。
处理异常值：对于数值型特征，检查是否有异常值（如超出合理范围的值）。可以使用箱线图或 Z-score 方法检测并处理异常值。
数据类型转换：确保所有特征的数据类型正确（例如，将类别型特征转换为字符串或分类类型）。
### 1.3 数据探索
统计分析：计算每个特征的统计量（均值、中位数、标准差等），了解数据分布。
可视化分析：绘制特征的分布图（直方图、箱线图）、相关性热力图等，了解特征之间的关系以及与目标变量的关系。
2. 特征工程
### 2.1 特征选择
基于相关性：筛选与目标变量相关性较高的特征。
基于重要性：使用树模型（如随机森林）初步评估特征重要性，选择重要性较高的特征。
### 2.2 特征转换
数值型特征：
对数值型特征进行标准化或归一化处理，以消除量纲的影响。
生成新的特征，如年龄分段、BMI 等。
类别型特征：
对类别型特征进行独热编码（One-Hot Encoding）或标签编码（Label Encoding）。
对于多类别特征，可以考虑合并稀有类别。
文本特征（如果有）：
使用 TF-IDF 或 Word2Vec 等方法将文本特征转换为数值型特征。
### 2.3 特征交互
生成特征交互项，例如两个特征的乘积、比值等，以捕捉特征之间的非线性关系。
3. 模型选择
### 3.1 基线模型
选择简单的模型（如逻辑回归、决策树）作为基线模型，评估其性能。
使用分层一致性指数（Stratified C-index）评估基线模型的性能。
### 3.2 高级模型
集成学习：随机森林、梯度提升树（如 XGBoost、LightGBM）、CatBoost 等。
深度学习：使用神经网络（如 MLP、RNN 或 Transformer）建模，尤其适用于特征维度较高或数据量较大的情况。
生存分析模型：考虑使用专门的生存分析模型，如 Cox 比例风险模型，以更好地处理生存时间和事件发生率。
4. 模型训练与调优
### 4.1 数据划分
将训练数据划分为训练集和验证集（如 80% 训练集，20% 验证集）。
使用 K 折交叉验证（如 5 折）来评估模型的稳定性和性能。
### 4.2 超参数调优
使用网格搜索（Grid Search）或随机搜索（Random Search）对模型的超参数进行调优。
使用贝叶斯优化（如 Optuna）进一步优化超参数。
### 4.3 模型融合
使用模型融合技术（如 Bagging、Boosting、Stacking）提高模型的泛化能力。
对多个模型的预测结果进行加权平均或投票，以生成最终的预测结果。
5. 结果评估
### 5.1 评估指标
使用分层一致性指数（Stratified C-index）作为主要评估指标，确保模型在不同种族群体中的公平性和准确性。
计算每个种族群体的 C-index，并计算其均值和标准差，以评估模型的分层性能。
### 5.2 模型对比
对比不同模型的性能，选择性能最优的模型。
分析模型的预测结果，检查是否存在偏差或不公平性。
6. 提交文件准备
### 6.1 生成预测结果
使用最终选择的模型对测试数据集进行预测，生成风险评分。
确保预测结果的格式符合要求（ID 和 prediction 列）。
6### .2 保存提交文件
将预测结果保存为 CSV 文件，命名为 submission.csv。
确保文件格式正确，无多余的空格或换行符。
7. 代码实现
### 7.1 示例代码
以下是基于 Python 和 Kaggle Notebook 的示例代码框架：
```Python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, KFold
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score
import xgboost as xgb
import lightgbm as lgb

# 数据加载
train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")

# 数据预处理
# 填充缺失值、特征转换等
train.fillna(train.median(), inplace=True)
test.fillna(test.median(), inplace=True)

# 特征工程
features = train.columns.drop(["ID", "target"])
X_train = train[features]
y_train = train["target"]
X_test = test[features]

# 数据划分
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# 模型选择与训练
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# 使用 XGBoost 作为示例
model = xgb.XGBClassifier()
model.fit(X_train_scaled, y_train)

# 预测与评估
y_pred = model.predict_proba(X_val_scaled)[:, 1]
print("Validation C-index:", roc_auc_score(y_val, y_pred))

# 生成提交文件
test["prediction"] = model.predict_proba(X_test_scaled)[:, 1]
test[["ID", "prediction"]].to_csv("submission.csv", index=False)
```
## 8. 注意事项
公平性：确保模型在不同种族群体中的表现公平，避免偏差。
隐私保护：竞赛使用合成数据，但仍需注意数据隐私和合规性。
代码优化：确保代码运行时间符合要求（CPU/GPU Notebook 运行时间不超过 9 小时）。
持续改进：根据模型评估结果，不断优化特征工程和模型调优。
希望这份方案能帮助你在比赛中取得好成绩！如果有任何问题或需要进一步的调整，请随时告诉我。


# 实施

好的，根据你提供的数据和比赛要求，我将为你编写一个完整的代码方案，用于处理数据、训练模型并生成预测结果。我们将使用Python和Kaggle Notebook环境来实现这个方案。
## 1. 数据加载与预处理
首先，我们需要加载数据并进行预处理，包括处理缺失值、编码类别型特征、标准化数值型特征等。
```Python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, KFold, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import roc_auc_score
import xgboost as xgb
import lightgbm as lgb
import catboost as cb

# 加载数据
train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')
data_dict = pd.read_csv('data_dictionary.csv')

# 查看数据
print(train.head())
print(test.head())
```
## 2. 数据预处理
### 2.1 处理缺失值
对于数值型特征，使用中位数填充；对于类别型特征，使用众数填充。
```Python
# 分离特征和目标变量
X = train.drop(columns=['ID', 'efs', 'efs_time'])
y = train['efs']

# 定义数值型和类别型特征
numeric_features = X.select_dtypes(include=['int64', 'float64']).columns
categorical_features = X.select_dtypes(include=['object', 'category']).columns

# 定义预处理管道
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# 应用预处理
X_processed = preprocessor.fit_transform(X)
test_processed = preprocessor.transform(test.drop(columns=['ID']))
```
## 3. 模型训练与调优
### 3.1 基线模型
使用随机森林作为基线模型。
```Python
# 划分训练集和验证集
X_train, X_val, y_train, y_val = train_test_split(X_processed, y, test_size=0.2, random_state=42)

# 训练随机森林模型
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# 验证集评估
y_pred = rf.predict_proba(X_val)[:, 1]
print(f'Validation ROC AUC: {roc_auc_score(y_val, y_pred)}')
```
### 3.2 高级模型
使用XGBoost、LightGBM和CatBoost进行训练和调优。
```Python
# import numpy as np
# import pandas as pd
# from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import StandardScaler, OneHotEncoder
# from sklearn.impute import SimpleImputer
# from sklearn.compose import ColumnTransformer
# from sklearn.pipeline import Pipeline
# from sklearn.metrics import roc_auc_score
# import xgboost as xgb
# import lightgbm as lgb
# import catboost as cb

# # 加载数据
# train = pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/train.csv')
# test = pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/test.csv')

# # 分离特征和目标变量
# X = train.drop(columns=['ID', 'efs', 'efs_time'])
# y = train['efs']

# # 定义数值型和类别型特征
# numeric_features = X.select_dtypes(include=['int64', 'float64']).columns
# categorical_features = X.select_dtypes(include=['object', 'category']).columns

# # 定义预处理管道
# numeric_transformer = Pipeline(steps=[
#     ('imputer', SimpleImputer(strategy='median')),
#     ('scaler', StandardScaler())
# ])

# categorical_transformer = Pipeline(steps=[
#     ('imputer', SimpleImputer(strategy='most_frequent')),
#     ('onehot', OneHotEncoder(handle_unknown='ignore'))
# ])

# preprocessor = ColumnTransformer(
#     transformers=[
#         ('num', numeric_transformer, numeric_features),
#         ('cat', categorical_transformer, categorical_features)
#     ])

# # 应用预处理
# X_processed = preprocessor.fit_transform(X)
# test_processed = preprocessor.transform(test.drop(columns=['ID']))

# 划分训练集和验证集
X_train, X_val, y_train, y_val = train_test_split(X_processed, y, test_size=0.2, random_state=42)

# 指定一个已存在的目录作为 train_dir
train_dir = '/kaggle/working/catboost_info'

# 确保目录存在
import os
if not os.path.exists(train_dir):
    os.makedirs(train_dir)

# XGBoost模型
xgb_model = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, random_state=42)
xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict_proba(X_val)[:, 1]
print(f'XGBoost Validation ROC AUC: {roc_auc_score(y_val, y_pred_xgb)}')

# LightGBM模型
lgb_model = lgb.LGBMClassifier(objective='binary', n_estimators=100, random_state=42)
lgb_model.fit(X_train, y_train)
y_pred_lgb = lgb_model.predict_proba(X_val)[:, 1]
print(f'LightGBM Validation ROC AUC: {roc_auc_score(y_val, y_pred_lgb)}')

# CatBoost模型
cb_model = cb.CatBoostClassifier(random_state=42, verbose=0, train_dir=train_dir)
cb_model.fit(X_train, y_train)
y_pred_cb = cb_model.predict_proba(X_val)[:, 1]
print(f'CatBoost Validation ROC AUC: {roc_auc_score(y_val, y_pred_cb)}')
```
### 4. 超参数调优
使用GridSearchCV对XGBoost进行超参数调优。
```Python
param_grid = {
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'n_estimators': [100, 200, 300]
}

grid_search = GridSearchCV(estimator=xgb.XGBClassifier(objective='binary:logistic', random_state=42),
                           param_grid=param_grid,
                           scoring='roc_auc',
                           cv=5,
                           verbose=1)

grid_search.fit(X_train, y_train)
print(f'Best parameters: {grid_search.best_params_}')
print(f'Best ROC AUC: {grid_search.best_score_}')

# 使用最佳参数重新训练
best_xgb_model = grid_search.best_estimator_
y_pred_best_xgb = best_xgb_model.predict_proba(X_val)[:, 1]
print(f'Best XGBoost Validation ROC AUC: {roc_auc_score(y_val, y_pred_best_xgb)}')
```
## 5. 模型融合
使用模型融合技术提高预测性能。
```Python
# 模型融合
from sklearn.ensemble import VotingClassifier

ensemble_model = VotingClassifier(estimators=[
    ('rf', rf),
    ('xgb', best_xgb_model),
    ('lgb', lgb_model),
    ('cb', cb_model)
], voting='soft')

ensemble_model.fit(X_train, y_train)
y_pred_ensemble = ensemble_model.predict_proba(X_val)[:, 1]
print(f'Ensemble Validation ROC AUC: {roc_auc_score(y_val, y_pred_ensemble)}')
```
## 6. 生成提交文件
使用最佳模型对测试集进行预测，并生成提交文件。
```Python
# 使用最佳模型对测试集进行预测
test_predictions = ensemble_model.predict_proba(test_processed)[:, 1]

# 生成提交文件
submission = pd.DataFrame({'ID': test['ID'], 'prediction': test_predictions})
submission.to_csv('submission.csv', index=False)

print('Submission file saved as submission.csv')
```
## 7. 评估与优化
根据比赛的评估指标（Stratified C-index），进一步优化模型。
```Python
# 使用最佳模型对测试集进行预测
test_predictions = ensemble_model.predict_proba(test_processed)[:, 1]

# 生成提交文件
submission = pd.DataFrame({'ID': test['ID'], 'prediction': test_predictions})

# 确保保存到 /kaggle/working/ 目录
submission.to_csv('/kaggle/working/submission.csv', index=False)

print('Submission file saved as /kaggle/working/submission.csv')
```


## 修改

### 1. 安装lifelines库：
在Kaggle环境中，你需要安装lifelines库。在代码中添加以下行：
```Python
!pip install lifelines
```
### 2. 定义score函数：
将大赛举办方提供的score函数直接到你的代码中：
```Python
import pandas as pd
import pandas.api.types
import numpy as np
from lifelines.utils import concordance_index

class ParticipantVisibleError(Exception):
    pass

def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:
    del solution[row_id_column_name]
    del submission[row_id_column_name]
    
    event_label = 'efs'
    interval_label = 'efs_time'
    prediction_label = 'prediction'
    
    for col in submission.columns:
        if not pandas.api.types.is_numeric_dtype(submission[col]):
            raise ParticipantVisibleError(f'Submission column {col} must be a number')
    
    # Merging solution and submission dfs on ID
    merged_df = pd.concat([solution, submission], axis=1)
    merged_df.reset_index(inplace=True)
    merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)
    metric_list = []
    
    for race in merged_df_race_dict.keys():
        # Retrieving values from y_test based on index
        indices = sorted(merged_df_race_dict[race])
        merged_df_race = merged_df.iloc[indices]
        # Calculate the concordance index
        c_index_race = concordance_index(
                        merged_df_race[interval_label],
                        -merged_df_race[prediction_label],
                        merged_df_race[event_label])
        metric_list.append(c_index_race)
    
    return float(np.mean(metric_list) - np.sqrt(np.var(metric_list)))
```
### 3. 调整验证集的评估方式：
在验证集上，你需要将y_val（包含efs、efs_time和race_group）和预测结果y_pred_val合并，然后调用score函数：
```Python

# 准备验证集的解决方案和提交数据
val_solution = y_val.copy().reset_index(drop=True)
val_submission = pd.DataFrame({'prediction': y_pred_val}).reset_index(drop=True)

# 计算验证集的分层一致性指数
val_score = score(val_solution, val_submission, 'index')
print(f'Validation Stratified C-index: {val_score}')
```
### 4. 生成提交文件：
在测试集上，你需要将预测结果保存到submission.csv文件中。这部分代码不需要修改，但需要确保文件路径正确：
```Python

# 使用最佳模型对测试集进行预测
test_predictions = ensemble_model.predict_proba(test_processed)[:, 1]

# 生成提交文件
submission = pd.DataFrame({'ID': test['ID'], 'prediction': test_predictions})

# 确保保存到 /kaggle/working/ 目录
submission.to_csv('/kaggle/working/submission.csv', index=False)

print('Submission file saved as /kaggle/working/submission.csv')
```

### 完整代码

```python
# 安装 lifelines 库
!pip install lifelines

import pandas as pd
import numpy as np
from lifelines.utils import concordance_index

# 加载数据
train = pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/train.csv')
test = pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/test.csv')

# 分离特征和目标变量
X = train.drop(columns=['ID', 'efs', 'efs_time'])
y = train[['efs', 'efs_time', 'race_group']]

# 定义数值型和类别型特征
numeric_features = X.select_dtypes(include=['int64', 'float64']).columns
categorical_features = X.select_dtypes(include=['object', 'category']).columns

# 定义预处理管道
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# 应用预处理
X_processed = preprocessor.fit_transform(X)
test_processed = preprocessor.transform(test.drop(columns=['ID']))

# 划分训练集和验证集
from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(X_processed, y, test_size=0.2, random_state=42)

# 训练模型
import xgboost as xgb

xgb_model = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, random_state=42)
xgb_model.fit(X_train, y_train['efs'])

# 验证集预测
y_pred_val = xgb_model.predict_proba(X_val)[:, 1]

# 定义 score 函数
def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:
    del solution[row_id_column_name]
    del submission[row_id_column_name]
    
    event_label = 'efs'
    interval_label = 'efs_time'
    prediction_label = 'prediction'
    
    for col in submission.columns:
        if not pd.api.types.is_numeric_dtype(submission[col]):
            raise ParticipantVisibleError(f'Submission column {col} must be a number')
    
    # Merging solution and submission dfs on ID
    merged_df = pd.concat([solution, submission], axis=1)
    merged_df.reset_index(inplace=True)
    merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)
    metric_list = []
    
    for race in merged_df_race_dict.keys():
        # Retrieving values from y_test based on index
        indices = sorted(merged_df_race_dict[race])
        merged_df_race = merged_df.iloc[indices]
        # Calculate the concordance index
        c_index_race = concordance_index(
                        merged_df_race[interval_label],
                        -merged_df_race[prediction_label],
                        merged_df_race[event_label])
        metric_list.append(c_index_race)
    
    return float(np.mean(metric_list) - np.sqrt(np.var(metric_list)))

# 准备验证集的解决方案和提交数据
val_solution = y_val.copy().reset_index(drop=True)
val_submission = pd.DataFrame({'prediction': y_pred_val}).reset_index(drop=True)

# 计算验证集的分层一致性指数
val_score = score(val_solution, val_submission, 'index')
print(f'Validation Stratified C-index: {val_score}')

# 使用最佳模型对测试集进行预测
test_predictions = xgb_model.predict_proba(test_processed)[:, 1]

# 生成提交文件
submission = pd.DataFrame({'ID': test['ID'], 'prediction': test_predictions})

# 确保保存到 /kaggle/working/ 目录
submission.to_csv('/kaggle/working/submission.csv', index=False)

print('Submission file saved as /kaggle/working/submission.csv')
```


## 总结
以上代码涵盖了数据预处理、模型训练、超参数调优、模型融合以及生成提交文件的完整流程。你可以根据比赛的具体要求和数据特点进一步调整和优化代码。希望这份代码能帮助你在比赛中取得好成绩！如果有任何问题，请随时告诉我。
