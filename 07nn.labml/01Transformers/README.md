# Transformers

This module contains PyTorch implementations and explanations of original transformer from paper [Attention Is All You Need](), and derivatives and enhancements of it.


- [Multi-head attention]() 
  - [多头注意力]()
- [Transformer Encoder and Decoder Models]()
  - [变压器编解码器模型]()
- [Position-wise Feed Forward Network (FFN)]()
  - [位置前馈网络(FFN)]()
- [Fixed positional encoding]()
  - [固定位置编码]()







