# Transformers

This module contains PyTorch implementations and explanations of original transformer from paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762), and derivatives and enhancements of it.


- [Multi-head attention]() 
  - [多头注意力](07nn.labml\01Transformers\001多头注意力/)
- [Transformer Encoder and Decoder Models]()
  - [变压器编解码器模型](07nn.labml\01Transformers\002变压器编解码器模型/)
- [Position-wise Feed Forward Network (FFN)]()
  - [位置前馈网络(FFN)](07nn.labml\01Transformers\003位置前馈网络(FFN))
- [Fixed positional encoding]()
  - [固定位置编码](07nn.labml\01Transformers\004固定位置编码)









