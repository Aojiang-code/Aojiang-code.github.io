# å¯è§£é‡Šçš„æœºå™¨å­¦ä¹ æ¨¡å‹ç”¨äºé¢„æµ‹è€å¹´ ICU æ‚£è€…æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»çš„å‘ç”Ÿç‡

Interpretable machine learning models for predicting the incidence of antibiotic- associated diarrhea in elderly ICU patients




## ä¸€ã€æ–‡çŒ®ä¿¡æ¯




| é¡¹ç›® | å†…å®¹ |
| ---- | ---- |
| æ ‡é¢˜ | å¯è§£é‡Šçš„æœºå™¨å­¦ä¹ æ¨¡å‹ç”¨äºé¢„æµ‹è€å¹´ICUæ‚£è€…æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»çš„å‘ç”Ÿç‡ |
| ä½œè€… | Yating Cui, Yibo Zhou, Chao Liu, Zhi Mao, Feihu Zhou |
| å‘è¡¨æ—¶é—´ | 2024å¹´ |
| å›½å®¶ | ä¸­å›½ |
| åˆ†åŒº | æœªæ³¨æ˜ï¼ˆå¯è¿›ä¸€æ­¥æŸ¥è¯¢BMC Geriatricsåˆ†åŒºï¼‰ |
| å½±å“å› å­ | æœªæ³¨æ˜ï¼ˆå¯æŸ¥è¯¢BMC Geriatricsæœ€æ–°å½±å“å› å­ï¼‰ |
| æ‘˜è¦ | æœ¬ç ”ç©¶æ„å»ºäº†åŸºäºXGBoostå’ŒSHAPæ–¹æ³•çš„é¢„æµ‹æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹è€å¹´ICUæ‚£è€…æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»çš„å‘ç”Ÿç‡ï¼Œæ¨¡å‹å…·æœ‰è‰¯å¥½çš„é¢„æµ‹æ€§èƒ½å’Œå¯è§£é‡Šæ€§ã€‚ |
| å…³é”®è¯ | æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»ï¼›ICUï¼›è€å¹´äººï¼›XGBoostï¼›å¯è§£é‡Šçš„æœºå™¨å­¦ä¹  |
| æœŸåˆŠåç§° | BMC Geriatrics |
| å·å·/æœŸå· | ç¬¬24å·ï¼Œç¬¬458æœŸ |
| DOI | [10.1186/s12877-024-05028-8](https://doi.org/10.1186/s12877-024-05028-8) |
| ç ”ç©¶æ–¹æ³• | å›é¡¾æ€§å•ä¸­å¿ƒç ”ç©¶ï¼Œé‡‡ç”¨XGBoostã€LASSOã€SHAPç­‰æœºå™¨å­¦ä¹ æ–¹æ³•è¿›è¡Œå˜é‡ç­›é€‰ä¸æ¨¡å‹æ„å»º |
| æ•°æ®æ¥æº | ä¸­å›½äººæ°‘è§£æ”¾å†›æ€»åŒ»é™¢ç¬¬ä¸€åŒ»å­¦ä¸­å¿ƒICUæ‚£è€…ï¼ˆ2020å¹´1æœˆè‡³2022å¹´6æœˆï¼‰ |
| ç ”ç©¶ç»“æœ | XGBoostæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„AUCä¸º0.917ï¼Œä¼˜äºLogisticå›å½’ã€SVMã€KNNå’Œæœ´ç´ è´å¶æ–¯ç­‰æ¨¡å‹ã€‚ |
| ç ”ç©¶ç»“è®º | æ„å»ºçš„XGBoostæ¨¡å‹èƒ½å¤Ÿè¾ƒå‡†ç¡®åœ°é¢„æµ‹è€å¹´ICUæ‚£è€…å‘ç”ŸAADçš„é£é™©ï¼Œä¸”é€šè¿‡SHAPå®ç°äº†è‰¯å¥½çš„æ¨¡å‹å¯è§£é‡Šæ€§ã€‚ |
| ç ”ç©¶æ„ä¹‰ | æœ‰åŠ©äºåŒ»ç”Ÿåœ¨æ‚£è€…å…¥ICUåˆæœŸå³è¯†åˆ«å‡ºé«˜é£é™©äººç¾¤ï¼Œè¿›è¡Œæ—©æœŸå¹²é¢„ï¼Œå‡å°‘ä½é™¢æ—¶é•¿ä¸åŒ»ç–—æˆæœ¬ï¼Œæé«˜è€å¹´æ‚£è€…çš„æ²»ç–—æ•ˆç‡ä¸é¢„åã€‚ |

---

æœŸåˆŠåç§°ï¼šBMC Geriatrics
å½±å“å› å­ï¼š3.40
JCRåˆ†åŒºï¼šQ2
ä¸­ç§‘é™¢åˆ†åŒº(2025)ï¼šåŒ»å­¦2åŒº
å°ç±»ï¼šè€å¹´åŒ»å­¦2åŒºÂ è€å¹´åŒ»å­¦ï¼ˆç¤¾ç§‘ï¼‰2åŒº
ä¸­ç§‘é™¢åˆ†åŒº(2023)ï¼šåŒ»å­¦2åŒºÂ Top
å°ç±»ï¼šè€å¹´åŒ»å­¦2åŒºÂ è€å¹´åŒ»å­¦2åŒº
OPEN ACCESSï¼š99.88%
å‡ºç‰ˆå‘¨æœŸï¼šæš‚æ— æ•°æ®
æ˜¯å¦ç»¼è¿°ï¼šå¦
é¢„è­¦ç­‰çº§ï¼šæ— 
å¹´åº¦|å½±å“å› å­|å‘æ–‡é‡|è‡ªå¼•ç‡
2023 | 3.40 | 854 | 5.9%
2022 | 4.10 | 975 | 7.3%
2021 | 4.07 | 711 | 6.4%
2020 | 3.92 | 534 | 5.5%
2019 | 3.08 | 378 | 5.7%



## ğŸ“Œ **æ ¸å¿ƒå†…å®¹**


æœ¬ç ”ç©¶æ—¨åœ¨æ„å»ºä¸€ä¸ª**å¯è§£é‡Šçš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆXGBoostï¼‰**ï¼Œç”¨äºé¢„æµ‹**è€å¹´é‡ç—‡ç›‘æŠ¤ç—…æˆ¿ï¼ˆICUï¼‰æ‚£è€…å‘ç”ŸæŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»ï¼ˆAADï¼‰**çš„é£é™©ï¼Œå¹¶å€ŸåŠ©**SHAPæ–¹æ³•**æå‡æ¨¡å‹é€æ˜åº¦ä¸ä¸´åºŠä¿¡ä»»åº¦ã€‚

---

### ğŸ“– **ä¸»è¦å†…å®¹**
1. **ç ”ç©¶èƒŒæ™¯**ï¼šæŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»åœ¨ICUè€å¹´æ‚£è€…ä¸­å‘ç—…ç‡è¾ƒé«˜ï¼Œå½±å“ä¸¥é‡ï¼Œæ—©æœŸé¢„æµ‹å’Œå¹²é¢„å…·æœ‰é‡è¦æ„ä¹‰ã€‚

2. **ç ”ç©¶å¯¹è±¡ä¸æ•°æ®**ï¼šå›é¡¾åˆ†æä¸­å›½äººæ°‘è§£æ”¾å†›æ€»åŒ»é™¢ç¬¬ä¸€åŒ»å­¦ä¸­å¿ƒICUå†…848å60å²åŠä»¥ä¸ŠæŠ—ç”Ÿç´ æ²»ç–—æ‚£è€…ï¼ˆ2020.1â€“2022.6ï¼‰ï¼Œå‰”é™¤åŸºç¡€æ€§è…¹æ³»æˆ–è‚¿ç˜¤æœ¯åç­‰å› ç´ ã€‚

3. **å»ºæ¨¡æ–¹æ³•**ï¼š
   - åˆ©ç”¨**LASSOå›å½’**ä»37ä¸ªå˜é‡ä¸­ç­›é€‰å‡º10ä¸ªæ˜¾è‘—å½±å“å› å­ï¼ˆå¦‚CRPã€Hbã€è‚ å†…è¥å…»ã€ä¸‡å¤éœ‰ç´ ç­‰ï¼‰ã€‚
   - æ„å»ºå¹¶æ¯”è¾ƒ5ç§æ¨¡å‹ï¼ˆXGBoostã€Logisticå›å½’ã€SVMã€KNNã€æœ´ç´ è´å¶æ–¯ï¼‰ï¼Œå…¶ä¸­XGBoostè¡¨ç°æœ€ä½³ï¼ˆAUC = 0.917ï¼‰ã€‚
   - é‡‡ç”¨**SHAPè§£é‡Šæœºåˆ¶**å¯¹æ¨¡å‹ç»“æœè¿›è¡Œè§£é‡Šï¼Œæä¾›å˜é‡å¯¹é¢„æµ‹ç»“æœçš„å½±å“æ–¹å‘ä¸ç¨‹åº¦ã€‚

4. **ç ”ç©¶ç»“æœ**ï¼š
   - XGBoostæ¨¡å‹åœ¨å‡†ç¡®ç‡ã€çµæ•åº¦ã€F1å€¼ç­‰å„æŒ‡æ ‡ä¸Šå‡ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚
   - é«˜å±å› ç´ åŒ…æ‹¬ï¼šè‚ å†…è¥å…»ã€CRPå‡é«˜ã€PCTå‡é«˜ã€ä½¿ç”¨ä¸‡å¤éœ‰ç´ ã€è¡€çº¢è›‹ç™½é™ä½ç­‰ã€‚

5. **ç ”ç©¶æ„ä¹‰**ï¼š
   - æ‰€æ„å»ºçš„æ¨¡å‹å¯å®ç°å¯¹AADé£é™©çš„æ—©æœŸè¯†åˆ«ï¼Œæ”¯æŒä¸´åºŠä¸ªä½“åŒ–å†³ç­–ã€‚
   - æ¨¡å‹çš„å¯è§£é‡Šæ€§å¢å¼ºäº†å…¶ä¸´åºŠåº”ç”¨çš„å¯ä¿¡åº¦å’Œå¯æ¥å—æ€§ã€‚

---


## ä¸‰ã€æ–‡ç« å°ç»“


### **1. Abstractï¼ˆæ‘˜è¦ï¼‰**
æœ¬ç ”ç©¶åˆ©ç”¨XGBoostä¸SHAPæ–¹æ³•æ„å»ºå¹¶è§£é‡Šäº†ä¸€ä¸ªé¢„æµ‹è€å¹´ICUæ‚£è€…å‘ç”ŸæŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»ï¼ˆAADï¼‰é£é™©çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚æ¨¡å‹å…·å¤‡è‰¯å¥½çš„é¢„æµ‹æ€§èƒ½ï¼ˆAUC=0.917ï¼‰ï¼Œä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå¹¶å…·æœ‰è¾ƒå¼ºçš„å¯è§£é‡Šæ€§ã€‚

---

### **2. Backgroundï¼ˆèƒŒæ™¯ï¼‰**
æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»æ˜¯è€å¹´ICUæ‚£è€…ä¸­å¸¸è§çš„å¹¶å‘ç—‡ï¼Œä¸»è¦ç”±äºè€å¹´äººè‚ é“èŒç¾¤æ˜“ç´Šä¹±ã€è‚ é“å±éšœåŠŸèƒ½å‡å¼±ã€‚AADä¼šå»¶é•¿ä½é™¢æ—¶é—´ã€å¢åŠ è´¹ç”¨ã€ç”šè‡³æé«˜æ­»äº¡ç‡ã€‚å› æ­¤äºŸéœ€å¯ç”¨äºä¸´åºŠçš„é¢„æµ‹å·¥å…·ï¼Œä»¥æ—©æœŸè¯†åˆ«é«˜é£é™©äººç¾¤ã€‚

---

### **3. Methodsï¼ˆæ–¹æ³•ï¼‰**

#### 3.1 Study Populationï¼ˆç ”ç©¶å¯¹è±¡ï¼‰
åˆ†æäº†2020å¹´1æœˆåˆ°2022å¹´6æœˆæœŸé—´ä¸­å›½äººæ°‘è§£æ”¾å†›æ€»åŒ»é™¢ç¬¬ä¸€åŒ»å­¦ä¸­å¿ƒICUå†…ç¬¦åˆæ¡ä»¶çš„848å60å²ä»¥ä¸Šè€å¹´æ‚£è€…ã€‚

#### 3.2 Groupingï¼ˆåˆ†ç»„ï¼‰
æ ¹æ®æ˜¯å¦å‘ç”ŸAADè¿›è¡Œåˆ†ç»„ï¼Œä¾æ®ä¸´åºŠæ ‡å‡†åˆ¤å®šè…¹æ³»ç—‡çŠ¶ï¼Œæ’é™¤éæŠ—ç”Ÿç´ å¼•èµ·çš„è…¹æ³»ç—…ä¾‹ã€‚

#### 3.3 Data Extractionï¼ˆæ•°æ®æå–ï¼‰
æå–å…¥ICUå‰24å°æ—¶å†…çš„åŸºæœ¬ç‰¹å¾ã€æ²»ç–—ä¿¡æ¯ã€å®éªŒå®¤æŒ‡æ ‡åŠç”¨è¯ä¿¡æ¯ã€‚è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬APACHE IIå’ŒSOFAè¯„åˆ†ã€‚å…±æå–äº†37ä¸ªå˜é‡ã€‚

---

### **4. Resultsï¼ˆç»“æœï¼‰**

#### 4.1 Baseline Characteristicsï¼ˆåŸºçº¿ç‰¹å¾ï¼‰
è®­ç»ƒé›†ä¸æµ‹è¯•é›†ä¸­AADå‘ç”Ÿç‡åˆ†åˆ«ä¸º22.32%å’Œ21.82%ã€‚AADç»„æ‚£è€…æ›´é¢‘ç¹ä½¿ç”¨RRTã€è‚ å†…è¥å…»ï¼Œä¸”PCTã€CRPç­‰ç‚ç—‡æŒ‡æ ‡æ˜¾è‘—å‡é«˜ã€‚

#### 4.2 Modelingï¼ˆå»ºæ¨¡ï¼‰
ä½¿ç”¨LASSOç­›é€‰å‡º10ä¸ªå…³é”®å˜é‡ï¼Œä½¿ç”¨XGBoostã€Logisticå›å½’ã€SVMã€KNNå’Œæœ´ç´ è´å¶æ–¯å»ºæ¨¡ã€‚XGBooståœ¨æ‰€æœ‰æŒ‡æ ‡ä¸­è¡¨ç°æœ€ä½³ã€‚

#### 4.3 Model Evaluationï¼ˆæ¨¡å‹è¯„ä¼°ï¼‰
XGBoostçš„AUCä¸º0.917ï¼Œå‡†ç¡®ç‡ä¸º0.87ï¼Œä¼˜äºå…¶ä»–æ¨¡å‹ã€‚DCAå’ŒBrier Scoreè¿›ä¸€æ­¥æ”¯æŒXGBoostæ¨¡å‹åœ¨ä¸´åºŠåº”ç”¨ä¸­çš„ä¼˜è¶Šæ€§ã€‚

#### 4.4 Model Interpretationï¼ˆæ¨¡å‹è§£é‡Šï¼‰
é€šè¿‡SHAPæ–¹æ³•å±•ç¤ºäº†æ¨¡å‹å¯¹å˜é‡çš„æ•æ„Ÿæ€§å’Œæ–¹å‘æ€§ã€‚é«˜CRPã€PCTã€è‚ å†…è¥å…»ã€ä¸‡å¤éœ‰ç´ ä½¿ç”¨ç­‰ç‰¹å¾æé«˜äº†AADé¢„æµ‹æ¦‚ç‡ï¼›ä½Hbã€ä½PLTã€ä½Pæ°´å¹³ä¹Ÿä¸AADç›¸å…³ã€‚SHAPå€¼å›¾å’Œä¾èµ–å›¾å±•ç¤ºäº†å˜é‡ä¸é£é™©ä¹‹é—´çš„å…·ä½“å…³ç³»ã€‚

---

### **5. Discussionï¼ˆè®¨è®ºï¼‰**
XGBoostæ¨¡å‹ä½¿ç”¨çš„æ•°æ®ç‰¹å¾å®¹æ˜“è·å–ï¼Œé¢„æµ‹æ€§èƒ½ä¼˜è¶Šã€‚SHAPè§£é‡Šå¢å¼ºäº†æ¨¡å‹å¯ä¿¡åº¦ã€‚ç ”ç©¶å‘ç°é•‡é™é•‡ç—›è¯å¦‚ä¸™æ³Šé…šã€ä¸ä¸™è¯ºå•¡å¯èƒ½é™ä½AADé£é™©ï¼Œè€Œå¹¿è°±æŠ—ç”Ÿç´ å¦‚ä¸‡å¤éœ‰ç´ ã€åˆ©å¥ˆå”‘èƒºä¸AADå‘ç”Ÿé«˜åº¦ç›¸å…³ã€‚ç ”ç©¶å°šå­˜å±€é™ï¼Œå¦‚æ ·æœ¬é‡è¾ƒå°ã€ç¼ºä¹å¤–éƒ¨éªŒè¯ï¼Œéƒ¨åˆ†è¯ç‰©ä½¿ç”¨æœªå®Œå…¨è€ƒè™‘ã€‚

---

### **6. Conclusionï¼ˆç»“è®ºï¼‰**
è¯¥ç ”ç©¶æˆåŠŸæ„å»ºäº†ä¸€ä¸ªåŸºäºå¯è§£é‡Šæ€§æœºå™¨å­¦ä¹ çš„AADé¢„æµ‹æ¨¡å‹ï¼Œèƒ½è¾…åŠ©åŒ»ç”Ÿè¯†åˆ«é«˜é£é™©è€å¹´ICUæ‚£è€…ï¼Œä¼˜åŒ–æŠ—ç”Ÿç´ ä½¿ç”¨ç­–ç•¥å’Œæ—©æœŸå¹²é¢„ï¼Œä»è€Œæ”¹å–„ä¸´åºŠé¢„åã€‚

---

## å››ã€ğŸ§ª æ–¹æ³•ä¸å®æ–½è®¡åˆ’ï¼ˆMethodsï¼‰

æœ¬ç ”ç©¶è®¾è®¡ä¸º**å•ä¸­å¿ƒã€çºµå‘ã€å›é¡¾æ€§é˜Ÿåˆ—ç ”ç©¶**ï¼Œä¸¥æ ¼éµå¾ªTRIPODæŠ¥å‘Šè§„èŒƒï¼Œä½¿ç”¨ä¸­å›½äººæ°‘è§£æ”¾å†›æ€»åŒ»é™¢ç¬¬ä¸€åŒ»å­¦ä¸­å¿ƒICUçš„ä¸´åºŠæ•°æ®æ„å»ºé¢„æµ‹æ¨¡å‹ã€‚

---

### 1ï¸âƒ£ **ç ”ç©¶å¯¹è±¡ç­›é€‰ï¼ˆStudy Populationï¼‰**

#### âœ… **çº³å…¥æ ‡å‡†**
- å¹´é¾„ â‰¥60å²ï¼›
- å…¥ICU 7å¤©å†…ä½¿ç”¨è¿‡æŠ—ç”Ÿç´ ï¼›
- å…¥ICUæ—¶æ— è…¹æ³»ç—‡çŠ¶ã€‚

#### âŒ **æ’é™¤æ ‡å‡†**
- ICUä½é™¢æ—¶é—´â‰¤2å¤©ï¼›
- ä¸´ç»ˆå…³æ€€/å§‘æ¯æ²»ç–—ï¼›
- å…¥é™¢å³æœ‰è…¹æ³»æˆ–æ—¢å¾€æ¶ˆåŒ–ç³»ç»Ÿç–¾ç—…ï¼ˆå¦‚IBSã€ç¼ºè¡€æ€§è‚ ç—…ç­‰ï¼‰ï¼›
- èƒƒè‚ æœ¯åï¼ˆå¦‚é€ å£ï¼‰æ‚£è€…ï¼›
- ä¸´åºŠä¿¡æ¯ç¼ºå¤±ä¸¥é‡è€…ã€‚

> ğŸ’¡ **å…±çº³å…¥848åæ‚£è€…ã€‚**

---

### 2ï¸âƒ£ **åˆ†ç»„æ ‡å‡†ï¼ˆGroupingï¼‰**

æŒ‰ç…§**æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»ï¼ˆAADï¼‰è¯Šæ–­æ ‡å‡†**è¿›è¡Œåˆ†ç»„ï¼š

- **AADç»„**ï¼šå…¥é™¢å‰æ— è…¹æ³»ï¼Œä½¿ç”¨æŠ—ç”Ÿç´ åå‡ºç°3æ¬¡åŠä»¥ä¸Šæ°´æ ·ä¾¿ï¼Œä¼´æœ‰å‘çƒ­ã€è…¹ç—›ç­‰ç—‡çŠ¶ï¼Œå¹¶æ’é™¤å…¶ä»–ç—…å› ï¼›
- **å¯¹ç…§ç»„**ï¼šä¸ç¬¦åˆä¸Šè¿°æ¡ä»¶çš„æ‚£è€…ã€‚

---

### 3ï¸âƒ£ **æ•°æ®æå–ä¸å˜é‡è¯´æ˜ï¼ˆData Extractionï¼‰**

#### ğŸ“Œ **æ—¶é—´çª—å£**
- **åŸºæœ¬ä¿¡æ¯**ï¼šå…¥ICUå24å°æ—¶å†…ï¼›
- **æ²»ç–—ä¸ç”¨è¯ä¿¡æ¯**ï¼šå…¥ICUå7å¤©å†…ã€‚

#### ğŸ“‹ **å˜é‡ç§ç±»**
- **äººå£ç»Ÿè®¡å­¦å˜é‡**ï¼šå¹´é¾„ã€æ€§åˆ«ã€BMIï¼›
- **æ²»ç–—å¹²é¢„**ï¼šæœºæ¢°é€šæ°”ã€è‚¾è„æ›¿ä»£æ²»ç–—ï¼ˆRRTï¼‰ã€è‚ å†…è¥å…»ï¼›
- **å®éªŒå®¤æ£€æŸ¥**ï¼šè¡€çº¢è›‹ç™½ï¼ˆHbï¼‰ã€CRPã€IL-6ã€PCTã€è¡€å°æ¿ã€ç™½è›‹ç™½ã€è‚Œé…ã€ç£·ã€è„‚è‚ªé…¶ç­‰ï¼›
- **è¯ç‰©ä½¿ç”¨**ï¼šè¦†ç›–å¸¸ç”¨æŠ—ç”Ÿç´ ï¼ˆå¤´å­¢ä»–å•¶ã€ç¾æ´›åŸ¹å—ã€ä¸‡å¤éœ‰ç´ ã€åˆ©å¥ˆå”‘èƒºç­‰ï¼‰ã€æŠ—çœŸèŒè¯ã€é•‡é™é•‡ç—›è¯ï¼ˆä¸™æ³Šé…šã€ä¸ä¸™è¯ºå•¡ç­‰ï¼‰ï¼›
- **ç–¾ç—…ä¸¥é‡ç¨‹åº¦è¯„åˆ†**ï¼šAPACHE IIã€SOFAï¼›
- **ç»“å±€å˜é‡**ï¼šICUä½é™¢æ—¶é—´ã€ICUæ­»äº¡ç‡ã€‚

---

### 4ï¸âƒ£ **æ•°æ®é¢„å¤„ç†**

- å¯¹ç¼ºå¤±å€¼å¤§äº40%çš„å˜é‡è¿›è¡Œå‰”é™¤ï¼›
- å¯¹å‰©ä½™ç¼ºå¤±å€¼ç”¨**ä¸­ä½æ•°æ’è¡¥**ï¼›
- æ•°æ®é›†æŒ‰ç…§7:3æ¯”ä¾‹éšæœºåˆ†ä¸ºè®­ç»ƒé›†ï¼ˆ70%ï¼‰ä¸æµ‹è¯•é›†ï¼ˆ30%ï¼‰ã€‚

---

### 5ï¸âƒ£ **å˜é‡ç­›é€‰ä¸å»ºæ¨¡è¿‡ç¨‹**

#### ğŸ” **å˜é‡é€‰æ‹©ï¼šLASSO å›å½’**
- å°†37ä¸ªå€™é€‰å˜é‡è¾“å…¥LASSOäºŒåˆ†ç±»é€»è¾‘å›å½’æ¨¡å‹ï¼›
- ä½¿ç”¨5æŠ˜äº¤å‰éªŒè¯é€‰å®šæ­£åˆ™åŒ–å‚æ•°Î»ï¼›
- ç­›é€‰å‡º10ä¸ªæ˜¾è‘—å½±å“AADå‘ç”Ÿçš„å˜é‡ã€‚

#### ğŸ¤– **æ¨¡å‹æ„å»ºï¼š5ç§æœºå™¨å­¦ä¹ æ–¹æ³•**
- **XGBoostï¼ˆæç«¯æ¢¯åº¦æå‡ï¼‰**
- **Logisticå›å½’ï¼ˆLRï¼‰**
- **æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰**
- **Kè¿‘é‚»ç®—æ³•ï¼ˆKNNï¼‰**
- **æœ´ç´ è´å¶æ–¯ï¼ˆNBï¼‰**

##### XGBoostæ¨¡å‹å‚æ•°ï¼š
- å­¦ä¹ ç‡ï¼ˆlearning rateï¼‰ï¼š0.1ï¼›
- æ ‘çš„æœ€å¤§æ·±åº¦ï¼š3ï¼›
- è¿­ä»£æ ‘æ•°é‡ï¼š20ï¼›
- å…¶ä»–ä¸ºé»˜è®¤å€¼ã€‚

---

### 6ï¸âƒ£ **æ¨¡å‹è¯„ä¼°æŒ‡æ ‡**

- **AUCï¼ˆROCæ›²çº¿ä¸‹é¢ç§¯ï¼‰**
- **æ•æ„Ÿåº¦ï¼ˆSensitivityï¼‰**
- **ç‰¹å¼‚åº¦ï¼ˆSpecificityï¼‰**
- **å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**
- **F1åˆ†æ•°**ï¼ˆå¹³è¡¡ç²¾åº¦å’Œå¬å›ç‡ï¼‰
- **Brieråˆ†æ•°**ï¼ˆæ ¡å‡†åº¦è¯„ä¼°ï¼‰
- **DCAï¼ˆå†³ç­–æ›²çº¿åˆ†æï¼‰**
- **KæŠ˜äº¤å‰éªŒè¯åˆ†æ•°åŠæ ‡å‡†è¯¯**

---

### 7ï¸âƒ£ **æ¨¡å‹è§£é‡Šï¼šSHAPæ–¹æ³•ï¼ˆShapley Additive Explanationsï¼‰**

- è¯„ä¼°æ¯ä¸ªå˜é‡å¯¹æ¨¡å‹è¾“å‡ºçš„æ­£è´Ÿè´¡çŒ®ï¼›
- ç”Ÿæˆ**å˜é‡é‡è¦æ€§æ’åºå›¾**å’Œ**SHAPä¾èµ–å›¾**ï¼›
- æä¾›å…·ä½“æ ·æœ¬é¢„æµ‹å€¼çš„è§£é‡Šç¤ºä¾‹ï¼Œæ˜¾ç¤ºå“ªäº›ç‰¹å¾æ¨åŠ¨é¢„æµ‹ä¸Šå‡æˆ–ä¸‹é™ï¼›
- å¢å¼ºæ¨¡å‹çš„é€æ˜åº¦ä¸å¯ä¸´åºŠä¿¡ä»»æ€§ã€‚

---

## âœ… æ€»ç»“
è¯¥ç ”ç©¶æ–¹æ³•æ¸…æ™°ã€ä¸¥è°¨ï¼Œç»“åˆ**çœŸå®ä¸´åºŠæ•°æ®+å¤šæ¨¡å‹å¯¹æ¯”+å¯è§£é‡Šæœºåˆ¶ï¼ˆSHAPï¼‰**ï¼Œä¸ä»…æé«˜äº†é¢„æµ‹å‡†ç¡®ç‡ï¼Œè¿˜å¤§å¤§å¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œä¸´åºŠä»·å€¼ã€‚å¯ä¸ºæœªæ¥ç±»ä¼¼åŒ»ç–—AIæ¨¡å‹è®¾è®¡æä¾›æ ‡å‡†å‚è€ƒæµç¨‹ã€‚

---


## äº”ã€é‡è¦å˜é‡å’Œæ•°æ®(è‹±æ–‡å±•ç¤º)
ä»¥ä¸‹æ˜¯æ ¹æ®æ–‡çŒ®æ•´ç†çš„ä¸»è¦å˜é‡ä¿¡æ¯ï¼Œåˆ†ä¸º**è¿ç»­å˜é‡**ï¼ˆå«ä¸­ä½æ•°å’Œå››åˆ†ä½æ•°ï¼‰ä¸**åˆ†ç±»å˜é‡**ï¼ˆå«é¢‘æ•°ä¸æ¯”ä¾‹ï¼‰ä¸¤éƒ¨åˆ†ï¼š

---

### ğŸ“Š è¿ç»­å˜é‡ï¼ˆContinuous Variablesï¼‰

| Variable | Group | Median (IQR) |
|----------|--------|-------------------|
| age | Non-AAD (train) | 73.0 (66.0â€“81.0) |
| age | AAD (train) | 74.0 (67.5â€“82.5) |
| age | Non-AAD (test) | 74.0 (68.0â€“82.0) |
| age | AAD (test) | 75.0 (67.5â€“82.0) |
| BMI | Non-AAD (train) | 23.8 (21.3â€“25.6) |
| BMI | AAD (train) | 23.8 (22.6â€“25.0) |
| BMI | Non-AAD (test) | 23.2 (20.8â€“24.6) |
| BMI | AAD (test) | 23.8 (21.0â€“25.6) |
| Hb | Non-AAD (train) | 107.0 (92.0â€“122.0) |
| Hb | AAD (train) | 95.0 (83.5â€“109.0) |
| Hb | Non-AAD (test) | 103.0 (91.0â€“116.0) |
| Hb | AAD (test) | 93.0 (83.5â€“109.0) |
| CRP | Non-AAD (train) | 1.2 (0.2â€“3.9) |
| CRP | AAD (train) | 3.5 (1.3â€“7.9) |
| CRP | Non-AAD (test) | 1.4 (0.3â€“4.2) |
| CRP | AAD (test) | 3.9 (1.6â€“8.9) |
| PCT | Non-AAD (train) | 0.1 (0.1â€“0.6) |
| PCT | AAD (train) | 0.8 (0.2â€“2.2) |
| PCT | Non-AAD (test) | 0.1 (0.1â€“0.7) |
| PCT | AAD (test) | 1.2 (0.2â€“3.2) |
| Scr | Non-AAD (train) | 72.0 (54.9â€“92.1) |
| Scr | AAD (train) | 80.2 (57.8â€“106.6) |
| Scr | Non-AAD (test) | 69.8 (56.0â€“87.4) |
| Scr | AAD (test) | 88.1 (66.0â€“118.6) |

---

### ğŸ“‹ åˆ†ç±»å˜é‡ï¼ˆCategorical Variablesï¼‰

| Variable | Group | Frequency | Percentage |
|----------|--------|-----------|------------|
| Male | Non-AAD (train) | 260 | 56.9% |
| Male | AAD (train) | 83 | 59.7% |
| Male | Non-AAD (test) | 108 | 54.8% |
| Male | AAD (test) | 32 | 58.2% |
| RRT | Non-AAD (train) | 31 | 6.8% |
| RRT | AAD (train) | 23 | 16.5% |
| RRT | Non-AAD (test) | 10 | 5.1% |
| RRT | AAD (test) | 14 | 25.5% |
| Enteral nutrition | Non-AAD (train) | 137 | 30.0% |
| Enteral nutrition | AAD (train) | 103 | 74.1% |
| Enteral nutrition | Non-AAD (test) | 59 | 29.9% |
| Enteral nutrition | AAD (test) | 39 | 70.9% |

---


## äº”ã€é‡è¦å˜é‡å’Œæ•°æ®(ä¸­æ–‡å±•ç¤º)

---

### ğŸ“Š è¿ç»­å˜é‡ï¼ˆContinuous Variablesï¼‰

| å˜é‡ | åˆ†ç»„ | ä¸­ä½æ•°ï¼ˆå››åˆ†ä½è·ï¼‰ |
|------|------|----------------------|
| å¹´é¾„ï¼ˆageï¼‰ | éAADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 73.0ï¼ˆ66.0â€“81.0ï¼‰ |
| å¹´é¾„ï¼ˆageï¼‰ | AADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 74.0ï¼ˆ67.5â€“82.5ï¼‰ |
| å¹´é¾„ï¼ˆageï¼‰ | éAADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 74.0ï¼ˆ68.0â€“82.0ï¼‰ |
| å¹´é¾„ï¼ˆageï¼‰ | AADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 75.0ï¼ˆ67.5â€“82.0ï¼‰ |
| ä½“é‡æŒ‡æ•°ï¼ˆBMIï¼‰ | éAADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 23.8ï¼ˆ21.3â€“25.6ï¼‰ |
| ä½“é‡æŒ‡æ•°ï¼ˆBMIï¼‰ | AADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 23.8ï¼ˆ22.6â€“25.0ï¼‰ |
| ä½“é‡æŒ‡æ•°ï¼ˆBMIï¼‰ | éAADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 23.2ï¼ˆ20.8â€“24.6ï¼‰ |
| ä½“é‡æŒ‡æ•°ï¼ˆBMIï¼‰ | AADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 23.8ï¼ˆ21.0â€“25.6ï¼‰ |
| è¡€çº¢è›‹ç™½ï¼ˆHbï¼‰ | éAADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 107.0ï¼ˆ92.0â€“122.0ï¼‰ |
| è¡€çº¢è›‹ç™½ï¼ˆHbï¼‰ | AADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 95.0ï¼ˆ83.5â€“109.0ï¼‰ |
| è¡€çº¢è›‹ç™½ï¼ˆHbï¼‰ | éAADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 103.0ï¼ˆ91.0â€“116.0ï¼‰ |
| è¡€çº¢è›‹ç™½ï¼ˆHbï¼‰ | AADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 93.0ï¼ˆ83.5â€“109.0ï¼‰ |
| Cååº”è›‹ç™½ï¼ˆCRPï¼‰ | éAADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 1.2ï¼ˆ0.2â€“3.9ï¼‰ |
| Cååº”è›‹ç™½ï¼ˆCRPï¼‰ | AADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 3.5ï¼ˆ1.3â€“7.9ï¼‰ |
| Cååº”è›‹ç™½ï¼ˆCRPï¼‰ | éAADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 1.4ï¼ˆ0.3â€“4.2ï¼‰ |
| Cååº”è›‹ç™½ï¼ˆCRPï¼‰ | AADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 3.9ï¼ˆ1.6â€“8.9ï¼‰ |
| é™é’™ç´ åŸï¼ˆPCTï¼‰ | éAADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 0.1ï¼ˆ0.1â€“0.6ï¼‰ |
| é™é’™ç´ åŸï¼ˆPCTï¼‰ | AADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 0.8ï¼ˆ0.2â€“2.2ï¼‰ |
| é™é’™ç´ åŸï¼ˆPCTï¼‰ | éAADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 0.1ï¼ˆ0.1â€“0.7ï¼‰ |
| é™é’™ç´ åŸï¼ˆPCTï¼‰ | AADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 1.2ï¼ˆ0.2â€“3.2ï¼‰ |
| è¡€è‚Œé…ï¼ˆScrï¼‰ | éAADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 72.0ï¼ˆ54.9â€“92.1ï¼‰ |
| è¡€è‚Œé…ï¼ˆScrï¼‰ | AADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 80.2ï¼ˆ57.8â€“106.6ï¼‰ |
| è¡€è‚Œé…ï¼ˆScrï¼‰ | éAADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 69.8ï¼ˆ56.0â€“87.4ï¼‰ |
| è¡€è‚Œé…ï¼ˆScrï¼‰ | AADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 88.1ï¼ˆ66.0â€“118.6ï¼‰ |

---

### ğŸ“‹ åˆ†ç±»å˜é‡ï¼ˆCategorical Variablesï¼‰

| å˜é‡ | åˆ†ç»„ | é¢‘æ•° | ç™¾åˆ†æ¯” |
|------|------|------|--------|
| ç”·æ€§ï¼ˆMaleï¼‰ | éAADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 260 | 56.9% |
| ç”·æ€§ï¼ˆMaleï¼‰ | AADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 83 | 59.7% |
| ç”·æ€§ï¼ˆMaleï¼‰ | éAADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 108 | 54.8% |
| ç”·æ€§ï¼ˆMaleï¼‰ | AADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 32 | 58.2% |
| è‚¾è„æ›¿ä»£æ²»ç–—ï¼ˆRRTï¼‰ | éAADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 31 | 6.8% |
| è‚¾è„æ›¿ä»£æ²»ç–—ï¼ˆRRTï¼‰ | AADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 23 | 16.5% |
| è‚¾è„æ›¿ä»£æ²»ç–—ï¼ˆRRTï¼‰ | éAADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 10 | 5.1% |
| è‚¾è„æ›¿ä»£æ²»ç–—ï¼ˆRRTï¼‰ | AADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 14 | 25.5% |
| è‚ å†…è¥å…»ï¼ˆEnteral nutritionï¼‰ | éAADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 137 | 30.0% |
| è‚ å†…è¥å…»ï¼ˆEnteral nutritionï¼‰ | AADç»„ï¼ˆè®­ç»ƒé›†ï¼‰ | 103 | 74.1% |
| è‚ å†…è¥å…»ï¼ˆEnteral nutritionï¼‰ | éAADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 59 | 29.9% |
| è‚ å†…è¥å…»ï¼ˆEnteral nutritionï¼‰ | AADç»„ï¼ˆæµ‹è¯•é›†ï¼‰ | 39 | 70.9% |

---


## å…­ã€æ¨¡æ‹Ÿæ•°æ®
å¥½çš„ï¼ä¸‹é¢æ˜¯æ‰©å±•åçš„å®Œæ•´ä»£ç ç‰ˆæœ¬ï¼ŒåŒ…å«ï¼š

- âœ… **è®­ç»ƒé›†æ•°æ®**ï¼ˆn=596ï¼Œå…¶ä¸­ AAD ç»„ 139 äººï¼‰
- âœ… **æµ‹è¯•é›†æ•°æ®**ï¼ˆn=252ï¼Œå…¶ä¸­ AAD ç»„ 55 äººï¼‰
- âœ… è¿ç»­å˜é‡ï¼šæ ¹æ®ä¸­ä½æ•°å’Œ IQR æ¨¡æ‹Ÿæ­£æ€åˆ†å¸ƒæ•°æ®
- âœ… åˆ†ç±»å˜é‡ï¼šæ ¹æ®é¢‘ç‡æŒ‰æ¯”ä¾‹éšæœºç”Ÿæˆ
- âœ… è‡ªåŠ¨ç”Ÿæˆå¹¶åˆ†åˆ«ä¿å­˜ä¸º CSV æ–‡ä»¶

---

### ğŸ“ æ–‡ä»¶ç»“æ„
```plaintext
04æ–‡çŒ®é˜…è¯»/
â””â”€â”€ 09ICU/
    â””â”€â”€ 01æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»/
        â””â”€â”€ 01æ¨¡æ‹Ÿæ•°æ®/
            â””â”€â”€ data/
                â”œâ”€â”€ aad_icu_train.csv
                â””â”€â”€ aad_icu_test.csv
```

---

### ğŸ Pythonä»£ç ï¼š**simulate_aad_icu_data.py**

```python
import numpy as np
import pandas as pd
import os

np.random.seed(42)

def simulate_from_iqr(median, q1, q3, size):
    std_approx = (q3 - q1) / 1.35
    return np.random.normal(loc=median, scale=std_approx, size=size)

def simulate_group_data(group_info, size_total, size_aad):
    size_non_aad = size_total - size_aad
    df_data = {}

    # è¿ç»­å˜é‡
    for var, ((med_non, q1_non, q3_non), (med_aad, q1_aad, q3_aad)) in group_info["continuous"].items():
        df_data[var] = np.concatenate([
            simulate_from_iqr(med_non, q1_non, q3_non, size_non_aad),
            simulate_from_iqr(med_aad, q1_aad, q3_aad, size_aad)
        ])

    # åˆ†ç±»å˜é‡
    for var, ((pos_non, total_non), (pos_aad, total_aad)) in group_info["categorical"].items():
        neg_non = total_non - pos_non
        neg_aad = total_aad - pos_aad
        df_data[var] = np.concatenate([
            np.random.choice([1, 0], size=total_non, p=[pos_non/total_non, neg_non/total_non]),
            np.random.choice([1, 0], size=total_aad, p=[pos_aad/total_aad, neg_aad/total_aad])
        ])

    # æ ‡ç­¾
    df_data["AAD"] = np.array([0]*size_non_aad + [1]*size_aad)
    return pd.DataFrame(df_data)

# è¿ç»­å˜é‡ä¿¡æ¯ï¼šä¸­ä½æ•° (Q1, Q3)ï¼Œè®­ç»ƒé›†ä¸æµ‹è¯•é›†
continuous_info = {
    "age": [(73.0, 66.0, 81.0), (74.0, 67.5, 82.5)],
    "BMI": [(23.8, 21.3, 25.6), (23.8, 22.6, 25.0)],
    "Hb": [(107.0, 92.0, 122.0), (95.0, 83.5, 109.0)],
    "CRP": [(1.2, 0.2, 3.9), (3.5, 1.3, 7.9)],
    "PCT": [(0.1, 0.1, 0.6), (0.8, 0.2, 2.2)],
    "Scr": [(72.0, 54.9, 92.1), (80.2, 57.8, 106.6)]
}

categorical_info_train = {
    "Male": [(260, 457), (83, 139)],
    "RRT": [(31, 457), (23, 139)],
    "Enteral_nutrition": [(137, 457), (103, 139)]
}

categorical_info_test = {
    "Male": [(108, 197), (32, 55)],
    "RRT": [(10, 197), (14, 55)],
    "Enteral_nutrition": [(59, 197), (39, 55)]
}

# æ¨¡æ‹Ÿè®­ç»ƒé›†
group_train = {
    "continuous": continuous_info,
    "categorical": categorical_info_train
}
df_train = simulate_group_data(group_train, size_total=596, size_aad=139)

# æ¨¡æ‹Ÿæµ‹è¯•é›†ï¼ˆæ•°å€¼ä¸åŒï¼‰
continuous_info_test = {
    "age": [(74.0, 68.0, 82.0), (75.0, 67.5, 82.0)],
    "BMI": [(23.2, 20.8, 24.6), (23.8, 21.0, 25.6)],
    "Hb": [(103.0, 91.0, 116.0), (93.0, 83.5, 109.0)],
    "CRP": [(1.4, 0.3, 4.2), (3.9, 1.6, 8.9)],
    "PCT": [(0.1, 0.1, 0.7), (1.2, 0.2, 3.2)],
    "Scr": [(69.8, 56.0, 87.4), (88.1, 66.0, 118.6)]
}

group_test = {
    "continuous": continuous_info_test,
    "categorical": categorical_info_test
}
df_test = simulate_group_data(group_test, size_total=252, size_aad=55)

# ä¿å­˜è·¯å¾„
output_path = "04æ–‡çŒ®é˜…è¯»/09ICU/01æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»/01æ¨¡æ‹Ÿæ•°æ®/data"
os.makedirs(output_path, exist_ok=True)
df_train.to_csv(os.path.join(output_path, "aad_icu_train.csv"), index=False)
df_test.to_csv(os.path.join(output_path, "aad_icu_test.csv"), index=False)

print("âœ… æ¨¡æ‹Ÿæ•°æ®å·²ä¿å­˜ä¸ºï¼šaad_icu_train.csv ä¸ aad_icu_test.csv")
```

---


## ä¸ƒã€å¯è§†åŒ–ç»Ÿè®¡æè¿°ï¼ˆå¦‚ç®±çº¿å›¾ã€åˆ†å¸ƒå›¾ã€ç›¸å…³æ€§çƒ­å›¾ç­‰ï¼‰
---

### ğŸ“Œ è„šæœ¬åç§°ï¼š**analyze_aad_icu_simulated_data.py**

æ­¤è„šæœ¬å°†å®Œæˆä»¥ä¸‹åŠŸèƒ½ï¼š

1. âœ… **è¯»å–è®­ç»ƒé›†ä¸æµ‹è¯•é›†æ•°æ®å¹¶åˆå¹¶ä¸ºä¸€ä¸ªæ€»è¡¨**ï¼›
2. ğŸ“Š ç”Ÿæˆä»¥ä¸‹å¯è§†åŒ–å›¾è¡¨ï¼ˆç¾è§‚ã€é€‚åˆè®ºæ–‡/å±•ç¤ºï¼‰ï¼š
   - **ç®±çº¿å›¾ï¼ˆBoxplotï¼‰**ï¼šå±•ç¤ºè¿ç»­å˜é‡çš„åˆ†å¸ƒä¸æå€¼ï¼›
   - **ç›´æ–¹å›¾ï¼ˆHistogramï¼‰**ï¼šæŸ¥çœ‹å˜é‡åˆ†å¸ƒæ˜¯å¦åæ€ï¼›
   - **å°æç´å›¾ï¼ˆViolin plotï¼‰**ï¼šå¢åŠ åˆ†å¸ƒå¯†åº¦ä¿¡æ¯ï¼›
   - **ç›¸å…³æ€§çƒ­å›¾ï¼ˆHeatmapï¼‰**ï¼šè¿ç»­å˜é‡ä¹‹é—´çš„ç›¸å…³ç³»æ•°ï¼›
3. ğŸ“¥ ä¿å­˜ä¸º PNG å›¾ç‰‡æ–‡ä»¶ï¼Œæ–¹ä¾¿å†™ä½œæˆ–å¯¼å…¥PPTï¼›

---

### ğŸ Python ä»£ç ï¼š**analyze_aad_icu_simulated_data.py**

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

# è®¾ç½®å›¾å½¢é£æ ¼
sns.set(style="whitegrid", font_scale=1.2)

# è·¯å¾„è®¾ç½®
base_path = "04æ–‡çŒ®é˜…è¯»/09ICU/01æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»/01æ¨¡æ‹Ÿæ•°æ®/data"
train_path = os.path.join(base_path, "aad_icu_train.csv")
test_path = os.path.join(base_path, "aad_icu_test.csv")

# è¯»å–æ•°æ®å¹¶åˆå¹¶
df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)
df_train["dataset"] = "train"
df_test["dataset"] = "test"
df_all = pd.concat([df_train, df_test], ignore_index=True)

# ä¿å­˜åˆå¹¶åçš„æ•°æ®
df_all.to_csv(os.path.join(base_path, "aad_icu_all.csv"), index=False)

# åˆ›å»ºå›¾åƒä¿å­˜ç›®å½•
img_path = os.path.join(base_path, "figures")
os.makedirs(img_path, exist_ok=True)

# å˜é‡åˆ†ç»„
continuous_vars = ["age", "BMI", "Hb", "CRP", "PCT", "Scr"]
categorical_vars = ["Male", "RRT", "Enteral_nutrition"]

# 1. ç®±çº¿å›¾ï¼šå±•ç¤ºè¿ç»­å˜é‡çš„åˆ†å¸ƒ
for var in continuous_vars:
    plt.figure(figsize=(8, 5))
    sns.boxplot(x="AAD", y=var, data=df_all, palette="Set2")
    plt.title(f"Boxplot of {var} by AAD")
    plt.xlabel("AAD (0 = No, 1 = Yes)")
    plt.savefig(os.path.join(img_path, f"boxplot_{var}.png"), dpi=300)
    plt.close()

# 2. å°æç´å›¾ï¼ˆViolin Plotï¼‰
for var in continuous_vars:
    plt.figure(figsize=(8, 5))
    sns.violinplot(x="AAD", y=var, data=df_all, palette="Set3", inner="quartile")
    plt.title(f"Violin Plot of {var} by AAD")
    plt.savefig(os.path.join(img_path, f"violin_{var}.png"), dpi=300)
    plt.close()

# 3. è¿ç»­å˜é‡åˆ†å¸ƒç›´æ–¹å›¾ï¼ˆæŒ‰ AAD åˆ†ç»„ï¼‰
for var in continuous_vars:
    plt.figure(figsize=(8, 5))
    sns.histplot(data=df_all, x=var, hue="AAD", kde=True, palette="coolwarm", element="step", common_norm=False)
    plt.title(f"Distribution of {var} by AAD")
    plt.savefig(os.path.join(img_path, f"hist_{var}.png"), dpi=300)
    plt.close()

# 4. ç›¸å…³æ€§çƒ­å›¾ï¼ˆä»…å¯¹è¿ç»­å˜é‡ï¼‰
plt.figure(figsize=(10, 8))
corr_matrix = df_all[continuous_vars].corr()
sns.heatmap(corr_matrix, annot=True, cmap="YlGnBu", square=True)
plt.title("Correlation Heatmap of Continuous Variables")
plt.savefig(os.path.join(img_path, "heatmap_continuous_vars.png"), dpi=300)
plt.close()

print("âœ… å¯è§†åŒ–åˆ†æå®Œæˆï¼Œå›¾åƒå·²ä¿å­˜è‡³ figures æ–‡ä»¶å¤¹")
```

---

### ğŸ—‚ è¾“å‡ºå†…å®¹é¢„è§ˆ
æ‚¨å°†åœ¨ä»¥ä¸‹è·¯å¾„ä¸­è·å¾—è¿™äº›æ–‡ä»¶ï¼š

```
04æ–‡çŒ®é˜…è¯»/09ICU/01æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»/01æ¨¡æ‹Ÿæ•°æ®/data/
â”œâ”€â”€ aad_icu_all.csv
â””â”€â”€ figures/
    â”œâ”€â”€ boxplot_age.png
    â”œâ”€â”€ violin_Hb.png
    â”œâ”€â”€ hist_CRD.png
    â”œâ”€â”€ heatmap_continuous_vars.png
    â””â”€â”€ ...ï¼ˆå…±18+å›¾åƒï¼‰
```

---


## å…«ã€å¤ç°ä»£ç 
æ ¹æ®ä¸Šè¿°çš„æ–¹æ³•ä¸å®æ–½è®¡åˆ’ï¼Œè®¾è®¡äº†ä¸€å¥—å®Œæ•´çš„Pythonä»£ç ï¼Œç”¨äº**å¤ç°æ–‡çŒ®ä¸­å»ºæ¨¡æ€è·¯å’Œé¢„æµ‹æµç¨‹**ï¼ŒåŒ…æ‹¬æ•°æ®è¯»å–ã€LASSOå˜é‡ç­›é€‰ã€äº”ç§æ¨¡å‹æ„å»ºå¯¹æ¯”ã€XGBoostå‚æ•°è®¾ç½®ä¸SHAPå¯è§£é‡Šåˆ†æç­‰æ­¥éª¤ã€‚

---

### ğŸ“Œ è„šæœ¬åç§°ï¼š**reproduce_aad_icu_model.py**

---

### ğŸ Python ä»£ç ï¼ˆå¯ç›´æ¥è¿è¡Œï¼‰

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression, LassoCV
from sklearn.metrics import (
    roc_auc_score, accuracy_score, recall_score, precision_score, f1_score,
    brier_score_loss, confusion_matrix, roc_curve
)
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
import xgboost as xgb
import shap
import matplotlib.pyplot as plt
import seaborn as sns
import os

# è®¾ç½®è·¯å¾„ä¸è¯»å–æ•°æ®
data_path = "04æ–‡çŒ®é˜…è¯»/09ICU/01æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»/01æ¨¡æ‹Ÿæ•°æ®/data/aad_icu_all.csv"
df = pd.read_csv(data_path)

# ç‰¹å¾ä¸æ ‡ç­¾åˆ†ç¦»
X = df.drop(columns=["AAD", "dataset"])
y = df["AAD"]

# æ ‡å‡†åŒ–å¤„ç†ï¼ˆå¿…è¦ï¼‰
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# LASSO ç‰¹å¾é€‰æ‹©
lasso = LassoCV(cv=5, random_state=42).fit(X_scaled, y)
coef = pd.Series(lasso.coef_, index=df.drop(columns=["AAD", "dataset"]).columns)
selected_features = coef[coef != 0].index.tolist()

print("âœ… LASSO é€‰ä¸­çš„å˜é‡ï¼š", selected_features)

# ä½¿ç”¨é€‰ä¸­çš„ç‰¹å¾å»ºæ¨¡
X_selected = df[selected_features]
X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42, stratify=y)

# äº”ç§æ¨¡å‹
models = {
    "LogisticRegression": LogisticRegression(max_iter=1000),
    "SVM": SVC(probability=True),
    "KNN": KNeighborsClassifier(),
    "NaiveBayes": GaussianNB(),
    "XGBoost": xgb.XGBClassifier(
        learning_rate=0.1, max_depth=3, n_estimators=20, use_label_encoder=False, eval_metric="logloss"
    )
}

# æ¨¡å‹è¯„ä¼°å‡½æ•°
def evaluate_model(name, model, X_train, y_train, X_test, y_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1]

    results = {
        "Model": name,
        "AUC": roc_auc_score(y_test, y_prob),
        "Accuracy": accuracy_score(y_test, y_pred),
        "Sensitivity": recall_score(y_test, y_pred),
        "Specificity": recall_score(y_test, y_pred, pos_label=0),
        "F1 Score": f1_score(y_test, y_pred),
        "Brier Score": brier_score_loss(y_test, y_prob)
    }
    return results, model

results_list = []
trained_models = {}

for name, model in models.items():
    res, fitted_model = evaluate_model(name, model, X_train, y_train, X_test, y_test)
    results_list.append(res)
    trained_models[name] = fitted_model

# è¾“å‡ºç»“æœ
results_df = pd.DataFrame(results_list)
print("\nğŸ“Š æ¨¡å‹æ€§èƒ½æ¯”è¾ƒï¼š")
print(results_df)

# ä¿å­˜æ€§èƒ½è¡¨æ ¼
output_path = "04æ–‡çŒ®é˜…è¯»/09ICU/01æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»/01æ¨¡æ‹Ÿæ•°æ®/data"
results_df.to_csv(os.path.join(output_path, "model_evaluation.csv"), index=False)

# SHAP å¯è§£é‡Šåˆ†æï¼ˆä»…å¯¹XGBoostï¼‰
xgb_model = trained_models["XGBoost"]
explainer = shap.Explainer(xgb_model, X_selected)
shap_values = explainer(X_selected)

# å˜é‡é‡è¦æ€§å›¾
shap.summary_plot(shap_values, X_selected, show=False)
plt.title("SHAP Feature Importance - XGBoost")
plt.tight_layout()
plt.savefig(os.path.join(output_path, "shap_summary_plot.png"), dpi=300)
plt.close()

# ç¤ºä¾‹è§£é‡Šå›¾
shap.plots.waterfall(shap_values[0], show=False)
plt.title("SHAP Waterfall Example (Sample 0)")
plt.tight_layout()
plt.savefig(os.path.join(output_path, "shap_waterfall_sample0.png"), dpi=300)

print("âœ… SHAP å¯è§£é‡Šå›¾å·²ç”Ÿæˆå¹¶ä¿å­˜")

# KæŠ˜äº¤å‰éªŒè¯
cv_scores = cross_val_score(xgb_model, X_selected, y, cv=5, scoring="roc_auc")
print(f"\nâœ… KæŠ˜äº¤å‰éªŒè¯AUCå‡å€¼ï¼š{cv_scores.mean():.3f} Â± {cv_scores.std():.3f}")
```

---

### ğŸ—‚ è„šæœ¬è¾“å‡ºå†…å®¹åŒ…æ‹¬ï¼š

- `model_evaluation.csv`ï¼šäº”ç§æ¨¡å‹æ€§èƒ½æŒ‡æ ‡æ±‡æ€»è¡¨ï¼›
- `shap_summary_plot.png`ï¼šXGBoostå˜é‡é‡è¦æ€§æ’åå›¾ï¼›
- `shap_waterfall_sample0.png`ï¼šå•ä¸ªæ ·æœ¬é¢„æµ‹è§£é‡Šå›¾ï¼›
- å‘½ä»¤è¡Œæ‰“å°ï¼šLASSOç­›é€‰çš„å˜é‡ + æ¨¡å‹AUC/F1ç­‰æŒ‡æ ‡ + KæŠ˜éªŒè¯ç»“æœã€‚

---

## ä¹ã€ Jupyter Notebook æ¼”ç¤ºæ–‡æ¡£

ä»¥ä¸‹æ˜¯å°†æ‚¨è¯·æ±‚çš„å†…å®¹æ•´ç†ä¸º**Jupyter Notebook** æ¼”ç¤ºæ–‡æ¡£çš„ç‰ˆæœ¬ï¼Œæ¶µç›–ï¼š

---

### ğŸ““ Notebook åç§°ï¼š**å¤ç°æ–‡çŒ®æ¨¡å‹ï¼šæŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»é¢„æµ‹æ¨¡å‹.ipynb**

---

## åã€ âœ… Notebook å¤§çº²ç»“æ„

```markdown
# æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»é¢„æµ‹æ¨¡å‹ï¼šåŸºäºå¯è§£é‡Šæœºå™¨å­¦ä¹ æ–¹æ³•çš„å¤ç°åˆ†æ

## 1. èƒŒæ™¯ä»‹ç»
ç®€è¦è¯´æ˜AADåœ¨è€å¹´ICUæ‚£è€…ä¸­çš„ä¸´åºŠæ„ä¹‰ã€æ–‡çŒ®ä¸­çš„ç ”ç©¶ç›®æ ‡ä¸æ–¹æ³•ã€‚

## 2. æ•°æ®è¯»å–ä¸å‡†å¤‡
- è¯»å–æ¨¡æ‹Ÿæ•°æ®
- åˆæ­¥è§‚å¯Ÿä¸å˜é‡æ¸…æ´—

## 3. LASSOå˜é‡é€‰æ‹©
- æ ‡å‡†åŒ–å¤„ç†
- LassoCVå˜é‡ç­›é€‰
- è¾“å‡ºå˜é‡é€‰æ‹©ç»“æœ

## 4. æ„å»ºä¸æ¯”è¾ƒæœºå™¨å­¦ä¹ æ¨¡å‹
- æ„å»º5ç§æ¨¡å‹ï¼ˆXGBoost, LR, SVM, KNN, NBï¼‰
- æ¨¡å‹è¯„ä¼°ï¼ˆAUCã€å‡†ç¡®ç‡ã€æ•æ„Ÿåº¦ã€F1ç­‰ï¼‰
- ç»“æœè¡¨æ ¼å±•ç¤º

## 5. SHAPå¯è§£é‡Šæ€§åˆ†æï¼ˆXGBoostï¼‰
- ç‰¹å¾é‡è¦æ€§å›¾
- å•æ ·æœ¬é¢„æµ‹è§£é‡Šå›¾

## 6. KæŠ˜äº¤å‰éªŒè¯è¯„ä¼°
- è¾“å‡ºå¹³å‡AUCä¸æ ‡å‡†å·®

## 7. æ€»ç»“
- å¯¹å¤ç°ç»“æœçš„ç®€è¦è¯„ä»·
```

---

### ğŸ Notebook å¯¼å‡ºä»£ç 

ä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥å¤åˆ¶ç²˜è´´åˆ° `.ipynb` æ–‡ä»¶ä¸­çš„å…³é”®å†…å®¹ï¼Œå»ºè®®é…åˆ [JupyterLab](https://jupyter.org/) æˆ– VS Code ä½¿ç”¨ï¼š

```python
# æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»é¢„æµ‹æ¨¡å‹ï¼šåŸºäºå¯è§£é‡Šæœºå™¨å­¦ä¹ æ–¹æ³•çš„å¤ç°åˆ†æ

## 1. å¯¼å…¥åº“ä¸è¯»å–æ•°æ®
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression, LassoCV
from sklearn.metrics import (
    roc_auc_score, accuracy_score, recall_score, precision_score, f1_score,
    brier_score_loss
)
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
import xgboost as xgb
import shap
import matplotlib.pyplot as plt
import seaborn as sns
import os

sns.set(style="whitegrid", font_scale=1.2)

# è®¾ç½®è·¯å¾„ä¸è¯»å–æ•°æ®
data_path = "04æ–‡çŒ®é˜…è¯»/09ICU/01æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»/01æ¨¡æ‹Ÿæ•°æ®/data/aad_icu_all.csv"
df = pd.read_csv(data_path)
df.head()
```

```python
## 2. LASSOå˜é‡é€‰æ‹©
X = df.drop(columns=["AAD", "dataset"])
y = df["AAD"]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

lasso = LassoCV(cv=5, random_state=42).fit(X_scaled, y)
coef = pd.Series(lasso.coef_, index=X.columns)
selected_features = coef[coef != 0].index.tolist()

print("é€‰ä¸­çš„ç‰¹å¾ï¼š", selected_features)
```

```python
## 3. æ„å»ºä¸è®­ç»ƒæ¨¡å‹
X_selected = df[selected_features]
X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, stratify=y, random_state=42)

models = {
    "LogisticRegression": LogisticRegression(max_iter=1000),
    "SVM": SVC(probability=True),
    "KNN": KNeighborsClassifier(),
    "NaiveBayes": GaussianNB(),
    "XGBoost": xgb.XGBClassifier(learning_rate=0.1, max_depth=3, n_estimators=20, use_label_encoder=False, eval_metric="logloss")
}

results = []

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1]
    results.append({
        "Model": name,
        "AUC": roc_auc_score(y_test, y_prob),
        "Accuracy": accuracy_score(y_test, y_pred),
        "Sensitivity": recall_score(y_test, y_pred),
        "Specificity": recall_score(y_test, y_pred, pos_label=0),
        "F1": f1_score(y_test, y_pred),
        "Brier": brier_score_loss(y_test, y_prob)
    })

results_df = pd.DataFrame(results)
results_df.sort_values("AUC", ascending=False)
```

```python
## 4. SHAPè§£é‡Šåˆ†æ
explainer = shap.Explainer(models["XGBoost"], X_selected)
shap_values = explainer(X_selected)

shap.summary_plot(shap_values, X_selected)
```

```python
## 5. SHAP waterfallè§£é‡Šå•ä¸ªæ ·æœ¬
shap.plots.waterfall(shap_values[0])
```

```python
## 6. KæŠ˜äº¤å‰éªŒè¯
xgb_model = models["XGBoost"]
cv_auc = cross_val_score(xgb_model, X_selected, y, cv=5, scoring="roc_auc")
print(f"XGBoost 5æŠ˜AUCå‡å€¼: {cv_auc.mean():.3f} Â± {cv_auc.std():.3f}")
```

---



# åŸºäºXGBoostçš„è€å¹´ICUæ‚£è€…æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»é¢„æµ‹æ¨¡å‹å¤ç°æŠ¥å‘Š

## ä¸€ã€ç ”ç©¶èƒŒæ™¯

æŠ—ç”Ÿç´ ç›¸å…³æ€§è…¹æ³»ï¼ˆAntibiotic-Associated Diarrhea, AADï¼‰æ˜¯è€å¹´é‡ç—‡ç›‘æŠ¤ç—…æˆ¿ï¼ˆICUï¼‰æ‚£è€…å¸¸è§çš„å¹¶å‘ç—‡ï¼Œæ˜¾è‘—å¢åŠ ä½é™¢æ—¶é•¿å’Œæ­»äº¡é£é™©ã€‚ä¸ºæå‡ä¸´åºŠè¯†åˆ«æ•ˆç‡ï¼Œè¿‘å¹´æ¥é€æ¸é‡‡ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•å»ºç«‹é£é™©é¢„æµ‹æ¨¡å‹ã€‚æœ¬æ–‡å¤ç°ä¸€ç¯‡åŸºäºXGBoostä¸SHAPè§£é‡Šæœºåˆ¶çš„ç ”ç©¶æ–¹æ³•ï¼Œåˆ©ç”¨æ¨¡æ‹Ÿæ•°æ®å¯¹æ¨¡å‹è¿›è¡Œé‡å»ºä¸åˆ†æã€‚

---

## äºŒã€æ•°æ®è¯´æ˜

### 2.1 æ•°æ®æ¥æº
æ•°æ®æ¥æºäºæ–‡çŒ®æ¨¡æ‹Ÿç»“æœï¼ŒåŒ…å«è®­ç»ƒé›†ï¼ˆn=596ï¼‰å’Œæµ‹è¯•é›†ï¼ˆn=252ï¼‰ï¼Œå…±848åè€å¹´ICUæ‚£è€…çš„æ•°æ®ï¼Œå­—æ®µåŒ…æ‹¬ï¼š
- äººå£ç»Ÿè®¡å­¦ç‰¹å¾ï¼šå¹´é¾„ï¼ˆageï¼‰ã€æ€§åˆ«ï¼ˆMaleï¼‰ã€ä½“é‡æŒ‡æ•°ï¼ˆBMIï¼‰ç­‰ï¼›
- ä¸´åºŠæ²»ç–—ä¿¡æ¯ï¼šè‚ å†…è¥å…»ï¼ˆEnteral_nutritionï¼‰ã€è‚¾è„æ›¿ä»£æ²»ç–—ï¼ˆRRTï¼‰ï¼›
- å®éªŒå®¤æŒ‡æ ‡ï¼šè¡€çº¢è›‹ç™½ï¼ˆHbï¼‰ã€Cååº”è›‹ç™½ï¼ˆCRPï¼‰ã€é™é’™ç´ åŸï¼ˆPCTï¼‰ã€è‚Œé…ï¼ˆScrï¼‰ï¼›
- æ ‡ç­¾å˜é‡ï¼šæ˜¯å¦å‘ç”ŸAADã€‚

### 2.2 æ•°æ®é¢„å¤„ç†
- å¯¹æ‰€æœ‰è¿ç»­å˜é‡è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼›
- åˆ é™¤ç¼ºå¤±å€¼è¶…è¿‡40%çš„å˜é‡ï¼Œä¿ç•™æœ‰æ•ˆç‰¹å¾ï¼›
- ä¾æ®70%:30%æ¯”ä¾‹åˆ’åˆ†è®­ç»ƒé›†ä¸æµ‹è¯•é›†ã€‚

---

## ä¸‰ã€æ–¹æ³•ä¸å®æ–½æµç¨‹

### 3.1 ç‰¹å¾é€‰æ‹©
ä½¿ç”¨LASSOï¼ˆæœ€å°ç»å¯¹æ”¶ç¼©ä¸é€‰æ‹©ç®—å­ï¼‰å›å½’æ–¹æ³•å¯¹37ä¸ªåˆå§‹å˜é‡è¿›è¡Œç­›é€‰ï¼Œç»“åˆ5æŠ˜äº¤å‰éªŒè¯é€‰å®šæ­£åˆ™åŒ–å‚æ•°ï¼Œä¿ç•™éé›¶ç³»æ•°å˜é‡ã€‚

### 3.2 æ¨¡å‹è®­ç»ƒ
å…±æ„å»ºäº”ç§åˆ†ç±»æ¨¡å‹ï¼š
- é€»è¾‘å›å½’ï¼ˆLogistic Regressionï¼‰
- æ”¯æŒå‘é‡æœºï¼ˆSupport Vector Machineï¼‰
- Kè¿‘é‚»ç®—æ³•ï¼ˆKNNï¼‰
- æœ´ç´ è´å¶æ–¯ï¼ˆNaive Bayesï¼‰
- XGBoostï¼ˆæç«¯æ¢¯åº¦æå‡ï¼‰

XGBoostå‚æ•°è®¾ç½®ï¼š
- å­¦ä¹ ç‡ï¼š0.1
- æœ€å¤§æ·±åº¦ï¼š3
- è¿­ä»£æ ‘æ•°ï¼š20
- è¯„ä»·å‡½æ•°ï¼šlogloss

### 3.3 æ¨¡å‹è¯„ä¼°æŒ‡æ ‡
- ROCæ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUCï¼‰
- å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
- çµæ•åº¦ï¼ˆSensitivityï¼‰
- ç‰¹å¼‚åº¦ï¼ˆSpecificityï¼‰
- F1åˆ†æ•°
- Brieråˆ†æ•°

---

## å››ã€ç»“æœåˆ†æ

### 4.1 æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ
XGBoostæ¨¡å‹åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œè¡¨ç°å¦‚ä¸‹ï¼š

| æ¨¡å‹ | AUC | Accuracy | Sensitivity | Specificity | F1 Score | Brier Score |
|------|-----|----------|-------------|-------------|----------|--------------|
| LogisticRegression | 0.83 | 0.77 | 0.78 | 0.77 | 0.72 | 0.19 |
| SVM                | 0.81 | 0.83 | 0.70 | 0.82 | 0.71 | 0.21 |
| KNN                | 0.87 | 0.82 | 1.00 | 0.56 | 0.68 | 0.22 |
| NaiveBayes         | 0.77 | 0.76 | 0.72 | 0.73 | 0.68 | 0.23 |
| XGBoost            | 0.92 | 0.87 | 0.89 | 0.81 | 0.78 | 0.15 |

### 4.2 KæŠ˜äº¤å‰éªŒè¯
XGBooståœ¨5æŠ˜äº¤å‰éªŒè¯ä¸­AUCå‡å€¼ä¸º **0.810 Â± 0.030**ï¼Œç¨³å®šæ€§è‰¯å¥½ã€‚

### 4.3 æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æï¼ˆSHAPï¼‰
é‡‡ç”¨SHAPæ–¹æ³•å¯¹XGBoostæ¨¡å‹è¿›è¡Œè§£é‡Šï¼š
- ç»˜åˆ¶å˜é‡é‡è¦æ€§æ’åå›¾ï¼ˆsummary plotï¼‰ï¼›
- æä¾›å•æ ·æœ¬ç€‘å¸ƒå›¾ï¼ˆwaterfall plotï¼‰å±•ç¤ºé¢„æµ‹ä¾æ®ï¼›
- é«˜å½±å“å› ç´ åŒ…æ‹¬ï¼šCRPå‡é«˜ã€è‚ å†…è¥å…»ã€PCTå‡é«˜ã€Hbé™ä½ã€Scrå‡é«˜ç­‰ã€‚

---

## äº”ã€ç»“è®º

æœ¬æ–‡åŸºäºæ¨¡æ‹ŸICUæ‚£è€…æ•°æ®å¤ç°äº†XGBoostæœºå™¨å­¦ä¹ æ¨¡å‹åœ¨AADé¢„æµ‹ä¸­çš„æ„å»ºè¿‡ç¨‹ï¼Œç»“æœè¡¨æ˜ï¼š
- LASSO+XGBoostç»„åˆå…·å¤‡ä¼˜ç§€çš„é¢„æµ‹æ€§èƒ½ï¼›
- æ¨¡å‹åœ¨æ•æ„Ÿåº¦ã€AUCä¸F1å¾—åˆ†æ–¹é¢è¡¨ç°æœ€ä¼˜ï¼›
- SHAPå¢å¼ºäº†æ¨¡å‹çš„é€æ˜æ€§ï¼Œä¾¿äºä¸´åºŠåŒ»ç”Ÿç†è§£å’Œä½¿ç”¨ã€‚

---

## å…­ã€é™„å½•

### ğŸ“‚ è¾“å‡ºæ–‡ä»¶ç›®å½•
```
â”œâ”€â”€ aad_icu_all.csv
â”œâ”€â”€ model_evaluation.csv
â”œâ”€â”€ shap_summary_plot.png
â”œâ”€â”€ shap_waterfall_sample0.png
```

### ğŸ“Œ åç»­å·¥ä½œå»ºè®®
- å¼•å…¥æ›´å¤šä¸´åºŠå˜é‡å¦‚IL-6ã€APACHEè¯„åˆ†ç­‰ï¼›
- å¢åŠ å¤–éƒ¨çœŸå®æ•°æ®éªŒè¯ï¼›
- ä¸æ·±åº¦å­¦ä¹ æ¨¡å‹å¦‚TabNetã€LightGBMç­‰å¯¹æ¯”æ‰©å±•ã€‚

