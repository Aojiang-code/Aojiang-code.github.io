{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 1.4 \u533b\u5b66\u56e0\u679c\u63a8\u65ad\u5e38\u7528\u65b9\u6cd5 \u00b7 \u6700\u5c0f\u53ef\u8fd0\u884c\u6a21\u677f\n", "\n", "\u751f\u6210\u65f6\u95f4\uff1a2025-08-15 04:18:06\n", "\n", "\u5305\u542b\uff1a\n", "- **PSM**\uff08\u5339\u914d + Love plot\uff09\n", "- **IPTW**\uff08\u7a33\u5b9a\u5316 + \u622a\u5c3e + ESS\uff09\n", "- **IV**\uff082SLS with robust SE\uff09\n", "- **DR**\uff08EconML DRLearner\uff1aATE + ITE\uff09\n", "\n", "> \u5148\u8fd0\u884c\u201c\ud83e\uddea \u751f\u6210/\u52a0\u8f7d\u6f14\u793a\u6570\u636e\u201d\u548c\u201c\ud83d\udd27 \u5de5\u5177\u51fd\u6570\u201d\u3002\n", "> \u5408\u6210\u6570\u636e\u4ec5\u6f14\u793a\u7528\u9014\uff1b\u5b9e\u9645\u7814\u7a76\u8bf7\u66ff\u6362\u4e3a\u771f\u5b9e\u6570\u636e\u5e76\u8865\u5145\u5b8c\u6574\u8bca\u65ad\u4e0e\u654f\u611f\u6027\u5206\u6790\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\uddea \u751f\u6210/\u52a0\u8f7d\u6f14\u793a\u6570\u636e"]}, {"cell_type": "code", "metadata": {"name": "data_gen"}, "source": ["import numpy as np, pandas as pd\n", "rng = np.random.default_rng(42)\n", "\n", "n = 800\n", "age = rng.normal(70, 8, n)\n", "sex = rng.integers(0, 2, n)  # 0 female, 1 male\n", "sofa = rng.integers(0, 12, n)\n", "charlson = rng.integers(0, 8, n)\n", "\n", "# Treatment assignment via logistic model\n", "lin_ps = -4 + 0.03*age + 0.25*sex + 0.15*sofa + 0.20*charlson\n", "ps_true = 1/(1+np.exp(-lin_ps))\n", "treatment = rng.binomial(1, ps_true)\n", "\n", "# Treatment effect heterogeneity\n", "tau =  -1.0 + 0.02*(80-age) + 0.1*(sex==0)\n", "# Baseline outcome\n", "y0 = 10 + 0.08*age + 0.6*sofa + 0.8*charlson + rng.normal(0, 3, n)\n", "# Realized outcome\n", "outcome = y0 + tau*treatment + rng.normal(0, 1.2, n)\n", "\n", "df = pd.DataFrame({\n", "    'age': np.round(age, 1),\n", "    'sex': sex,\n", "    'sofa': sofa,\n", "    'charlson': charlson,\n", "    'treatment': treatment,\n", "    'outcome': np.round(outcome, 3)\n", "})\n", "df.to_csv('/mnt/data/causal_toy_data.csv', index=False)\n", "print('Saved synthetic dataset to /mnt/data/causal_toy_data.csv with shape:', df.shape)\n", "df.head()"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd27 \u5de5\u5177\u51fd\u6570\uff08SMD\u3001ESS\uff09"]}, {"cell_type": "code", "metadata": {"name": "utils"}, "source": ["import numpy as np, pandas as pd\n", "\n", "# Compute SMD for numeric/binary columns; returns Series\n", "def smd_standardized_mean_diff(df, cols, treat_col, weights=None):\n", "    out = {}\n", "    T = df[treat_col].values.astype(int)\n", "    for c in cols:\n", "        x = df[c].values\n", "        if weights is None:\n", "            wt = np.ones_like(x, dtype=float)\n", "        else:\n", "            wt = np.asarray(weights, dtype=float)\n", "        tmask = T==1\n", "        cmask = T==0\n", "        mt = np.sum(wt[tmask]*x[tmask])/np.sum(wt[tmask])\n", "        mc = np.sum(wt[cmask]*x[cmask])/np.sum(wt[cmask])\n", "        vt = np.sum(wt[tmask]*(x[tmask]-mt)**2)/np.sum(wt[tmask])\n", "        vc = np.sum(wt[cmask]*(x[cmask]-mc)**2)/np.sum(wt[cmask])\n", "        sp = np.sqrt(0.5*(vt+vc)+1e-12)\n", "        out[c] = (mt-mc)/sp if sp>0 else 0.0\n", "    return pd.Series(out).sort_values(key=lambda s: np.abs(s), ascending=False)\n", "\n", "def effective_sample_size(weights):\n", "    w = np.asarray(weights, dtype=float)\n", "    return (w.sum()**2) / (np.sum(w**2) + 1e-12)"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1) PSM\uff1a\u5339\u914d + Love plot"]}, {"cell_type": "code", "metadata": {"name": "psm"}, "source": ["import numpy as np, pandas as pd\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.neighbors import NearestNeighbors\n", "import matplotlib.pyplot as plt\n", "\n", "df = pd.read_csv('/mnt/data/causal_toy_data.csv')\n", "\n", "T, Y = 'treatment', 'outcome'\n", "pre_covs = ['age','sex','sofa','charlson']\n", "\n", "# 1) Estimate PS\n", "X = pd.get_dummies(df[pre_covs], drop_first=True)\n", "ps_model = LogisticRegression(max_iter=1000).fit(X, df[T])\n", "ps = ps_model.predict_proba(X)[:,1]\n", "\n", "# 2) 1:1 nearest neighbor matching with caliper\n", "treated_idx = df.index[df[T]==1].to_numpy()\n", "control_idx = df.index[df[T]==0].to_numpy()\n", "\n", "nbrs = NearestNeighbors(n_neighbors=1).fit(ps[control_idx].reshape(-1,1))\n", "dist, nn = nbrs.kneighbors(ps[treated_idx].reshape(-1,1))\n", "matched_control = control_idx[nn.flatten()]\n", "pairs = pd.DataFrame({'treated': treated_idx, 'control': matched_control, 'dist': dist.flatten()})\n", "caliper = 0.05\n", "pairs = pairs[pairs['dist'] <= caliper]\n", "\n", "# 3) ATT\n", "yt = df.loc[pairs['treated'], Y].to_numpy()\n", "yc = df.loc[pairs['control'], Y].to_numpy()\n", "att = yt.mean() - yc.mean()\n", "print(f\"PSM ATT (caliper={caliper}): {att:.4f} | pairs: {len(pairs)}\")\n", "\n", "# 4) Love plot SMD before/after\n", "from __main__ import smd_standardized_mean_diff\n", "\n", "smd_before = smd_standardized_mean_diff(pd.concat([df[pre_covs], df[[T]]], axis=1), pre_covs, T)\n", "\n", "weights_matched = np.zeros(len(df))\n", "weights_matched[pairs['treated']] = 1\n", "weights_matched[pairs['control']] += 1\n", "\n", "smd_after = smd_standardized_mean_diff(df, pre_covs, T, weights=weights_matched)\n", "\n", "plt.figure()\n", "order = smd_before.abs().sort_values(ascending=True).index.tolist()\n", "plt.scatter(smd_before[order], range(len(order)), label='Before')\n", "plt.scatter(smd_after[order], range(len(order)), marker='x', label='After')\n", "plt.yticks(range(len(order)), order)\n", "plt.axvline(0.1, linestyle='--'); plt.axvline(-0.1, linestyle='--')\n", "plt.xlabel('Standardized Mean Difference')\n", "plt.title('Love Plot: PSM Balance')\n", "plt.legend()\n", "plt.show()"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2) IPTW\uff1a\u7a33\u5b9a\u5316 + \u622a\u5c3e + ESS"]}, {"cell_type": "code", "metadata": {"name": "iptw"}, "source": ["import numpy as np, pandas as pd\n", "from sklearn.linear_model import LogisticRegression\n", "import matplotlib.pyplot as plt\n", "\n", "df = pd.read_csv('/mnt/data/causal_toy_data.csv')\n", "T, Y = 'treatment', 'outcome'\n", "pre_covs = ['age','sex','sofa','charlson']\n", "\n", "X = pd.get_dummies(df[pre_covs], drop_first=True)\n", "ps = LogisticRegression(max_iter=1000).fit(X, df[T]).predict_proba(X)[:,1]\n", "\n", "p_t = df[T].mean()\n", "w = np.where(df[T]==1, p_t/ps, (1-p_t)/(1-ps))\n", "\n", "# Trim\n", "lo, hi = np.percentile(w, [1, 99])\n", "w_clip = np.clip(w, lo, hi)\n", "\n", "ate = (w_clip[df[T]==1]*df.loc[df[T]==1, Y]).sum()/w_clip[df[T]==1].sum() - \\\n", "      (w_clip[df[T]==0]*df.loc[df[T]==0, Y]).sum()/w_clip[df[T]==0].sum()\n", "print(f\"IPTW (stabilized, trimmed {lo:.3f}-{hi:.3f}) ATE: {ate:.4f}\")\n", "\n", "from __main__ import effective_sample_size, smd_standardized_mean_diff\n", "ESS = effective_sample_size(w_clip)\n", "print(\"Effective Sample Size (ESS):\", round(ESS, 1))\n", "\n", "plt.figure()\n", "plt.hist(w, bins=40, alpha=0.7, label='Raw')\n", "plt.hist(w_clip, bins=40, alpha=0.7, label='Trimmed')\n", "plt.title('IPTW Weights Distribution')\n", "plt.legend()\n", "plt.show()\n", "\n", "smd_w = smd_standardized_mean_diff(df, pre_covs, T, weights=w_clip)\n", "print(\"Top weighted SMD:\\n\", smd_w.head())"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3) IV\uff082SLS\uff09\uff1a\u6700\u5c0f\u793a\u4f8b"]}, {"cell_type": "code", "metadata": {"name": "iv"}, "source": ["import numpy as np, pandas as pd\n", "import statsmodels.api as sm\n", "from linearmodels.iv import IV2SLS\n", "\n", "df = pd.read_csv('/mnt/data/causal_toy_data.csv')\n", "# Toy instrument: cluster-level treatment rate proxying physician preference\n", "clusters = (df['age'] // 5).astype(int)\n", "pref = clusters.map(df.groupby(clusters)['treatment'].mean())\n", "df['physician_preference'] = pref.values\n", "\n", "Y = df['outcome']\n", "X = df['treatment']\n", "Z = df[['physician_preference']]\n", "W = sm.add_constant(df[['age','sex','sofa','charlson']], has_constant='add')\n", "\n", "iv_res = IV2SLS(dependent=Y, exog=W, endog=X, instruments=pd.concat([Z, W], axis=1)).fit(cov_type='robust')\n", "print(iv_res.summary)"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4) DR\uff08EconML DRLearner\uff09\uff1aATE \u4e0e ITE"]}, {"cell_type": "code", "metadata": {"name": "dr"}, "source": ["import numpy as np, pandas as pd\n", "from sklearn.ensemble import RandomForestRegressor\n", "from sklearn.linear_model import LogisticRegression, LassoCV\n", "from econml.dr import DRLearner\n", "\n", "df = pd.read_csv('/mnt/data/causal_toy_data.csv')\n", "T, Y = 'treatment', 'outcome'\n", "X = pd.get_dummies(df[['age','sex','sofa','charlson']], drop_first=True).values\n", "\n", "est = DRLearner(\n", "    model_propensity=LogisticRegression(max_iter=1000),\n", "    model_regression=RandomForestRegressor(n_estimators=200, random_state=0),\n", "    model_final=LassoCV(cv=5, random_state=0)\n", ")\n", "est.fit(Y=df[Y].values, T=df[T].values, X=X)\n", "\n", "ate = np.mean(est.effect(X))\n", "print(\"DRLearner ATE:\", round(float(ate), 4))\n", "print(\"First 10 ITE estimates:\", np.round(est.effect(X[:10]), 4))"], "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}