# 1.4 医学因果推断常用方法（入门者强化版）

> 入门总览（先记这张“口袋卡”）
>
> * **PSM**：先估 PS，再**配对**，对“像”的人做对比 → 常估 **ATT**（对已治疗者的平均效应）
> * **IPTW**：先估 PS，再**加权**，造一个“伪随机化”样本 → 常估 **ATE**（总体平均效应）
> * **IV**：有不可测混杂时，用“只影响治疗、不直接影响结局”的外生变异 → 常估 **LATE**（受激励者的局部平均效应）
> * **DR（AIPW/DR-Learner/TMLE）**：同时建**PS**与**结果**两个模型，任一正确都能无偏（双重稳健）

---

## 1️⃣ 倾向评分匹配（PSM, Propensity Score Matching）

### 直觉

把**治疗组**里每个人，用“倾向评分（PS）相近”的**对照组**人去“配对”，形成可比的成对样本，然后比较结局差异。

### 识别假设（用背门法则）

* **可交换性**：给定治疗前协变量 $Z$，治疗与潜在结局独立（没有重要未测混杂）
* **重叠性**：任意 $Z$ 下，接受/未接受治疗的概率都 > 0
* **一致性 / SUTVA**：治疗定义一致、个体之间互不干扰

### 实操步骤

1. **只用治疗前协变量**训练 PS（常用逻辑回归/梯度提升等）
2. 选择匹配算法：

   * 最近邻（1:1, 1\:k）、带**卡尺**（caliper, 如 0.2×PS logit 标准差）
   * 是否允许替换（with/without replacement）
3. **诊断**：匹配后看 **SMD（标准化均数差）** 是否降至 ≤0.1/0.2；报告丢失样本比例
4. **估计**：成对差值、配对 t 检验或在匹配样本上回归；一般是 **ATT**

### 最小 Python 示例（不依赖稀有包）

```python
import numpy as np, pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import NearestNeighbors

# 假设 df 有列：T='treatment'(0/1), Y='outcome'，协变量列表 pre_covs
T, Y = 'treatment', 'outcome'
pre_covs = ['age','sex','sofa','charlson']  # 只放治疗前变量

# 1) 估计 PS
X = pd.get_dummies(df[pre_covs], drop_first=True)
ps_model = LogisticRegression(max_iter=1000).fit(X, df[T])
ps = ps_model.predict_proba(X)[:, 1]

# 2) 最近邻 1:1 匹配（卡尺可用 |ps_i-ps_j| < 0.05 之类约束，这里演示最简）
treated_idx  = df.index[df[T]==1]
control_idx  = df.index[df[T]==0]

nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(ps[control_idx].reshape(-1,1))
dist, nn = nbrs.kneighbors(ps[treated_idx].reshape(-1,1))
matched_control = control_idx[nn.flatten()]

matched_pairs = pd.DataFrame({'treated': treated_idx, 'control': matched_control, 'dist': dist.flatten()})
# 可加卡尺过滤，如 matched_pairs = matched_pairs[matched_pairs['dist'] < 0.05]

# 3) 构建匹配样本并估计 ATT（均值差）
yt = df.loc[matched_pairs['treated'], Y].to_numpy()
yc = df.loc[matched_pairs['control'], Y].to_numpy()
att = yt.mean() - yc.mean()
print("PSM 估计 ATT:", att, " | 配对数:", len(matched_pairs))
```

> 诊断要点：
>
> * 报告匹配前/后 **SMD**（可画 Love plot）
> * 报告匹配比例、丢弃样本比例、卡尺/配对策略
> * 匹配后推断时应考虑成对相关（可用成对差值或配对回归）

**优点**：直观、易解释，平衡性好时效果稳定
**缺点**：样本可能被丢弃；估计的通常是 **ATT**；推断需要考虑匹配不确定性

---

## 2️⃣ 倾向评分加权（IPTW, Inverse Probability of Treatment Weighting）

### 直觉

把每个样本按“其接受到的治疗的**逆概率**”加权；罕见情形给更高权重 → 让**加权后的样本**在协变量上近似“随机化”。

### 权重（ATE 的常用形式）

* 未稳定化：治疗 $w=1/PS$；对照 $w=1/(1-PS)$
* **稳定化**（常用，降低方差）：
  $w = \dfrac{P(T=1)}{PS}$（治疗）; $w = \dfrac{P(T=0)}{1-PS}$（对照）

> 也可构造 **ATT/ATC/Overlap** 等权重（例如 Overlap Weight $w\propto PS(1-PS)$ 抑制极端 PS）

### 实操步骤

1. **只用治疗前协变量**估 PS
2. 计算权重，常做**截尾/裁剪**（如 1%–99% 分位）
3. **诊断**：加权后检验 **SMD** 是否达标，计算**有效样本量（ESS）**
4. **估计**：加权均值差 / 加权回归 / 生存场景用加权 Cox；常估 **ATE**

### 最小 Python 示例（含截尾与 ESS）

```python
import numpy as np, pandas as pd
from sklearn.linear_model import LogisticRegression

T, Y = 'treatment', 'outcome'
pre_covs = ['age','sex','sofa','charlson']

X = pd.get_dummies(df[pre_covs], drop_first=True)
ps = LogisticRegression(max_iter=1000).fit(X, df[T]).predict_proba(X)[:,1]

p_t = df[T].mean()  # 稳定化常用
w = np.where(df[T]==1, p_t/ps, (1-p_t)/(1-ps))

# 截尾（避免极端权重）
lo, hi = np.percentile(w, [1, 99])
w_clip = np.clip(w, lo, hi)

# 加权 ATE（均值差）
ate = (w_clip[df[T]==1]*df.loc[df[T]==1, Y]).sum()/w_clip[df[T]==1].sum() - \
      (w_clip[df[T]==0]*df.loc[df[T]==0, Y]).sum()/w_clip[df[T]==0].sum()
print("IPTW (stabilized, trimmed) ATE:", ate)

# 有效样本量（ESS）
ESS = (w_clip.sum()**2) / ( (w_clip**2).sum() )
print("有效样本量 ESS:", ESS)
```

> 诊断要点：
>
> * 报告权重分布（箱线/直方）、截尾阈值、ESS
> * 加权后 **SMD**（≤0.1/0.2）
> * 生存数据：用加权 KM / 加权 Cox，权重进入生存模型

**优点**：保留全部样本；目标通常是 **ATE**；易与生存分析结合
**缺点**：极端 PS → 权重爆炸；必须做截尾/稳健方法；对 PS 模型设定敏感

---

## 3️⃣ 工具变量（IV, Instrumental Variables）

### 直觉

当存在**不可测混杂**导致背门法则失效时，找一个“只影响治疗、不直接影响结局（除了通过治疗）”的外生变异（工具变量 $Z$）来识别**局部效应**。

### 三大假设（必须逐条思考）

1. **相关性（Relevance）**：$Z$ 显著影响 $X$（第一阶段强度充足，F>10）
2. **排他性（Exclusion）**：$Z$ 不通过其他路径影响 $Y$
3. **独立性（Independence）**：$Z$ 与潜在结局独立（不受未测混杂影响）
   （若要解释为 **LATE** 还需 **单调性（Monotonicity）**：不存在“违抗者”）

### 医学常见候选

* 医师/科室/医院的**处方倾向**、地理距离、分诊规则、政策变更、床位紧张度等

### 估计对象与解读

* 通常得到 **LATE（服从激励者的局部平均处理效应）**，不是总体 ATE
* **解释边界**：只对**被工具“推动而改变治疗选择”的人群**有效

### 最小 Python 示例（2SLS；推荐使用 `linearmodels` 以获得正确标准误）

```python
# pip install linearmodels
from linearmodels.iv import IV2SLS
import statsmodels.api as sm

# Y: outcome, X: treatment, Z: instrument, W: 观测混杂
Y = df['outcome']
X = df['treatment']
Z = df['physician_preference']   # 举例：医生处方倾向
W = df[['age','sex','sofa','charlson']]  # 控制项（可选）
W = sm.add_constant(W, has_constant='add')

# 2SLS：Y ~ 1 + [X ~ Z + W] + W
iv_res = IV2SLS(dependent=Y, exog=W, endog=X, instruments=pd.concat([Z, W], axis=1)).fit(cov_type='robust')
print(iv_res.summary)
```

> 诊断要点：
>
> * 第一阶段强度（F 统计量）
> * 工具合理性论证（临床/制度背景 + 形式检验/安慰剂检验）
> * 效应解释为 **LATE**，明确其适用人群

**优点**：在不可测混杂下仍可识别效应
**缺点**：好工具难找；估的是 LATE；对假设要求高

---

## 4️⃣ 双重稳健（DR, Doubly Robust）

### 直觉

同时建两条线：**PS 模型**（治疗分配）和**结果模型**（结局），再用 **AIPW/DR** 形式合并；只要**任意一个**模型正确，估计就**一致**。

### 常见形态

* **AIPW（Augmented IPW）**：在 IPTW 基础上加一个“结果模型校正项”
* **DR-Learner / R-Learner / X-Learner**：面向 CATE/ITE 的元学习器
* **TMLE（Targeted MLE）**：在结果模型上做目标化更新，兼容非参数/ML

### 何时选 DR

* 担心 PS 模型或结果模型有设定误差
* 想要兼顾稳健性与效率（特别是高维/非线性场景）

### 最小 Python 示例（EconML 的 DRLearner）

```python
# pip install econml
import numpy as np, pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LassoCV, LogisticRegression
from econml.dr import DRLearner

T, Y = 'treatment', 'outcome'
X = pd.get_dummies(df[['age','sex','sofa','charlson']], drop_first=True).values

est = DRLearner(
    model_propensity=LogisticRegression(max_iter=1000),
    model_regression=RandomForestRegressor(n_estimators=200, random_state=0),
    model_final=LassoCV(cv=5, random_state=0)
)
est.fit(Y=df[Y].values, T=df[T].values, X=X)

# 平均效应（ATE）与个体化效应（ITE/CATE）
ate = np.mean(est.effect(X))
print("DR 估计 ATE:", ate)

# 某个患者的个体效应
ite_sample = est.effect(X[:5])
print("前5名患者的 ITE 估计:", ite_sample)
```

> 诊断要点：
>
> * 报告两条模型（PS 与 Outcome）的拟合与变量清单（仅**治疗前**协变量）
> * 与 IPTW/PSM/G-formula 等方法做**一致性对比**
> * 做**敏感性分析**（截尾、替代模型、负控）

**优点**：模型设定更稳健、可输出 CATE/ITE
**缺点**：实现复杂度更高；解释需谨慎（外推范围=数据重叠区域）

---

## 选方法的小抄（实用决策树）

* **数据量中等、变量不多，重叠尚可** → 先试 **PSM**（好解释），再用 **IPTW/DR** 验证
* **希望保留全部样本、做生存分析** → **IPTW**（加权 KM/Cox）
* **有不可测混杂的合理担忧 + 有好工具** → **IV（2SLS）**
* **担心模型设定错误、想兼顾稳健与效率** → **DR（AIPW/DR-Learner/TMLE）**
* **个体化治疗/精准医学** → 在平均效应稳健后，用 **DR-Learner / Causal Forest / EconML** 做 **CATE/ITE**

---

## 统一的报告与诊断清单（论文/报告模板）

1. **变量与时间线**：治疗、结局、协变量均为**治疗前**；纳排标准明确
2. **平衡性**：SMD/Love plot（PSM 前后；IPTW 加权后）
3. **重叠性**：PS 分布/极端值比例；权重分布与**截尾阈值**
4. **方法细节**：

   * PSM：匹配比、卡尺、替换与否、丢弃比例
   * IPTW：稳定化/截尾、ESS
   * IV：工具来源、第一阶段强度、LATE 解释
   * DR：PS/Outcome 模型设定、ML 超参
5. **效应指标**：ATE/ATT/ATC、RR/OR/HR（区分估计目标）
6. **稳健性/敏感性**：替代模型、不同卡尺/截尾、负控、E-value/未测混杂评估
7. **可解释性**：临床意义（绝对风险差/Number Needed to Treat）、亚组/异质性

---

### 常见坑（务必避免）

* 在 PS/背门调整集里放**治疗后**变量（中介/碰撞）
* 极端 PS 不处理就 IPTW（权重爆炸）
* PSM 只看点估计，不看匹配后平衡与丢样
* IV 工具不满足排他/独立性还强行解释为因果
* DR/CATE 模型做完不报重叠边界与稳健性

---

配套代码:`001_Env_Check_and_Quickload.ipynb`

