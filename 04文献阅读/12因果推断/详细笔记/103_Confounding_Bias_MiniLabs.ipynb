{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56768c74",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ““ é˜¶æ®µ 1 Â· 1.3 ä¸“ç”¨ Notebook â€”â€” æ··æ‚ä¸åå€š Â· è¿·ä½ å®éªŒåˆé›†\n",
    "\n",
    "æœ¬ Notebook åŒ…å«ï¼š  \n",
    "1) **æ··æ‚å®éªŒ**ï¼šå±•ç¤ºâ€œé‡ç—‡è€…æ›´å¸¸è¢«æ²»ç–— â†’ å¤©çœŸæ¯”è¾ƒæ–¹å‘é¢ å€’â€å¹¶ç”¨å›å½’/IPTWçŸ«æ­£ï¼›  \n",
    "2) **ç¢°æ’å®éªŒ**ï¼šå±•ç¤ºâ€œæ¡ä»¶åŒ–ç¢°æ’å˜é‡ â†’ å‡­ç©ºé€ å‡ºç›¸å…³â€ï¼›  \n",
    "3) **å˜é‡é€‰æ‹©æ¸…å•**ï¼šé¿å…è¿‡åº¦/ä¸è¶³/é”™è¯¯è°ƒæ•´çš„æ“ä½œæŒ‡å—ã€‚\n",
    "\n",
    "> è¿è¡Œé¡ºåºï¼šä» 1 åˆ° 3 ä¾æ¬¡æ‰§è¡Œã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b19cf1e",
   "metadata": {},
   "source": [
    "\n",
    "## 1. æ··æ‚å®éªŒï¼šæ–¹å‘é¢ å€’ä¸æ ¡æ­£\n",
    "**è®¾å®š**ï¼šé‡ç—‡åº¦ `Z` è¶Šé«˜ â†’ è¶Šå¯èƒ½è¢«æ²»ç–— `X`ï¼Œä¹Ÿè¶Šå¯èƒ½æ­»äº¡ `Y`ï¼›çœŸç›¸ä¸­æ²»ç–—**é™ä½**æ­»äº¡ã€‚  \n",
    "**ç°è±¡**ï¼šå¤©çœŸæ¯”è¾ƒæ˜¾ç¤ºâ€œæ²»ç–—æ›´è‡´æ­»â€ï¼ˆè¢«æ··æ‚éª—äº†ï¼‰ï¼›å›å½’/IPTW æ ¡æ­£åæ¢å¤â€œæ²»ç–—ä¿æŠ¤â€ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470fa068",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(0)\n",
    "n = 5000\n",
    "\n",
    "# æ··æ‚ Zï¼šé‡ç—‡åº¦ï¼ˆè¶Šé«˜è¶Šé‡ï¼‰\n",
    "Z = np.clip(np.random.normal(0, 1, n), -2.5, 2.5)\n",
    "\n",
    "# æ²»ç–—åˆ†é…ï¼šZ è¶Šé«˜è¶Šå¯èƒ½è¢«æ²»ç–—ï¼ˆæŒ‡å¾æ··æ‚ï¼‰\n",
    "logit_t = -0.2 + 1.2*Z\n",
    "p_t = 1/(1+np.exp(-logit_t))\n",
    "X = (np.random.rand(n) < p_t).astype(int)  # 1=æ²»ç–—\n",
    "\n",
    "# çœŸç›¸ï¼šæ²»ç–—æœ‰ç›Šï¼ˆé™ä½æ­»äº¡ï¼‰ï¼Œä½†é‡ç—‡æœ¬èº«æé«˜æ­»äº¡\n",
    "logit_y = -2.0 + 1.1*Z - 0.8*X\n",
    "p_y = 1/(1+np.exp(-logit_y))\n",
    "Y = (np.random.rand(n) < p_y).astype(int)  # 1=æ­»äº¡\n",
    "\n",
    "df = pd.DataFrame({'Z':Z,'X':X,'Y':Y})\n",
    "\n",
    "# 1) å¤©çœŸæ¯”è¾ƒï¼šæ²»ç–—ç»„ vs å¯¹ç…§ç»„æ­»äº¡ç‡å·®\n",
    "naive_diff = df.loc[df.X==1,'Y'].mean() - df.loc[df.X==0,'Y'].mean()\n",
    "print(\"å¤©çœŸæ¯”è¾ƒï¼šæ²»ç–—ç»„-å¯¹ç…§ç»„æ­»äº¡ç‡å·® =\", round(naive_diff, 3))\n",
    "\n",
    "# 2) å›å½’è°ƒæ•´ï¼šåœ¨ logit(Y) ~ X + Z ä¸­çœ‹ X çš„ç³»æ•°æ–¹å‘\n",
    "m_adj = LogisticRegression(max_iter=1000).fit(df[['X','Z']], df['Y'])\n",
    "print(\"Logitå›å½’ä¸­ X çš„ç³»æ•°ï¼ˆ<0 è¡¨ç¤ºæ²»ç–—ä¿æŠ¤ï¼‰:\", round(m_adj.coef_[0][0], 3))\n",
    "\n",
    "# 3) IPTWï¼šåªç”¨ Z å»º PSï¼Œå¹¶ä¼°è®¡ ATEï¼ˆæ­»äº¡ç‡å·®ï¼‰\n",
    "scaler = StandardScaler()\n",
    "ps = LogisticRegression(max_iter=1000).fit(scaler.fit_transform(df[['Z']]), df['X']).predict_proba(scaler.transform(df[['Z']]))[:,1]\n",
    "w = np.where(df['X']==1, 1/ps, 1/(1-ps))\n",
    "ate_iptw = (w[df.X==1]*df.Y[df.X==1]).sum()/w[df.X==1].sum() - (w[df.X==0]*df.Y[df.X==0]).sum()/w[df.X==0].sum()\n",
    "print(\"IPTW ä¼°è®¡ATEï¼ˆ>0=å¢é£é™©ï¼Œ<0=é™é£é™©ï¼‰:\", round(ate_iptw, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03597c9",
   "metadata": {},
   "source": [
    "\n",
    "## 2. ç¢°æ’å®éªŒï¼šæ¡ä»¶åŒ–å…±åŒç»“æœ â†’ é€ å‡ºè™šå‡ç›¸å…³\n",
    "**è®¾å®š**ï¼šX ä¸ U åŸæœ¬ç‹¬ç«‹ï¼›A æ˜¯ X ä¸ U çš„å…±åŒç»“æœï¼ˆ**ç¢°æ’**ï¼‰ã€‚è‹¥åªåˆ†æ A=1 çš„æ ·æœ¬ï¼Œå°±ä¼šå‡­ç©ºå‡ºç° Xâ€“Y çš„ç›¸å…³ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb00f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "np.random.seed(1); n=100000\n",
    "\n",
    "# X ä¸ U äº’ä¸ç›¸å…³\n",
    "X = np.random.binomial(1, 0.5, n)\n",
    "U = np.random.binomial(1, 0.5, n)\n",
    "\n",
    "# A æ˜¯ X ä¸ U çš„å…±åŒç»“æœï¼ˆç¢°æ’ï¼‰ï¼šåªæœ‰ A=1 çš„äººè¿›å…¥æ ·æœ¬\n",
    "A = (np.random.rand(n) < (0.05 + 0.4*X + 0.4*U)).astype(int)\n",
    "keep = A==1\n",
    "\n",
    "# ç»“å±€åªå— U å½±å“ï¼ˆä¸ X æ— å…³ï¼‰ï¼Œä¾¿äºè§‚å¯Ÿç¢°æ’åå€š\n",
    "Y = U  # ç®€åŒ–è®¾å®š\n",
    "\n",
    "dfc = pd.DataFrame({'X':X[keep], 'U':U[keep], 'Y':Y[keep]})\n",
    "overall_corr = np.corrcoef(X, Y)[0,1]\n",
    "sample_corr = np.corrcoef(dfc.X, dfc.Y)[0,1]\n",
    "print(\"æ€»ä½“ Xâ€“Y ç›¸å…³ï¼ˆåº”â‰ˆ0ï¼‰â†’\", round(overall_corr, 4))\n",
    "print(\"ç­›é€‰ A=1 åæ ·æœ¬çš„ Xâ€“Y ç›¸å…³ï¼ˆè¢«ç¢°æ’æ‰“å¼€ï¼‰â†’\", round(sample_corr, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf99606",
   "metadata": {},
   "source": [
    "\n",
    "## 3. å˜é‡é€‰æ‹©æ¸…å•ï¼ˆé¿å…è¿‡åº¦/ä¸è¶³/é”™è¯¯è°ƒæ•´ï¼‰\n",
    "\n",
    "**åªæŠŠâ€œæ²»ç–—å‰â€å˜é‡å½“æ··æ‚**ï¼›ä¼˜å…ˆé€‰æ‹©**åŒæ—¶å½±å“ X ä¸ Y çš„å…±åŒåŸå› **ï¼›é¿å…æŠŠ**ä¸­ä»‹**å’Œ**ç¢°æ’**çº³å…¥ PS/èƒŒé—¨è°ƒæ•´é›†ã€‚\n",
    "\n",
    "### 3.1 åˆ¤å®šè§’è‰²\n",
    "- æ··æ‚ï¼ˆConfounderï¼‰ï¼šæ²»ç–—å‰ã€å…±åŒåŸå› ï¼ˆâœ… è°ƒæ•´ï¼‰  \n",
    "- ä¸­ä»‹ï¼ˆMediatorï¼‰ï¼šXâ†’Mâ†’Yï¼ˆâŒ è‹¥ä¼°æ€»æ•ˆåº”ï¼Œä¸åœ¨ PS/èƒŒé—¨é‡Œè°ƒæ•´ï¼‰  \n",
    "- ç¢°æ’ï¼ˆColliderï¼‰ï¼šXâ†’Aâ†U çš„å…±åŒç»“æœï¼ˆâŒ ä¸èƒ½æ¡ä»¶åŒ–ï¼‰  \n",
    "- æ•ˆåº”ä¿®é¥°ï¼ˆEffect Modifierï¼‰ï¼šæ•ˆåº”éš W æ”¹å˜ï¼ˆâš ï¸ æŠ¥å¼‚è´¨æ€§/CATEï¼‰\n",
    "\n",
    "### 3.2 æœ€å°æµç¨‹\n",
    "1) æ˜ç¡®æ—¶é—´çº¿ï¼šå˜é‡æ˜¯å¦åœ¨æ²»ç–—å‰å¯è§‚æµ‹ï¼›  \n",
    "2) ç”»ç®€æ˜“ DAGï¼šåˆ—å…±åŒåŸå› ï¼Œæ’é™¤ä¸­ä»‹ä¸ç¢°æ’ï¼›  \n",
    "3) ä»…ç”¨æ²»ç–—å‰æ··æ‚å»º PSï¼Œæ£€æŸ¥**å¹³è¡¡ï¼ˆSMDï¼‰**ä¸**é‡å ï¼ˆPS åˆ†å¸ƒï¼‰**ï¼›  \n",
    "4) ä¼°è®¡æ•ˆåº”ï¼šPSM/IPTW/DR/G-formulaï¼›  \n",
    "5) æ•æ„Ÿæ€§åˆ†æï¼šæç«¯æƒé‡æˆªå°¾ã€æ›¿ä»£æ¨¡å‹ã€æœªæµ‹æ··æ‚/è´Ÿæ§ã€‚\n",
    "\n",
    "> å»ºè®®æŠŠæœ¬é¡µå½“ä½œâ€œä½œæˆ˜æ‰‹å†Œâ€ï¼Œæ¯åšä¸€æ¬¡åˆ†æéƒ½è¿‡ä¸€éè¿™å¼ æ¸…å•ã€‚\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}