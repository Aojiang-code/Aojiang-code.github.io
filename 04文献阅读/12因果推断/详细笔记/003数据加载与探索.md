# 0.3 数据加载与探索（扩展版）

> 学会“拿到数据就能动手”：
> 1）明确**变量角色**（ID/时间/治疗或暴露/结局/潜在混杂/工具变量）；
> 2）做**因果视角的 EDA**（缺失、分布、基线平衡、可识别性与可比性、重叠/positivity）；
> 3）为后续估计做准备（如倾向评分、配重/匹配、敏感性分析）。

## 0.3.0 动手前的“小地图”：我需要先搞清什么？

* **ID 与时间**：是否有患者唯一标识（patient\_id）、就诊/ICU 住院唯一标识（hadm\_id / icustay\_id）？有无日期时间列（admit\_time、drug\_start、death\_time）？
* **治疗/暴露（Treatment/Exposure）**：是否存在明确的干预（药物、手术、护理策略）？是二分类（0/1）还是多水平？时间相对结局是否**先发生**？
* **结局（Outcome）**：是二分类（如 28 天死亡）还是连续型（如住院天数、评分）或生存时间？
* **潜在混杂（Confounders）**：可能同时影响“治疗选择”和“结局”的基线变量（年龄、合并症、严重度评分、既往治疗等）。
* **工具变量（IV）**（可选）：影响“治疗选择”但**不直接**影响结局的变量（如区域处方偏好、分诊规则等）。
* **重叠/可比性（Positivity/Overlap）**：不同协变量水平下，治疗与对照都要“出现过”，否则无法比较。

---

## 0.3.1 使用 DoWhy 内置 Lalonde 数据集（从 0 到 1 的“安全练手场”）

这个数据集是**合成教学集**，结构清晰：

* `treatment`（0/1）：是否接受“培训”（类比临床干预是否给予）
* `y`：结果（类比结局）
* `v0`\~`v4`：常见混杂变量（baseline covariates）
* `z0`：工具变量（这里先不使用）

### A. 加载数据与认识列

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import dowhy.datasets as dwd

# 生成合成数据（参数可调：beta=效应大小、样本量、混杂个数等）
data = dwd.linear_dataset(
    beta=10,                  # 处理效应大小（越大越容易估到效果）
    num_common_causes=5,      # 混杂变量个数
    num_instruments=1,        # 工具变量个数
    num_samples=1000,
    treatment_is_binary=True,
    stddev_treatment_noise=1.0,
    stddev_outcome_noise=1.0,
    seed=2025
)

df = data["df"].copy()
T = data["treatment_name"]
Y = data["outcome_name"]
C = data["common_causes_names"]      # 混杂变量名列表
IV = data.get("instrument_names", [])  # 工具变量名列表

print("数据形状:", df.shape)
display(df.head())
print("treatment列:", T, " | outcome列:", Y)
print("混杂变量:", C, " | 工具变量:", IV)
```

### B. 基础 EDA（因果视角）

**1）缺失、类型、异常值**

```python
print(df.info())              # 类型/非空统计
display(df.describe())        # 连续变量分布
print(df.isnull().sum())      # 缺失值统计
```

**2）治疗组 vs 对照组的基线差异（SMD）**

> 标准化均数差（Standardized Mean Difference, SMD）是观察（未匹配/未加权）下的“组间差异”量化指标。
> 经验阈值：|SMD| ≤ 0.1（很好），≤ 0.2（可接受），> 0.2（不平衡，需处理）

```python
def smd_cont(x_t, x_c):
    mu_t, mu_c = np.nanmean(x_t), np.nanmean(x_c)
    sd_pool = np.sqrt((np.nanvar(x_t, ddof=1) + np.nanvar(x_c, ddof=1)) / 2)
    return (mu_t - mu_c) / (sd_pool + 1e-12)

tmask = df[T] == 1
cmask = ~tmask

rows = []
for v in C:  # 只演示连续型的 SMD（该合成数据的混杂通常是连续）
    rows.append((v, smd_cont(df.loc[tmask, v], df.loc[cmask, v])))

smd_table = pd.DataFrame(rows, columns=["variable", "SMD"]).sort_values("variable")
display(smd_table)
```

**3）可视化一个混杂变量在两组中的分布**（直方图）

```python
var = C[0]
plt.figure()
plt.hist(df.loc[tmask, var], bins=30, alpha=0.6, label="Treatment")
plt.hist(df.loc[cmask, var], bins=30, alpha=0.6, label="Control")
plt.xlabel(var); plt.ylabel("Count"); plt.legend(); plt.title(f"Distribution of {var}")
plt.show()
```

**4）重叠/positivity 粗查：倾向评分分布**

> 在后续因果估计里会用到**倾向评分（Propensity Score, PS）**。
> 这里用逻辑回归估一个“随便看看”——主要是看两组的 PS 分布是否有重叠（没有严重分离）。

```python
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler

X = df[C].values
y = df[T].values

scaler = StandardScaler()
X_std = scaler.fit_transform(X)

ps_model = LogisticRegression(max_iter=200).fit(X_std, y)
ps = ps_model.predict_proba(X_std)[:, 1]
df["propensity_score"] = ps

plt.figure()
plt.hist(df.loc[tmask, "propensity_score"], bins=30, alpha=0.6, label="Treatment")
plt.hist(df.loc[cmask, "propensity_score"], bins=30, alpha=0.6, label="Control")
plt.xlabel("Propensity Score"); plt.ylabel("Count"); plt.legend(); plt.title("PS Overlap Check")
plt.show()
```

> **看图要点**：两组的 PS 分布要有足够重叠。如果某些协变量组合下只有治疗组（或只有对照组），**不可比**，后续可能需要**剔除极端 PS**（如 0.01/0.99 outside trimming）或改变建模策略。

---

## 0.3.2 获取免费医学数据集（从“玩具”到“真实”）

> 下面给出**UCI Heart Disease**（公网可直接下载）、**MIMIC-IV**（需注册、临床级 RWD）、**SEER**（癌症注册与生存分析）三类数据的“加载+因果 EDA 视角”示例。
> 注意：**本阶段只做 EDA**，不做因果估计；目的是习惯**角色识别、质量检查、可比性与时间顺序**等要点。

### （1）UCI Heart Disease（心血管教学数据）

**用途**：熟悉医疗常见字段与“病例/对照”之间的差异。
**注意**：不同版本列名略有差异，这里用一个常见整理版（`Heart.csv`）。

```python
import pandas as pd

url = "https://raw.githubusercontent.com/selva86/datasets/master/Heart.csv"
dfh = pd.read_csv(url)

print("形状:", dfh.shape)
display(dfh.head())
print(dfh.info())

# 统一列名为小写，便于调用
dfh.columns = [c.lower() for c in dfh.columns]

# 识别结局列：常见为 'ahd'（Yes/No），某些版本是 'target'（0/1）
target_candidates = [c for c in dfh.columns if c in ("ahd", "target", "disease")]
print("可能的结局列:", target_candidates)
target = target_candidates[0] if target_candidates else None

# 若是字符串标签，转为 0/1
if target and dfh[target].dtype == "O":
    dfh[target] = dfh[target].map({"Yes":1, "No":0}).fillna(dfh[target]).astype(int)

# 缺失值与基本分布
print("缺失值统计：")
print(dfh.isnull().sum().sort_values(ascending=False).head(10))
display(dfh.describe(include='all'))

# 例：按是否患病对比几项指标（仅 EDA，不代表因果）
cols_focus = [c for c in ["age","restbp","chol","maxhr","oldpeak"] if c in dfh.columns]
if target and cols_focus:
    print("\n按是否患病分组的均值：")
    print(dfh.groupby(target)[cols_focus].mean())

# 一个简单的可视化：不同结局组的年龄分布
import matplotlib.pyplot as plt
plt.figure()
for val, name in [(0,"No Disease"), (1,"Disease")]:
    if target:
        plt.hist(dfh.loc[dfh[target]==val, "age"].dropna(), bins=20, alpha=0.6, label=name)
plt.xlabel("Age"); plt.ylabel("Count"); plt.legend(); plt.title("Age by Disease Status")
plt.show()
```

> **因果视角提醒**：UCI Heart 并不自带明确“治疗”变量（更多是风险/临床特征）。
> 如果要用它练习因果方法，常见做法是**构造一个“伪治疗”**（例如把某个可解释的二分类变量当“暴露”），只用于演练方法流程，不解释现实含义。真正的因果研究需有明确干预/暴露定义与时间顺序。

---

### （2）MIMIC‑IV（重症监护 · 真实世界数据，需注册）

**用途**：构建“干预→结局”的真实医学问题（如“使用血管活性药物对 28 天死亡率的影响？”）。
**获取**：在 PhysioNet 注册并通过数据使用协议。下载后常见为多表（patients、admissions、icustays、prescriptions、labevents 等）。

**建议最小合并（示例）**：选取**首次 ICU 住院**，构造结局与候选混杂。下面给出**范式代码**（请根据你本地 MIMIC‑IV 文件路径与实际列名调整；不同版本可能列名有细微差异）：

```python
import pandas as pd
from pathlib import Path

# 假设你已将部分表导出为 CSV（注意：真实 MIMIC-IV 文件结构较大，通常需要数据库查询）
root = Path("/path/to/mimiciv_csv")

# 1) 基础主键与时间
patients = pd.read_csv(root/"patients.csv")      # 包含 subject_id, anchor_age, dod 等
admissions = pd.read_csv(root/"admissions.csv")  # 包含 hadm_id, admittime, dischtime 等
icustays = pd.read_csv(root/"icustays.csv")      # 包含 icustay_id, intime, outtime, first_careunit 等

# 2) 选择每位患者的**首个 ICU 住院**
icustays = icustays.sort_values(["subject_id","intime"])
first_icustay = icustays.drop_duplicates(subset=["subject_id"], keep="first")

# 合并基本信息
base = (first_icustay
        .merge(admissions, on="hadm_id", how="left", suffixes=("","_adm"))
        .merge(patients, on="subject_id", how="left", suffixes=("","_pt"))
       )

# 3) （示例）构造 28 天死亡：需要死亡日期（dod）与入院时间（admittime）
# 注：不同版本/去标识策略中，死亡时间字段可能出现在不同表或以偏移形式存在，请按你版本适配
for col in ["admittime","dischtime","intime","outtime","dod"]:
    if col in base.columns:
        base[col] = pd.to_datetime(base[col], errors="coerce")

if {"admittime","dod"}.issubset(base.columns):
    base["death_within_28d"] = ((base["dod"] - base["admittime"]).dt.days <= 28).astype("float").where(base["dod"].notna(), 0.0)
else:
    base["death_within_28d"] = pd.NA  # 如果暂未能计算，则先占位

# 4) （示例）定义“治疗/暴露”——是否使用去甲肾上腺素（norepinephrine）
# 真实做法：从 prescriptions 或 inputevents 表中识别药物名称/ATC 码与给药时间。
try:
    prescriptions = pd.read_csv(root/"prescriptions.csv")  # 含 hadm_id, drug等
    prescriptions["drug"] = prescriptions["drug"].str.lower()
    norepi_hadm = prescriptions[prescriptions["drug"].str.contains("norepinephrine", na=False)]["hadm_id"].unique()
    base["treat_norepi"] = base["hadm_id"].isin(norepi_hadm).astype(int)
except Exception as e:
    print("未能载入 prescriptions 或字段不匹配：", e)
    base["treat_norepi"] = pd.NA

print("样本量:", base.shape)
display(base[["subject_id","hadm_id","icustay_id","admittime","dod","death_within_28d","treat_norepi"]].head())

# 5) 因果 EDA 关键：基线平衡与重叠（仅举例）
# 你需要在此处列出候选混杂（如年龄、性别、SOFA、SAPS-II、肾功能等），这里只演示 anchor_age
if "anchor_age" in base.columns and "treat_norepi" in base.columns:
    import numpy as np
    tmask = base["treat_norepi"] == 1
    cmask = base["treat_norepi"] == 0
    def smd_cont(x_t, x_c):
        mu_t, mu_c = np.nanmean(x_t), np.nanmean(x_c)
        sd_pool = np.sqrt((np.nanvar(x_t, ddof=1)+np.nanvar(x_c, ddof=1))/2)
        return (mu_t - mu_c) / (sd_pool + 1e-12)
    smd_age = smd_cont(base.loc[tmask, "anchor_age"], base.loc[cmask, "anchor_age"])
    print("SMD(anchor_age) =", round(smd_age,3))
```

> **因果视角提醒（RWD 特别重要）**：
>
> * 时间顺序：治疗开始时间要**早于**或**不晚于**结局观察窗起点，否则会发生时间倒置（immortal time bias）。
> * 协变量**截取窗口**：混杂要用“治疗前”信息；治疗开始后产生的信息不要作为混杂进入模型（避免中介或collider混杂）。
> * 重叠性：重症临床经常出现极端倾向（某些患者“必然”用抢救药，另一些“几乎不会”），这时方法选择与样本修剪要格外谨慎。

---

### （3）SEER 癌症注册数据（需申请，适合生存分析与异质性探索）

**用途**：生存分析（如 5 年生存）、治疗选择差异（手术 vs 非手术）与异质性（分期、病理分型）。
**获取**：申请 SEER\*Stat，导出分析用 CSV。导出后常见列含：诊断年份、年龄分组、肿瘤分期、治疗指示变量、生存月数、结局状态等（具体以你的导出为准）。

**加载与最小生存 EDA 模板**（示例列名需按你的数据改）：

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

seer = pd.read_csv("/path/to/your/seer_export.csv")

# 示例：规范列名
seer.columns = [c.lower() for c in seer.columns]

# 常见字段（需按你的导出匹配）
# 假设：'surv_months' 生存月数；'vital_status' 1=死亡, 0=生存；'age' 年龄；'year_dx' 诊断年；'surgery' 手术(0/1)
need = ["surv_months","vital_status","age","year_dx","surgery"]
print("字段存在性：", {c: (c in seer.columns) for c in need})

# 基础 EDA
display(seer[need].describe(include='all'))

# 生存时间的粗看（非因果，仅了解分布）
plt.figure()
seer["surv_months"].plot(kind="hist", bins=40)
plt.xlabel("Survival Months"); plt.title("SEER Survival Months Distribution")
plt.show()

# 如果要做 IPTW+生存分析，后续会：1) 构造手术作为“治疗”；2) 只用治疗前混杂估 PS；3) 加权 KM 或加权 Cox。
# 本阶段仅 EDA，提醒注意：治疗时间应早于随访开始，纳入排除要清晰（比如去除诊断当天死亡等极端情况）。
```

> **因果视角提醒（生存数据）**：
>
> * 右删失（censoring）的合理处理：删失独立性假设；
> * 竞争风险（competing risks）场景：例如死因特异生存；
> * **治疗分配机制**与**治疗起始时间**的严谨界定：不要用“随访期间发生”的信息作为基线协变量。

---

## 0.3.3 可复用的“因果 EDA 小工具”

> 这些函数在你用任何数据集时都能复用，建议放到一个 `eda_utils.py` 里。

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def smd_cont(x_t, x_c):
    mu_t, mu_c = np.nanmean(x_t), np.nanmean(x_c)
    sd_pool = np.sqrt((np.nanvar(x_t, ddof=1)+np.nanvar(x_c, ddof=1))/2)
    return (mu_t - mu_c) / (sd_pool + 1e-12)

def smd_binary(x_t, x_c):
    # 二分类变量的 SMD = (p1 - p0) / sqrt( p*(1-p) ), p 为总体合并比例
    p1, p0 = np.nanmean(x_t), np.nanmean(x_c)
    p = np.nanmean(np.r_[x_t, x_c])
    denom = np.sqrt(p*(1-p) + 1e-12)
    return (p1 - p0) / denom

def balance_table(df, treat_col, covs, cat_covs=None):
    """返回一个包含各协变量 SMD 的表格（连续按 smd_cont，分类按 smd_binary）"""
    cat_covs = set(cat_covs or [])
    tmask = df[treat_col] == 1
    cmask = df[treat_col] == 0
    rows = []
    for v in covs:
        if v in cat_covs or df[v].dropna().isin([0,1]).all():
            smd = smd_binary(df.loc[tmask, v], df.loc[cmask, v])
        else:
            smd = smd_cont(df.loc[tmask, v], df.loc[cmask, v])
        rows.append((v, smd))
    out = pd.DataFrame(rows, columns=["variable","SMD"]).sort_values("variable")
    return out

def plot_ps_overlap(ps_t, ps_c, bins=30):
    plt.figure()
    plt.hist(ps_t, bins=bins, alpha=0.6, label="Treatment")
    plt.hist(ps_c, bins=bins, alpha=0.6, label="Control")
    plt.xlabel("Propensity Score"); plt.ylabel("Count"); plt.legend(); plt.title("PS Overlap")
    plt.show()
```

---

## 0.3.4 常见坑与经验法则（新手最容易忽略的点）

1. **时间顺序错误**：把“治疗后才知道的信息”当作治疗前混杂（比如治疗后实验室指标）→ 会引入偏倚。
2. **不检查重叠**：极端倾向的样本让估计不稳定。看 PS 分布，必要时做 trimming（如去掉 PS<0.01 或 >0.99 的样本）。
3. **把中介当混杂**：中介在治疗后发生，不能作为调整变量（会“挡掉”真实效应的一部分）。
4. **把碰撞变量（collider）纳入模型**：会引入虚假关联。先画 DAG 或至少按临床路径梳理前因后果。
5. **变量泄露（leakage）**：用结局相关、但在真实预测/决策时不可用的信息（如出院后信息）进行建模。
6. **随意离散化**：粗暴把连续变量二分会损失信息，也可能改变可比性（除非有明确临床阈值）。
7. **样本选择偏倚**：排除了“太严重/太轻”的病例后得到的结论可能无法外推。记录清楚纳入排除标准。

---

### ✅ 本节你应达到的能力

* 能用 `DoWhy` 合成数据**加载+检查**：缺失、类型、基线平衡、PS 初步分布。
* 能拿一个公共医学数据集（UCI Heart）完成**基本 EDA**，并知道它**不直接适合做因果**（除非构造“伪暴露”做流程演练）。
* 知道如何把多表（MIMIC‑IV）合并出**首个 ICU 住院队列**、构造**结局**与**候选混杂**的骨架。
* 会使用**SMD 表**与**PS 重叠图**做“因果 EDA 小体检”。

---

配套代码:`003_01_Lalonde_Causal_EDA.ipynb` `003_02_UCI_Heart_with_Utils.ipynb`

