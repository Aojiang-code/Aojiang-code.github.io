# 📓 阶段 1 学习笔记 —— 医学因果推断的最小理论

## 1.1 因果推断与预测的区别

### **预测（Predictive Modeling）**

* **目标**：根据已知特征预测一个结果的数值或概率
* **核心问题**：在**当前条件**下，结果会是多少
* **例子（医学）**：

  * 用患者的年龄、性别、血压、化验结果预测**1 年内发生心梗的概率**
* **局限**：

  * 预测模型学到的可能是相关性，不一定是因果关系
  * 如果我们真的干预了变量（比如降血压），预测结果可能失效

### **因果推断（Causal Inference）**

* **目标**：估计一个变量（干预）对另一个变量（结果）的因果效应
* **核心问题**：如果我们**改变**某个变量，会导致结果怎样变化
* **例子（医学）**：

  * 判断降压药是否**真的**降低了中风发生率
* **特点**：

  * 关注干预的结果，而非被动观察
  * 需要考虑混杂因子

| 对比         | 预测模型         | 因果推断                |
| ---------- | ------------ | ------------------- |
| 目的         | 精准预测结果       | 估计干预的因果效应           |
| 数据要求       | 任意可预测模式      | 需要因果可识别的数据          |
| 是否能回答“为什么” | ❌            | ✅                   |
| 医学例子       | 预测 ICU 病人死亡率 | 估计早期抗生素是否降低 ICU 死亡率 |

---

## 1.2 Pearl 因果推断三层次（Causal Hierarchy）

Judea Pearl 将因果问题分为三层，复杂度和信息需求依次增加：

### **1️⃣ 关联（Association）**

* **定义**：两个变量之间的统计关系
* **问题形式**：

  > 已知症状 S，患者患病的概率是多少？
* **数学表示**：

  $$
  P(Y \mid X)
  $$
* **医学例子**：

  * 有吸烟史的人肺癌概率更高（但这并不能证明因果关系）

---

### **2️⃣ 干预（Intervention）**

* **定义**：如果我们强制设置某变量为特定值，结果会怎样变化
* **问题形式**：

  > 如果让患者每天服用药物 A，会怎样？
* **数学表示（do-运算）**：

  $$
  P(Y \mid do(X))
  $$
* **医学例子**：

  * 随机分配患者是否服用降糖药，比较 HbA1c 的变化

---

### **3️⃣ 反事实（Counterfactuals）**

* **定义**：假设现实相反，会发生什么
* **问题形式**：

  > 患者已经用了药物 A 并康复，如果他没用药，会怎样？
* **数学表示**：

  $$
  P(Y_{X=0} \mid X=1, Y=1)
  $$
* **医学例子**：

  * 癌症患者术后无复发，如果没做手术，是否会复发？

> 📌 **关键点**：
> 关联 → 干预 → 反事实 是递进关系
> 越高层级需要的假设越多、数据要求越高

---

## 1.3 混杂变量与偏倚

### **混杂变量（Confounder）**

* 定义：同时影响干预和结果的变量
* 作用：如果不调整混杂变量，因果效应可能被高估或低估
* 医学例子：

  * 研究吸烟（X）对肺癌（Y）的影响，职业（Z）可能是混杂因素（煤矿工人既更可能吸烟，也更易肺癌）

### **常见偏倚类型**

1. **选择偏倚（Selection Bias）**：样本不代表总体
2. **测量偏倚（Measurement Bias）**：变量测量误差
3. **遗漏变量偏倚（Omitted Variable Bias）**：缺失重要混杂变量

---

## 1.4 医学因果推断常用方法

### **1️⃣ 倾向评分匹配（Propensity Score Matching, PSM）**

* 核心思想：用倾向评分（患者接受治疗的概率）匹配相似的治疗组和对照组患者
* 步骤：

  1. 用逻辑回归预测每个患者接受治疗的概率（PS）
  2. 找到 PS 接近的患者配对
  3. 比较结果差异
* Python 实现：

```python
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import NearestNeighbors

# 1. 计算倾向评分
logit = LogisticRegression()
logit.fit(X_covariates, treatment)
ps = logit.predict_proba(X_covariates)[:,1]
```

* 优点：简单直观
* 缺点：可能丢失样本（匹配不到）

---

### **2️⃣ 倾向评分加权（Inverse Probability of Treatment Weighting, IPTW）**

* 核心思想：用倾向评分作为权重，让治疗组和对照组在基线特征上平衡
* 权重计算：

  * 治疗组：$w = 1/PS$
  * 对照组：$w = 1/(1-PS)$
* 优点：保留全部样本
* 缺点：极端 PS 值可能导致高权重 → 需截断

---

### **3️⃣ 工具变量（Instrumental Variables, IV）**

* 核心思想：找到一个变量 Z，它影响治疗 X，但不直接影响结果 Y（除非通过 X）
* 医学例子：

  * 用“医生开药倾向”作为工具变量，估计药物真实效果
* 常用方法：两阶段最小二乘（2SLS）

---

### **4️⃣ 双重稳健（Doubly Robust, DR）**

* 核心思想：同时建模倾向评分（PS）和结果模型，如果其中一个模型正确，估计仍然无偏
* 优点：在实际医学研究中鲁棒性高
* Python 实现可用 `econml` 或 `causalml`

---

## 1.5 因果图（DAG）与变量选择

### **因果图（Directed Acyclic Graph）**

* 节点：变量（X, Y, Z）
* 有向边：因果关系
* 无环：不能从一个节点出发又回到自己

#### 医学例子：

研究 **药物（X） → 血压（Y）** 的因果效应：

```
Age  →  X
Age  →  Y
X    →  Y
```

* 这里 Age 是混杂变量，需要调整

### **工具**

* **DAGitty**: 在线绘制因果图 → [https://dagitty.net/](https://dagitty.net/)
* **Python**:

```python
import networkx as nx
G = nx.DiGraph()
G.add_edges_from([("Age", "Drug"), ("Age", "BP"), ("Drug", "BP")])
```

---

## 📌 阶段 1 学习目标达成标准

* 能区分预测与因果推断
* 理解 Pearl 三层因果问题
* 能识别混杂变量与常见偏倚
* 理解 PSM / IPTW / IV / DR 四种常用方法
* 会画简单的医学因果图

---


