# ğŸ““ é˜¶æ®µ 2 å­¦ä¹ ç¬”è®° â€”â€” Python å®æˆ˜å…¥é—¨

## ğŸ¯ å­¦ä¹ ç›®æ ‡

* èƒ½ç”¨ Python åœ¨æ•°æ®ä¸Šè·‘å‡º **ATEï¼ˆå¹³å‡å› æœæ•ˆåº”ï¼‰** å’Œ **CATEï¼ˆæ¡ä»¶/ä¸ªä½“åŒ–å› æœæ•ˆåº”ï¼‰**
* å­¦ä¼šç”¨ `DoWhy`ã€`EconML`ã€`causalml` ç­‰å·¥å…·
* æŒæ¡åŒ»å­¦å¸¸è§åœºæ™¯ï¼ˆè¯ç‰©å¹²é¢„ã€ç”Ÿå­˜ç‡åˆ†æï¼‰çš„åŸºç¡€å®ç°æµç¨‹

---

## 2.1 ä½¿ç”¨ DoWhy è¿›è¡Œå› æœæ¨æ–­

### â‘  åŠ è½½å†…ç½® Lalonde æ•°æ®é›†

Lalonde æ•°æ®æ˜¯å› æœæ¨æ–­æ•™å­¦çš„â€œHello Worldâ€ï¼Œç›¸å½“äºæ¨¡æ‹Ÿäº†ä¸€æ¬¡ä¸´åºŠè¯•éªŒï¼š**å°±ä¸šåŸ¹è®­ï¼ˆå¹²é¢„ï¼‰ â†’ æ”¶å…¥ï¼ˆç»“æœï¼‰**ã€‚

```python
import dowhy.datasets
import pandas as pd

# åŠ è½½æ•°æ®ï¼ˆåŒ…å« treatment, outcome, æ··æ‚å› å­ï¼‰
data = dowhy.datasets.lalonde_binary()

df = data["df"]
print(df.head())
```

* `treatment`ï¼šæ˜¯å¦æ¥å—åŸ¹è®­ï¼ˆæ¨¡æ‹Ÿè¯ç‰©æ²»ç–—ï¼‰
* `re78`ï¼š1978 å¹´æ”¶å…¥ï¼ˆæ¨¡æ‹Ÿä¸´åºŠç»“å±€ï¼‰
* å…¶ä»–ï¼šæ··æ‚å˜é‡ï¼ˆå¹´é¾„ã€æ•™è‚²ã€ç§æ—ç­‰ï¼‰

---

### â‘¡ æ„å»ºå› æœæ¨¡å‹ï¼ˆDAGï¼‰

åœ¨ `DoWhy` é‡Œï¼Œæˆ‘ä»¬éœ€è¦ç”¨ **å› æœå›¾**ï¼ˆDAGï¼‰å‘Šè¯‰æ¨¡å‹ï¼šå“ªäº›å˜é‡æ˜¯æ··æ‚å› ç´ ã€‚

```python
from dowhy import CausalModel

model = CausalModel(
    data=df,
    treatment="treatment",
    outcome="re78",
    common_causes=["age","educ","black","hispan","married","nodegree","re74","re75"]
)

model.view_model()  # è¾“å‡ºå› æœå›¾
```

è¿™ä¸€æ­¥ç›¸å½“äºåœ¨ä¸´åºŠç ”ç©¶ä¸­æ˜ç¡®ï¼šå“ªäº›æ˜¯**åŸºçº¿åå˜é‡**ã€‚

---

### â‘¢ ä¼°è®¡æ²»ç–—æ•ˆæœï¼ˆATEï¼‰

DoWhy æ”¯æŒå¤šç§ä¼°è®¡æ–¹æ³•ï¼ˆå›å½’ã€PSMã€IPTW ç­‰ï¼‰ã€‚

```python
identified_estimand = model.identify_effect()
estimate = model.estimate_effect(
    identified_estimand,
    method_name="backdoor.propensity_score_matching"
)
print("ATE (PSM):", estimate.value)
```

è¾“å‡ºå³ä¸º **å¹³å‡å› æœæ•ˆåº”ï¼ˆATEï¼‰**ã€‚

---

### â‘£ å‡è®¾æ£€éªŒä¸æ•æ„Ÿæ€§åˆ†æ

```python
refutation = model.refute_estimate(
    identified_estimand,
    estimate,
    method_name="random_common_cause"
)
print(refutation)
```

è¿™ä¸€æ­¥ç±»ä¼¼åŒ»å­¦é‡Œçš„ **æ•æ„Ÿæ€§åˆ†æ**ï¼šæ£€éªŒç»“æœæ˜¯å¦ç¨³å¥ã€‚

---

## 2.2 ä½¿ç”¨ EconML è¿›è¡Œä¸ªä½“åŒ–æ²»ç–—æ•ˆæœä¼°è®¡ï¼ˆITE/CATEï¼‰

åœ¨ä¸´åºŠé‡Œï¼Œæˆ‘ä»¬ä¸ä»…è¦çŸ¥é“â€œå¹³å‡æ•ˆæœâ€ï¼Œè¿˜è¦çŸ¥é“**ä¸åŒæ‚£è€…æ˜¯å¦æœ‰å·®å¼‚åŒ–è·ç›Š**ã€‚è¿™æ—¶ç”¨ `EconML`ã€‚

### â‘  åŠ è½½ UCI Heart Disease æ•°æ®

```python
import pandas as pd

url = "https://raw.githubusercontent.com/selva86/datasets/master/Heart.csv"
df = pd.read_csv(url)
print(df.head())
```

å‡è®¾ï¼š

* `treatment` = æ˜¯å¦æœç”¨æŸè¯ç‰©ï¼ˆè¿™é‡Œå¯ç”¨ `AHD` å­—æ®µå‡è®¾ä¸ºæ²»ç–—æ ‡å¿—ï¼‰
* `Chol`ï¼ˆèƒ†å›ºé†‡ï¼‰ã€`Age`ã€`Sex` ç­‰ä½œä¸ºåå˜é‡

---

### â‘¡ T-learner / X-learner

```python
from econml.metalearners import TLearner, XLearner
from sklearn.ensemble import RandomForestRegressor

# å®šä¹‰ç‰¹å¾å’Œå˜é‡
X = df[["Age","Sex","Chol","RestBP"]]
T = (df["AHD"]=="Yes").astype(int)  # 0/1 å¤„ç†
Y = df["MaxHR"]

# T-learner
t_learner = TLearner(models=RandomForestRegressor())
t_learner.fit(Y, T, X=X)
cate_t = t_learner.effect(X)

print("ä¸ªä½“åŒ–æ²»ç–—æ•ˆåº”å‰ 5 ä¸ªï¼š", cate_t[:5])
```

* è¾“å‡ºçš„æ˜¯æ¯ä¸ªæ‚£è€…çš„ **CATE**ï¼Œå³â€œåœ¨ä»–çš„æ¡ä»¶ä¸‹ï¼Œæ²»ç–— vs ä¸æ²»ç–—çš„å·®å¼‚â€ã€‚

---

### â‘¢ è§£é‡Šä¸åŒæ‚£è€…çš„æ•ˆæœ

æˆ‘ä»¬å¯ä»¥ç”»å‡º CATE çš„åˆ†å¸ƒï¼Œçœ‹å“ªäº›äººç¾¤æ›´è·ç›Šã€‚

```python
import matplotlib.pyplot as plt
plt.hist(cate_t, bins=30)
plt.xlabel("Estimated CATE")
plt.ylabel("Patients")
plt.title("Distribution of Individual Treatment Effects")
plt.show()
```

è¿™ç±»ä¼¼åŒ»å­¦é‡Œçš„â€œ**å¼‚è´¨æ€§æ²»ç–—æ•ˆæœï¼ˆHTEï¼‰**â€ã€‚

---

## 2.3 å€¾å‘è¯„åˆ†åŒ¹é…ï¼ˆPSMï¼‰å®æˆ˜

### â‘  æ¨¡æ‹Ÿæ•°æ®ï¼šäºŒç”²åŒèƒæ²»ç–—

```python
import numpy as np

np.random.seed(42)
n = 500
age = np.random.randint(40,70,n)
bmi = np.random.normal(28,5,n)
treatment = np.random.binomial(1, p=1/(1+np.exp(-(0.1*age-0.2*bmi))), size=n)

# ç»“å±€ï¼ˆè¡€ç³–æ°´å¹³ï¼‰
y = 10 - 0.5*treatment + 0.05*age + 0.1*bmi + np.random.normal(0,1,n)

df = pd.DataFrame({"age":age,"bmi":bmi,"treatment":treatment,"y":y})
print(df.head())
```

---

### â‘¡ ä¼°è®¡å€¾å‘è¯„åˆ† + åŒ¹é…

```python
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import NearestNeighbors

# å€¾å‘è¯„åˆ†
logit = LogisticRegression()
logit.fit(df[["age","bmi"]], df["treatment"])
ps = logit.predict_proba(df[["age","bmi"]])[:,1]

df["ps"] = ps

# æœ€è¿‘é‚»åŒ¹é…
treated = df[df.treatment==1]
control = df[df.treatment==0]

nn = NearestNeighbors(n_neighbors=1).fit(control[["ps"]])
_, idx = nn.kneighbors(treated[["ps"]])
matched_control = control.iloc[idx.flatten()]
matched = pd.concat([treated, matched_control])
```

---

### â‘¢ åŒ¹é…å‰åå¹³è¡¡æ€§

```python
import seaborn as sns

sns.kdeplot(df[df.treatment==1]["ps"], label="Treated", shade=True)
sns.kdeplot(df[df.treatment==0]["ps"], label="Control", shade=True)
plt.title("å€¾å‘è¯„åˆ†åˆ†å¸ƒï¼ˆåŒ¹é…å‰ï¼‰")
plt.show()

sns.kdeplot(matched[matched.treatment==1]["ps"], label="Treated", shade=True)
sns.kdeplot(matched[matched.treatment==0]["ps"], label="Control", shade=True)
plt.title("å€¾å‘è¯„åˆ†åˆ†å¸ƒï¼ˆåŒ¹é…åï¼‰")
plt.show()
```

---

# âœ… é˜¶æ®µ 2 æ€»ç»“

1. **DoWhy** â†’ æœ€é€‚åˆå…¥é—¨ï¼Œèƒ½è·‘ **ATE + æ•æ„Ÿæ€§åˆ†æ**
2. **EconML** â†’ é€‚åˆç ”ç©¶ **CATE/ä¸ªä½“åŒ–æ•ˆåº”**ï¼Œä¸´åºŠå¼‚è´¨æ€§åˆ†æå¾ˆå¸¸ç”¨
3. **PSM å®æˆ˜** â†’ åŒ»å­¦ç ”ç©¶æœ€å¸¸è§æ–¹æ³•ï¼Œè¦æŒæ¡â€œå€¾å‘è¯„åˆ†åˆ†å¸ƒå¯¹é½ + å¹³è¡¡æ€§è¯Šæ–­â€

---

æŠŠè¿™ä¸‰éƒ¨åˆ†æ•´ç†æˆ **ä¸‰ä¸ªå¯è¿è¡Œ Notebook**ï¼ˆå«å®Œæ•´ä»£ç +æ³¨é‡Šï¼‰ï¼Œç›´æ¥æ”¾åˆ°ä¸‹è½½åŒº