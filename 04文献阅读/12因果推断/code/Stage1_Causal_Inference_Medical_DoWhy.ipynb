{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ©º Stage 1 â€” åŒ»å­¦å› æœæ¨æ–­å…¥é—¨ï¼ˆå¯è¿è¡Œ Notebookï¼ŒPython + DoWhyï¼‰\n",
        "\n",
        "æœ¬ Notebook ç›®æ ‡ï¼š\n",
        "1. ç”¨ä¸€ä¸ªåŒ»ç–—åŒ–çš„ç©å…·æ•°æ®å®Œæˆ**ä»å› æœå›¾åˆ° ATE ä¼°è®¡**çš„å®Œæ•´æµç¨‹ã€‚\n",
        "2. ç”¨ DoWhy è·‘é€š**è¯†åˆ« â†’ ä¼°è®¡ â†’ åé©³/æ•æ„Ÿæ€§åˆ†æ**çš„æ ‡å‡†ç®¡çº¿ã€‚\n",
        "3. é¡ºå¸¦ç»™å‡º**PS ä¼°è®¡ + IPTW çš„å¹³è¡¡æ€§æ£€æŸ¥**ä»£ç æ¨¡æ¿ï¼Œæ–¹ä¾¿è¿ç§»åˆ°åŒ»å­¦æ•°æ®ï¼ˆMIMIC/SEER ç­‰ï¼‰ã€‚\n",
        "\n",
        "**ä½ éœ€è¦å…ˆå®‰è£…ï¼š**\n",
        "```bash\n",
        "pip install pandas numpy matplotlib scikit-learn statsmodels dowhy econml causalml\n",
        "```\n",
        "\n",
        "---\n",
        "## ç›®å½•\n",
        "1. ç¯å¢ƒä¸æ•°æ®åŠ è½½ï¼ˆDoWhy å†…ç½®æ¨¡æ‹ŸåŒ»ç–—æ•°æ®ï¼‰\n",
        "2. å› æœå›¾ï¼ˆDAGï¼‰æ„å»ºä¸å¯è¯†åˆ«æ€§æ£€æŸ¥\n",
        "3. ATE/CATE ä¼°è®¡ï¼ˆå¤šæ–¹æ³•å¯¹æ¯”ï¼šçº¿æ€§å›å½’ã€PSMã€åˆ†å±‚ã€IPTWï¼‰\n",
        "4. åé©³ä¸æ•æ„Ÿæ€§åˆ†æï¼ˆRandom CC / Placebo / Subsetï¼‰\n",
        "5. PS + IPTW çš„åå˜é‡å¹³è¡¡æ€§ï¼ˆSMDï¼‰è¯Šæ–­\n",
        "6. ä¸´åºŠè§£é‡Šä¸ä¸‹ä¸€æ­¥ï¼ˆè¿ç§»åˆ°çœŸå®åŒ»å­¦æ•°æ®ï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 1. ç¯å¢ƒä¸æ•°æ®åŠ è½½ ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import dowhy\n",
        "from dowhy import CausalModel\n",
        "from dowhy import datasets as dy_datasets\n",
        "\n",
        "np.random.seed(42)\n",
        "print({\n",
        "    'numpy': np.__version__,\n",
        "    'pandas': pd.__version__,\n",
        "    'matplotlib': plt.matplotlib.__version__,\n",
        "    'dowhy': dowhy.__version__\n",
        "})\n",
        "\n",
        "# ä½¿ç”¨ DoWhy æ„é€ ä¸€ä¸ªâ€œåŒ»å­¦å‘³é“â€çš„æ¨¡æ‹Ÿæ•°æ®é›†ï¼š\n",
        "# treatment: æ˜¯å¦æ¥å—æŸè¯ç‰©ï¼ˆ1/0ï¼‰\n",
        "# outcome y: è¿ç»­å‹ç»“å±€ï¼Œä¾‹å¦‚ä½é™¢å¤©æ•°å‡å°‘é‡ï¼ˆæˆ–æŸç”Ÿç†æŒ‡æ ‡æ”¹å–„å€¼ï¼‰\n",
        "# v0...v4: åŸºçº¿åå˜é‡ï¼ˆå¹´é¾„ã€åˆå¹¶ç—‡è¯„åˆ†ç­‰æ··æ‚ï¼‰\n",
        "# z0: å·¥å…·å˜é‡ï¼ˆç±»ä¼¼åœ°ç†/åˆ¶åº¦å·®å¼‚å¸¦æ¥çš„å¤„ç½®æ¦‚ç‡å·®å¼‚ï¼‰\n",
        "data = dy_datasets.linear_dataset(\n",
        "    beta=8,\n",
        "    num_common_causes=5,\n",
        "    num_instruments=1,\n",
        "    num_samples=1500,\n",
        "    treatment_is_binary=True,\n",
        ")\n",
        "df = data['df'].copy()\n",
        "treatment = data['treatment_name']\n",
        "outcome = data['outcome_name']\n",
        "common_causes = data['common_causes_names']\n",
        "instruments = data['instrument_names']\n",
        "print('Columns:', df.columns.tolist())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å°å‹ EDAï¼šç¼ºå¤±ã€åˆ†å¸ƒã€åŸºçº¿å·®å¼‚\n",
        "print('Shape:', df.shape)\n",
        "print('Missing counts:\\n', df.isnull().sum())\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.hist(df[outcome], bins=30)\n",
        "ax.set_title('Outcome distribution')\n",
        "ax.set_xlabel(outcome)\n",
        "ax.set_ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.boxplot([df.loc[df[treatment]==0, outcome], df.loc[df[treatment]==1, outcome]], labels=['control','treated'])\n",
        "ax.set_title('Outcome by treatment group')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. å› æœå›¾ï¼ˆDAGï¼‰ä¸è¯†åˆ«\n",
        "æˆ‘ä»¬åŸºäºé¢†åŸŸçŸ¥è¯†ï¼ˆæ­¤å¤„ä¸ºæ•™å­¦ç¤ºèŒƒï¼‰æ„é€  DAGï¼šæ··æ‚å˜é‡ $v0\\dots v4$ å½±å“æ²»ç–—ä¸ç»“å±€ï¼›å·¥å…·å˜é‡ $z0$ å½±å“æ²»ç–—ä½†ä¸ç›´æ¥å½±å“ç»“å±€ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ„é€ å› æœæ¨¡å‹\n",
        "model = CausalModel(\n",
        "    data=df,\n",
        "    treatment=treatment,\n",
        "    outcome=outcome,\n",
        "    common_causes=common_causes,\n",
        "    instruments=instruments,\n",
        ")\n",
        "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
        "print(identified_estimand)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ATE ä¼°è®¡ï¼ˆå¤šæ–¹æ³•å¯¹æ¯”ï¼‰\n",
        "æˆ‘ä»¬ç”¨å››ç§å¸¸è§æ–¹æ³•ä¼°è®¡å¹³å‡å¤„ç†æ•ˆåº”ï¼ˆATEï¼‰ï¼š\n",
        "1. çº¿æ€§å›å½’ï¼ˆæ§åˆ¶æ··æ‚ï¼‰\n",
        "2. å€¾å‘è¯„åˆ†åŒ¹é…ï¼ˆPSMï¼‰\n",
        "3. å€¾å‘è¯„åˆ†åˆ†å±‚ï¼ˆStratificationï¼‰\n",
        "4. å€¾å‘è¯„åˆ†åŠ æƒï¼ˆIPTWï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "est_lr = model.estimate_effect(\n",
        "    identified_estimand,\n",
        "    method_name='backdoor.linear_regression',\n",
        ")\n",
        "print('ATE (Linear Regression):', est_lr.value)\n",
        "\n",
        "est_psm = model.estimate_effect(\n",
        "    identified_estimand,\n",
        "    method_name='backdoor.propensity_score_matching',\n",
        ")\n",
        "print('ATE (PSM):', est_psm.value)\n",
        "\n",
        "est_strat = model.estimate_effect(\n",
        "    identified_estimand,\n",
        "    method_name='backdoor.propensity_score_stratification',\n",
        ")\n",
        "print('ATE (Stratification):', est_strat.value)\n",
        "\n",
        "est_iptw = model.estimate_effect(\n",
        "    identified_estimand,\n",
        "    method_name='backdoor.propensity_score_weighting',\n",
        ")\n",
        "print('ATE (IPTW):', est_iptw.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. åé©³ä¸æ•æ„Ÿæ€§åˆ†æï¼ˆRefutationsï¼‰\n",
        "ç”¨ DoWhy å†…ç½® refuters åšä¸‰ç§å¿«é€Ÿç¨³å¥æ€§æ£€æŸ¥ï¼š\n",
        "- **Random Common Cause**ï¼šåŠ å…¥ä¸€ä¸ªéšæœºâ€œæ··æ‚â€ï¼Œçœ‹ä¼°è®¡æ˜¯å¦ç¨³å®šï¼›\n",
        "- **Placebo Treatment**ï¼šæŠŠå¤„ç†å˜é‡æ‰“ä¹±ï¼Œçœ‹æ˜¯å¦å‡ºç°ä¼ªæ•ˆåº”ï¼›\n",
        "- **Subset Refuter**ï¼šéšæœºæŠ½æ ·æ•°æ®å­é›†ï¼Œçœ‹æ•ˆåº”æ˜¯å¦ç¨³å¥ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ref_random_cc = model.refute_estimate(identified_estimand, est_iptw, method_name='random_common_cause')\n",
        "print(ref_random_cc)\n",
        "\n",
        "ref_placebo = model.refute_estimate(identified_estimand, est_iptw, method_name='placebo_treatment_refuter')\n",
        "print(ref_placebo)\n",
        "\n",
        "ref_subset = model.refute_estimate(identified_estimand, est_iptw, method_name='data_subset_refuter')\n",
        "print(ref_subset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. åå˜é‡å¹³è¡¡æ€§è¯Šæ–­ï¼ˆSMDï¼‰\n",
        "è™½ç„¶ DoWhy ä¼šå°è£… PS ä¸æƒé‡ï¼Œä½†æ—¥å¸¸åŒ»å­¦ç ”ç©¶é‡Œæˆ‘ä»¬é€šå¸¸**å•ç‹¬è®¡ç®— PS ä¸ IPTW**ï¼Œå¹¶å¯¹**å¹³è¡¡æ€§**åšå›¾/è¡¨æ£€æŸ¥ã€‚ä¸‹é¢ç»™å‡ºä¸€ä¸ª**å¯ç›´æ¥å¤ç”¨**çš„æ¨¡æ¿ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def standardized_mean_difference(x_t, x_c):\n",
        "    m_t, m_c = np.mean(x_t), np.mean(x_c)\n",
        "    s_t, s_c = np.var(x_t, ddof=1), np.var(x_c, ddof=1)\n",
        "    s_p = np.sqrt((s_t + s_c) / 2)\n",
        "    return (m_t - m_c) / s_p if s_p > 0 else 0.0\n",
        "\n",
        "X = df[common_causes].values\n",
        "T = df[treatment].values\n",
        "\n",
        "# é€»è¾‘å›å½’ä¼°è®¡ PS\n",
        "ps_model = make_pipeline(StandardScaler(with_mean=False), LogisticRegression(max_iter=200))\n",
        "ps_model.fit(df[common_causes], T)\n",
        "ps = ps_model.predict_proba(df[common_causes])[:,1]\n",
        "print('PS ROC-AUC (sanity check):', roc_auc_score(T, ps))\n",
        "\n",
        "# IPTW æƒé‡ï¼ˆç¨³å®šåŒ–ï¼‰\n",
        "p_t = T.mean()\n",
        "w = np.where(T==1, p_t/ps, (1-p_t)/(1-ps))\n",
        "\n",
        "# è®¡ç®—æƒé‡å‰å SMD\n",
        "smd_before = {}\n",
        "smd_after = {}\n",
        "for col in common_causes:\n",
        "    x_t = df.loc[T==1, col].values\n",
        "    x_c = df.loc[T==0, col].values\n",
        "    smd_before[col] = standardized_mean_difference(x_t, x_c)\n",
        "\n",
        "    # åŠ æƒå‡å€¼/æ–¹å·®ï¼ˆç”¨ç®€å•å®ç°è¿‘ä¼¼ï¼‰\n",
        "    wt_t = w[T==1]\n",
        "    wt_c = w[T==0]\n",
        "    xt = df.loc[T==1, col].values\n",
        "    xc = df.loc[T==0, col].values\n",
        "    m_t = np.average(xt, weights=wt_t)\n",
        "    m_c = np.average(xc, weights=wt_c)\n",
        "    v_t = np.average((xt-m_t)**2, weights=wt_t)\n",
        "    v_c = np.average((xc-m_c)**2, weights=wt_c)\n",
        "    s_p = np.sqrt((v_t + v_c)/2)\n",
        "    smd_after[col] = (m_t - m_c) / s_p if s_p > 0 else 0.0\n",
        "\n",
        "smd_df = pd.DataFrame({'SMD_before': smd_before, 'SMD_after_IPTW': smd_after})\n",
        "smd_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(range(len(smd_df)), smd_df['SMD_before'].values, label='Before')\n",
        "ax.scatter(range(len(smd_df)), smd_df['SMD_after_IPTW'].values, label='After')\n",
        "ax.axhline(0.1, linestyle='--')\n",
        "ax.axhline(-0.1, linestyle='--')\n",
        "ax.set_xticks(range(len(smd_df)))\n",
        "ax.set_xticklabels(smd_df.index, rotation=45, ha='right')\n",
        "ax.set_ylabel('Standardized Mean Difference')\n",
        "ax.set_title('Covariate Balance Before/After IPTW')\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ä¸´åºŠè§£é‡Šä¸ä¸‹ä¸€æ­¥\n",
        "- **æ•ˆåº”é‡ï¼ˆATEï¼‰**ï¼šå»ºè®®æŠ¥å‘Šä¼°è®¡å€¼ + 95% ç½®ä¿¡åŒºé—´ï¼Œå¹¶æ¯”è¾ƒå¤šæ–¹æ³•ç»“æœçš„ä¸€è‡´æ€§ã€‚\n",
        "- **å¹³è¡¡æ€§**ï¼šSMD \n",
        "  - å¸¸ç”¨é˜ˆå€¼ï¼š|SMD| < 0.1 è§†ä¸ºå¹³è¡¡è‰¯å¥½ï¼›0.1~0.2 éœ€è°¨æ…ï¼›>0.2 éœ€è¦è¿›ä¸€æ­¥å¤„ç†ï¼ˆé‡æ–°å»ºæ¨¡/éçº¿æ€§ PSï¼‰ã€‚\n",
        "- **è¿ç§»åˆ°çœŸå®æ•°æ®**ï¼š\n",
        "  1) ç”¨ MIMIC/SEER é€‰å–æ˜ç¡®çš„**æ²»ç–—**ä¸**ç»“å±€**ï¼›\n",
        "  2) ä¾æ®ä¸´åºŠçŸ¥è¯†ç”» DAGï¼Œé€‰â€œæœ€å°å……åˆ†è°ƒæ•´é›†â€ï¼›\n",
        "  3) é‡å¤æœ¬æµç¨‹ï¼Œå¹¶åšå¥½**ç¼ºå¤±å€¼å¤„ç†**ä¸**æ•æ„Ÿæ€§åˆ†æ**ï¼ˆæœªæµ‹æ··æ‚ï¼‰ã€‚\n",
        "\n",
        "â¡ï¸ ä¸‹ä¸€æ­¥æˆ‘å¯ä»¥æä¾›ä¸€ä¸ª **MIMIC-IV å­é›† + ICU è¯ç‰©å¯¹ 28 å¤©æ­»äº¡ç‡çš„å› æœæ¨æ–­** Notebook æ¨¡æ¿ï¼ŒåŒ…å«ç”Ÿå­˜åˆ†æï¼ˆIPTW + Coxï¼‰ã€‚"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}