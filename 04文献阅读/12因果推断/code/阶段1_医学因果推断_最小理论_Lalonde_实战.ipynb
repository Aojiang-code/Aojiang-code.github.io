{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b639b3e",
   "metadata": {},
   "source": [
    "\n",
    "# 医学因果推断 · 阶段 1\n",
    "**目标（2 天）**：只掌握必要的概念，能看懂代码背后的因果逻辑，并用 Python 在 **Lalonde** 数据集（或等价替代）上完成 ATE/ATT 的基础估计与稳健性检验。\n",
    "\n",
    "> 你可以**从上到下顺序运行**每个单元格。每个章节都包含**简短理论 + 可运行代码**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38d13c",
   "metadata": {},
   "source": [
    "\n",
    "## 0. 环境准备\n",
    "\n",
    "此单元格会安装本 Notebook 需要的包（如果已安装会自动跳过）。\n",
    "- 数据处理与可视化：`pandas`, `numpy`, `matplotlib`, `seaborn`\n",
    "- 统计与机器学习：`scikit-learn`, `statsmodels`\n",
    "- 因果推断：`dowhy`, `econml`（可选，用于进阶）, `causalml`（可选）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd49070",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, subprocess, pkgutil\n",
    "\n",
    "def ensure(pkg):\n",
    "    if pkg in {m.name for m in pkgutil.iter_modules()}:\n",
    "        print(f\"{pkg} already installed\")\n",
    "    else:\n",
    "        print(f\"Installing {pkg} ...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "# Core\n",
    "for p in [\"pandas\",\"numpy\",\"matplotlib\",\"seaborn\",\"scikit-learn\",\"statsmodels\"]:\n",
    "    ensure(p)\n",
    "\n",
    "# Causal packages\n",
    "for p in [\"dowhy\",\"econml\",\"causalml\"]:\n",
    "    try:\n",
    "        ensure(p)\n",
    "    except Exception as e:\n",
    "        print(f\"Optional package {p} could not be installed automatically: {e}\")\n",
    "        print(\"You can try installing it manually later if needed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877615a",
   "metadata": {},
   "source": [
    "\n",
    "## 1. 最小理论（Minimal Theory）\n",
    "\n",
    "### 1.1 预测 vs 因果\n",
    "- **预测**：在当前条件下，结果会是多少？（例如：预测 1 年内是否发生心梗）  \n",
    "- **因果**：如果我们**干预**（改变）某变量，结果会怎样？（例如：**用药 A 会不会降低心梗风险**）\n",
    "\n",
    "### 1.2 Pearl 三层次（Causal Hierarchy）\n",
    "1. **关联**：\\(P(Y\\mid X)\\) —— 观察到 X 时，Y 的分布。  \n",
    "2. **干预**：\\(P(Y\\mid do(X))\\) —— **强制设置** X 为某值后的 Y。  \n",
    "3. **反事实**：\\(P(Y_{x'} \\mid X=x, Y=y)\\) —— 实际发生与假设世界对比（“如果没用药，会怎样？”）。\n",
    "\n",
    "### 1.3 混杂变量（Confounders）与偏倚\n",
    "- **混杂变量**同时影响治疗（X）与结局（Y），若不调整会导致偏倚。  \n",
    "- 常见偏倚：选择偏倚、测量偏倚、遗漏变量偏倚。\n",
    "\n",
    "### 1.4 四类常用方法（本 Notebook 会含代码示例）\n",
    "- **PSM**：倾向评分匹配  \n",
    "- **IPTW**：逆概率加权  \n",
    "- **IV**：工具变量（演示思路）  \n",
    "- **DR**：双重稳健（AIPW / DR Learner）\n",
    "\n",
    "> 我们将以 **Lalonde**（就业培训）数据集做演示，它具有与临床场景相似的“治疗/对照 + 混杂”的结构。若在线下载失败，会回退到 **DoWhy 的合成数据**（结构近似）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afe76c8",
   "metadata": {},
   "source": [
    "\n",
    "## 2. 数据加载：Lalonde（含离线回退）\n",
    "\n",
    "优先从 **Rdatasets** 在线加载 `MatchIt/lalonde.csv`：  \n",
    "- `treat`：是否参加项目（类比是否接受治疗）  \n",
    "- `re78`：1978 年收入（类比结局）  \n",
    "- 调整变量：`age, educ, black, hispan, married, nodegree, re74, re75`（类比混杂因子）\n",
    "\n",
    "若网络不可用或下载失败，则**合成一个具备相同结构的模拟数据集**（DoWhy `linear_dataset`）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fce18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_lalonde():\n",
    "    url = \"https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/MatchIt/lalonde.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "        # Standardize column names\n",
    "        df = df.rename(columns={\"treat\":\"treat\", \"re78\":\"re78\"})\n",
    "        # The Rdatasets version includes an index column 'Unnamed: 0' or first column; drop if present\n",
    "        if df.columns[0].lower() in {\"\", \"unnamed: 0\", \"row\"}:\n",
    "            df = df.drop(columns=[df.columns[0]])\n",
    "        # keep relevant columns if present\n",
    "        cols = ['treat','re78','age','educ','black','hispan','married','nodegree','re74','re75']\n",
    "        present = [c for c in cols if c in df.columns]\n",
    "        df = df[present]\n",
    "        df['treat'] = df['treat'].astype(int)\n",
    "        print(\"Loaded Lalonde from web. Shape:\", df.shape)\n",
    "        source = \"lalonde_online\"\n",
    "        return df, source\n",
    "    except Exception as e:\n",
    "        print(\"Failed to load Lalonde online:\", e)\n",
    "        print(\"Falling back to synthetic dataset with Lalonde-like structure (DoWhy).\")\n",
    "        import dowhy.datasets as dwd\n",
    "        data = dwd.linear_dataset(\n",
    "            beta=800,                       # treatment effect magnitude (income scale)\n",
    "            num_common_causes=8,            # confounders\n",
    "            num_instruments=0,              # no IV in synthetic baseline\n",
    "            num_samples=614,                # approx. Lalonde size\n",
    "            treatment_is_binary=True,\n",
    "            stddev_treatment_noise=1.0,\n",
    "            outcome_is_binary=False,\n",
    "            num_effect_modifiers=0,\n",
    "            num_discrete_common_causes=5,\n",
    "            num_continuous_common_causes=3,\n",
    "            alpha=1.0\n",
    "        )\n",
    "        df = data[\"df\"]\n",
    "        # Align names to mimic Lalonde\n",
    "        rename_map = {c:f\"v{i}\" for i,c in enumerate([col for col in df.columns if col not in [\"treatment\",\"y\"]])}\n",
    "        for i,(old,new) in enumerate(rename_map.items()):\n",
    "            df[new] = df.pop(old)\n",
    "        df = df.rename(columns={\"treatment\":\"treat\",\"y\":\"re78\"})\n",
    "        print(\"Generated synthetic Lalonde-like dataset. Shape:\", df.shape)\n",
    "        source = \"lalonde_synthetic\"\n",
    "        return df, source\n",
    "\n",
    "df, data_source = load_lalonde()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affac520",
   "metadata": {},
   "source": [
    "\n",
    "## 3. 初步探索（EDA）与基线平衡\n",
    "\n",
    "在因果推断中，EDA 的重点是：\n",
    "- **治疗组 vs 对照组**在基线特征上的**平衡性**（是否存在系统性差异）  \n",
    "- 缺失值与异常值处理  \n",
    "- 连续/分类变量的分布\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c524c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# group counts\n",
    "print(\"\\nTreatment counts:\")\n",
    "print(df['treat'].value_counts())\n",
    "\n",
    "# quick numeric summary\n",
    "display(df.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c833a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 可选：查看治疗组与对照组在关键变量上的差异\n",
    "numeric_cols = [c for c in df.columns if df[c].dtype != 'O' and c not in ['treat']]\n",
    "for col in numeric_cols[:6]:  # show a few\n",
    "    sns.kdeplot(data=df, x=col, hue='treat', common_norm=False)\n",
    "    plt.title(f\"Distribution of {col} by treatment\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e529cda",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 平衡性诊断：标准化差异（SMD）\n",
    "\n",
    "标准化差异（Standardized Mean Difference, SMD）是衡量组间基线差异的常用指标：  \n",
    "\\( \\text{SMD} = \\frac{\\bar{x}_T - \\bar{x}_C}{s} \\)，其中 \\(s\\) 是合并标准差。  \n",
    "经验规则：\\(|\\text{SMD}| < 0.1\\) 通常认为平衡较好。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a79697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def smd_binary_mask(x, t):\n",
    "    x_t = x[t==1]; x_c = x[t==0]\n",
    "    m_t, m_c = np.mean(x_t), np.mean(x_c)\n",
    "    s = np.sqrt((np.var(x_t, ddof=1)+np.var(x_c, ddof=1))/2)\n",
    "    return (m_t - m_c)/s if s>0 else 0.0\n",
    "\n",
    "def smd_table(df, treat_col='treat', exclude=None):\n",
    "    if exclude is None: exclude=[]\n",
    "    t = df[treat_col].values\n",
    "    table = []\n",
    "    for col in df.columns:\n",
    "        if col in [treat_col] + exclude: \n",
    "            continue\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            val = smd_binary_mask(df[col].values, t)\n",
    "            table.append((col, val))\n",
    "    return pd.DataFrame(table, columns=['Variable','SMD']).sort_values('Variable')\n",
    "\n",
    "smd0 = smd_table(df, treat_col='treat', exclude=['re78'])\n",
    "display(smd0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d70415",
   "metadata": {},
   "source": [
    "\n",
    "## 4. 倾向评分匹配（PSM）\n",
    "\n",
    "**思路**：用逻辑回归建模 \\(P(T=1\\mid X)\\) 得到倾向评分（PS），对 PS 相近的个体进行匹配，从而在混杂变量上实现“可比性”。\n",
    "\n",
    "- 匹配策略：1:1 近邻匹配（不放回），可设置 caliper（半径）限制。  \n",
    "- 估计量：ATT（对已治疗者的平均处理效应）或 ATE（平均处理效应）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4443a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Define columns\n",
    "outcome_col = 're78'\n",
    "treat_col = 'treat'\n",
    "covariate_cols = [c for c in df.columns if c not in [outcome_col, treat_col]]\n",
    "\n",
    "# Drop rows with any na in required columns\n",
    "work = df[[outcome_col, treat_col] + covariate_cols].dropna().copy()\n",
    "\n",
    "# 1) Fit propensity model\n",
    "logit = LogisticRegression(max_iter=1000)\n",
    "X = work[covariate_cols].select_dtypes(include=[np.number]).values\n",
    "T = work[treat_col].values\n",
    "logit.fit(X, T)\n",
    "ps = logit.predict_proba(X)[:,1]\n",
    "work['ps'] = ps\n",
    "\n",
    "# 2) 1:1 nearest-neighbor matching on PS (within caliper optional)\n",
    "treated_idx = np.where(T==1)[0]\n",
    "control_idx = np.where(T==0)[0]\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(ps[control_idx].reshape(-1,1))\n",
    "distances, indices = nbrs.kneighbors(ps[treated_idx].reshape(-1,1))\n",
    "\n",
    "# Optional caliper to avoid bad matches\n",
    "caliper = 0.2 * np.std(ps)  # common heuristic\n",
    "pairs = []\n",
    "for i, (d, j) in enumerate(zip(distances.ravel(), indices.ravel())):\n",
    "    if d <= caliper:\n",
    "        t_i = treated_idx[i]\n",
    "        c_j = control_idx[j]\n",
    "        pairs.append((t_i, c_j))\n",
    "\n",
    "len(pairs), \"matched pairs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1767c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Compute ATT from matched pairs\n",
    "treated_outcomes = work.iloc[[i for i,_ in pairs]][outcome_col].values\n",
    "control_outcomes = work.iloc[[j for _,j in pairs]][outcome_col].values\n",
    "att = np.mean(treated_outcomes - control_outcomes)\n",
    "\n",
    "print(f\"PSM ATT (1:1, caliper={caliper:.3f}) = {att:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Balance after matching (SMD on matched sample)\n",
    "matched_rows = [i for i,_ in pairs] + [j for _,j in pairs]\n",
    "matched = work.iloc[matched_rows].copy()\n",
    "\n",
    "smd_psm = smd_table(matched.rename(columns={treat_col:'treat'}), treat_col='treat', exclude=[outcome_col,'ps'])\n",
    "display(smd_psm)\n",
    "\n",
    "print(\"Before matching: mean |SMD| =\", np.mean(np.abs(smd0['SMD'])))\n",
    "print(\"After  matching: mean |SMD| =\", np.mean(np.abs(smd_psm['SMD'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98652244",
   "metadata": {},
   "source": [
    "\n",
    "## 5. 倾向评分加权（IPTW）\n",
    "\n",
    "**思路**：用 \\(w=1/PS\\)（治疗组）与 \\(w=1/(1-PS)\\)（对照组）做加权回归，让两组在协变量上“像随机化”一样平衡。\n",
    "\n",
    "- 这里使用**稳定化权重**减少极端权重的影响。\n",
    "- 估计 ATE 与 ATT 均可，下面演示 ATE。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab91209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stabilized weights\n",
    "p_t = T.mean()  # marginal P(T=1)\n",
    "w = np.where(T==1, p_t/ps, (1-p_t)/(1-ps))\n",
    "\n",
    "work['w'] = w\n",
    "\n",
    "# Weighted ATE: difference in weighted means\n",
    "y = work[outcome_col].values\n",
    "ate_iptw = np.sum(w*(T*y))/np.sum(w*T) - np.sum(w*((1-T)*y))/np.sum(w*(1-T))\n",
    "\n",
    "print(f\"IPTW ATE (stabilized) = {ate_iptw:.2f}\")\n",
    "\n",
    "# Check weight distribution\n",
    "print(\"Weight summary:\")\n",
    "display(pd.Series(w).describe(percentiles=[.01,.05,.5,.95,.99]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5571450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Balance diagnostics after IPTW (reweight the sample and compute weighted SMD)\n",
    "def weighted_smd(x, t, w):\n",
    "    x_t = x[t==1]; x_c = x[t==0]\n",
    "    w_t = w[t==1]; w_c = w[t==0]\n",
    "    m_t = np.average(x_t, weights=w_t)\n",
    "    m_c = np.average(x_c, weights=w_c)\n",
    "    v_t = np.average((x_t-m_t)**2, weights=w_t)\n",
    "    v_c = np.average((x_c-m_c)**2, weights=w_c)\n",
    "    s = np.sqrt((v_t+v_c)/2)\n",
    "    return (m_t-m_c)/s if s>0 else 0.0\n",
    "\n",
    "rows = []\n",
    "for col in covariate_cols:\n",
    "    if pd.api.types.is_numeric_dtype(work[col]):\n",
    "        rows.append((col, weighted_smd(work[col].values, T, w)))\n",
    "smd_iptw = pd.DataFrame(rows, columns=['Variable','Weighted_SMD']).sort_values('Variable')\n",
    "display(smd_iptw)\n",
    "\n",
    "print(\"After IPTW: mean |Weighted SMD| =\", np.mean(np.abs(smd_iptw['Weighted_SMD'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae82bc5",
   "metadata": {},
   "source": [
    "\n",
    "## 6. 双重稳健（AIPW / DR）\n",
    "\n",
    "**思路**：同时建模**倾向评分**与**结果模型**，只要二者之一被正确指定，估计仍然无偏。\n",
    "\n",
    "下面使用最常见的 **AIPW** 实现 ATE：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b2ac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Fit outcome models E[Y|X,T=1] and E[Y|X,T=0]\n",
    "Xnum = work[covariate_cols].select_dtypes(include=[np.number]).values\n",
    "y = work[outcome_col].values\n",
    "\n",
    "m1 = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "m0 = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "m1.fit(Xnum[T==1], y[T==1])\n",
    "m0.fit(Xnum[T==0], y[T==0])\n",
    "\n",
    "mu1 = m1.predict(Xnum)\n",
    "mu0 = m0.predict(Xnum)\n",
    "\n",
    "# AIPW pseudo-outcome\n",
    "# psi = mu1 - mu0 + T*(y - mu1)/ps - (1-T)*(y - mu0)/(1-ps)\n",
    "psi = (mu1 - mu0) + T*(y - mu1)/ps - (1-T)*(y - mu0)/(1-ps)\n",
    "ate_aipw = psi.mean()\n",
    "print(f\"AIPW / DR ATE = {ate_aipw:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178599d2",
   "metadata": {},
   "source": [
    "\n",
    "## 7. 使用 DoWhy：因果图（DAG）→ 识别 → 估计 → 反驳/稳健性\n",
    "\n",
    "我们构造一个简单的 DAG：\n",
    "- `X=treat`（治疗）影响 `Y=re78`（结局）  \n",
    "- 混杂变量 `C`（用我们选择的一组基线特征近似）同时影响 X 与 Y  \n",
    "- 目标：估计 `ATE: E[Y|do(X=1)] - E[Y|do(X=0)]`\n",
    "\n",
    "> 注意：对于真实医学研究，你应根据临床知识绘制更贴近现实的 DAG。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dowhy import CausalModel\n",
    "\n",
    "# Select covariates available in our data as \"common_causes\"\n",
    "common_causes = [c for c in covariate_cols if pd.api.types.is_numeric_dtype(work[c])]\n",
    "\n",
    "# Build a simple DAG string\n",
    "# We'll treat all common_causes as parents of both treat and re78\n",
    "edges = []\n",
    "for c in common_causes:\n",
    "    edges.append(f\"{c} -> {treat_col}\")\n",
    "    edges.append(f\"{c} -> {outcome_col}\")\n",
    "edges.append(f\"{treat_col} -> {outcome_col}\")\n",
    "graph_str = \"digraph { \" + \"; \".join(edges) + \" }\"\n",
    "print(graph_str[:200] + \" ...\")\n",
    "\n",
    "model = CausalModel(\n",
    "    data=work[[outcome_col, treat_col] + common_causes],\n",
    "    treatment=treat_col,\n",
    "    outcome=outcome_col,\n",
    "    graph=graph_str\n",
    ")\n",
    "\n",
    "identified_estimand = model.identify_effect()\n",
    "print(identified_estimand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Estimate effect via different methods\n",
    "estimate_psw = model.estimate_effect(\n",
    "    identified_estimand,\n",
    "    method_name=\"backdoor.propensity_score_weighting\"\n",
    ")\n",
    "print(\"DoWhy PSW (ATE):\", estimate_psw.value)\n",
    "\n",
    "estimate_reg = model.estimate_effect(\n",
    "    identified_estimand,\n",
    "    method_name=\"backdoor.linear_regression\"\n",
    ")\n",
    "print(\"DoWhy Regression (ATE):\", estimate_reg.value)\n",
    "\n",
    "estimate_match = model.estimate_effect(\n",
    "    identified_estimand,\n",
    "    method_name=\"backdoor.propensity_score_matching\"\n",
    ")\n",
    "print(\"DoWhy PSM (ATT approx):\", estimate_match.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b00017",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Refutation tests (robustness checks)\n",
    "refute_placebo = model.refute_estimate(identified_estimand, estimate_psw, method_name=\"placebo_treatment_refuter\")\n",
    "print(\"\\nRefutation: placebo treatment ->\", refute_placebo)\n",
    "\n",
    "refute_random_common = model.refute_estimate(identified_estimand, estimate_psw, method_name=\"random_common_cause\")\n",
    "print(\"\\nRefutation: add random common cause ->\", refute_random_common)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06eb846",
   "metadata": {},
   "source": [
    "\n",
    "## 8. 工具变量（IV）思路（简述）\n",
    "\n",
    "当存在**未测混杂**时，PSM/IPTW 可能无法消除偏倚。若能找到满足 **相关性** 与 **排他性** 的工具变量 \\(Z\\)：  \n",
    "- **相关性**：\\(Z\\) 影响治疗 \\(X\\)；  \n",
    "- **排他性**：\\(Z\\) 只通过 \\(X\\) 影响结局 \\(Y\\)，不通过其它路径。\n",
    "\n",
    "在医学中，常见候选是**医生的处方倾向**或**地理可及性**。  \n",
    "实现上常用 **2SLS（两阶段最小二乘）**。此 Notebook 使用的数据没有天然的 IV，后续可以在你的真实研究中尝试。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7193a955",
   "metadata": {},
   "source": [
    "\n",
    "## 9. 小结与下一步\n",
    "\n",
    "你已经完成：\n",
    "- 用 **Lalonde**（或等价合成）数据做了 **PSM / IPTW / AIPW（DR）** 的 ATE/ATT 估计；\n",
    "- 用 **DoWhy** 完成了 **DAG → 识别 → 估计 → 反驳** 的闭环。\n",
    "\n",
    "**下一步建议（阶段 2 起）**：\n",
    "1. 使用 `econml` 的 `DRLearner`、`XLearner` 估计 **CATE/ITE**（个体化治疗效果）；  \n",
    "2. 在医学数据（如 **MIMIC-IV** 子集）上，完成一个真实世界问题（例如：早期抗生素对 ICU 28 天死亡率的影响）；  \n",
    "3. 强化 **平衡性诊断**：SMD 分布、Love plot、截断极端权重；  \n",
    "4. 做 **敏感性分析**（未测混杂强度的 E-value、Rosenbaum bounds 等）。\n",
    "\n",
    "> 如果你需要，我可以把“阶段 2：Python 实战”的完整 Notebook 再为你生成一份，直接衔接今天的结果。\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
