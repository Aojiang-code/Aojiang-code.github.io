下面是**第12章：评估指标与临床可用性**的详细学习笔记。
全程遵循你的技术约束：**DuckDB + CSV/Parquet + Python（pandas/Polars）+ Jupyter（VSCode）**，**不使用 SQL / Postgres**。
范式：**分组交叉验证（按 subject\_id）+ 统一评估脚本 + 可复现快照**。

---

# 第12章 评估指标与临床可用性

> **输入**（来自第10–11章）
>
> * `derived/model_table_latest.parquet`：含 `stay_id / subject_id / aki_label / 特征…`
> * 训练得到的 **OOF 概率**（或你也可在本章脚本内做 5 折 StratifiedGroupKFold 复算 OOF）
> * （如有）**结构化 holdout** 测试集

> **输出**
>
> * 指标汇总（AUROC、AUPRC、灵敏度/特异度、F1）、**校准**（可靠性图、Brier、校准截距/斜率、ECE）
> * **阈值建议**（基于验证集）与 **决策曲线分析（DCA）**
> * **亚组分析**（基线来源/年龄/性别/诊断/ICU 单位）与稳健性报告
> * 所有图表（PNG）与指标（JSON/CSV）快照

通用导入与数据装载（与第11章一致）：

```python
from pathlib import Path
import json, numpy as np, polars as pl, pandas as pd
from sklearn.model_selection import StratifiedGroupKFold
from sklearn.metrics import (
    roc_auc_score, average_precision_score, brier_score_loss,
    precision_recall_curve, roc_curve, confusion_matrix
)
from sklearn.calibration import calibration_curve
import matplotlib.pyplot as plt

DER = Path("data/derived"); DER.mkdir(parents=True, exist_ok=True)
df = pl.read_parquet(DER/"model_table_latest.parquet").to_pandas()

y = df["aki_label"].astype(int).values
groups = df["subject_id"].values
stay_id = df["stay_id"].values
```

---

## 12.1 AUROC、AUPRC、灵敏度/特异度、F1、校准（可靠性图、Brier）

### 12.1.1 指标选择与含义（简要）

* **AUROC**：排序能力（不随阈值），对不平衡数据**乐观**；可配合 PR-AUC。
* **AUPRC**：更关注正类表现，适合 **AKI（稀有）**；基线等于阳性率。
* **灵敏度（Recall）/特异度（TNR）/F1**：**阈值依赖**；请在验证集/交叉验证上选阈值，再在测试集报告。
* **校准（Calibration）**：概率是否“可信”。用 **可靠性图**、**Brier 分数**、**校准截距/斜率**、**ECE** 综合判断。

  * **Brier**：均方误差（越小越好）。
  * **截距≈0、斜率≈1** 理想（过/欠置信可见于斜率偏离 1）。
  * **ECE**（Expected Calibration Error）：分箱后预测与真实频率差的加权平均（越小越好）。

### 12.1.2 OOF 概率与全局指标（分组CV）

> 推荐先通过 5 折 **StratifiedGroupKFold** 得到 **OOF 概率**，再统一计算指标（更稳健）。

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, RobustScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression

# 载入列清单（第10章导出的）
with open(DER/"feature_columns.json","r",encoding="utf-8") as f:
    meta = json.load(f)
NUM_COLS, CAT_COLS = meta["num_cols"], meta["cat_cols"]
X = df[NUM_COLS + CAT_COLS].copy()

num_pipe = Pipeline([("imp", SimpleImputer(strategy="median")), ("scaler", RobustScaler(quantile_range=(25,75)))])
cat_pipe = Pipeline([("imp", SimpleImputer(strategy="most_frequent")), ("ohe", OneHotEncoder(handle_unknown="ignore", sparse_output=False))])
pre = ColumnTransformer([("num", num_pipe, NUM_COLS), ("cat", cat_pipe, CAT_COLS)], remainder="drop")

clf = LogisticRegression(penalty="l2", solver="liblinear", class_weight="balanced", max_iter=200)
pipe = Pipeline([("pre", pre), ("clf", clf)])

cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)
oof_pred = np.zeros(len(y))

for tr, te in cv.split(X, y, groups):
    pipe.fit(X.iloc[tr], y[tr])
    oof_pred[te] = pipe.predict_proba(X.iloc[te])[:,1]

auroc = roc_auc_score(y, oof_pred)
auprc = average_precision_score(y, oof_pred)
brier = brier_score_loss(y, oof_pred)
print({"OOF_AUROC": auroc, "OOF_AUPRC": auprc, "OOF_Brier": brier})
```

### 12.1.3 阈值依赖指标（灵敏度/特异度/F1）

> 在 **OOF** 或每折验证集上扫描阈值，选择最优阈值（例如最大 F1、或约束敏感度≥某值）。

```python
prec, rec, thr = precision_recall_curve(y, oof_pred)
f1 = 2*prec*rec/(prec+rec+1e-9)
best_idx = np.nanargmax(f1[:-1])
best_t = float(thr[best_idx])
print("Best threshold (OOF PR-F1):", best_t)

y_hat = (oof_pred >= best_t).astype(int)
tn, fp, fn, tp = confusion_matrix(y, y_hat).ravel()
sens = tp/(tp+fn+1e-9)  # Recall
spec = tn/(tn+fp+1e-9)
ppv  = tp/(tp+fp+1e-9)
npv  = tn/(tn+fn+1e-9)
f1_at_t = 2*ppv*sens/(ppv+sens+1e-9)
print({"sens": sens, "spec": spec, "ppv": ppv, "npv": npv, "f1": f1_at_t})
```

### 12.1.4 校准分析：可靠性图、Brier、截距/斜率、ECE

```python
# 可靠性图（10或20箱）
prob_true, prob_pred = calibration_curve(y, oof_pred, n_bins=10, strategy="quantile")

plt.figure()
plt.plot(prob_pred, prob_true, marker="o", label="Model")
plt.plot([0,1],[0,1], "--", label="Perfect")
plt.xlabel("Predicted probability"); plt.ylabel("Observed frequency")
plt.title("Reliability plot (OOF)")
plt.legend(); plt.tight_layout()
plt.savefig(DER/"calibration_reliability_oof.png", dpi=160)

# 校准截距/斜率：以 logit(p) 回归 y（需避免 p=0/1）
from sklearn.linear_model import LogisticRegression
eps = 1e-6
logit = np.log((oof_pred+eps)/(1-oof_pred+eps)).reshape(-1,1)
lr_cal = LogisticRegression(fit_intercept=True, solver="lbfgs")
lr_cal.fit(logit, y)
cal_intercept = lr_cal.intercept_[0]
cal_slope = lr_cal.coef_[0][0]
print({"cal_intercept": cal_intercept, "cal_slope": cal_slope})

# ECE（Expected Calibration Error）
def ece_score(y_true, y_prob, n_bins=10):
    bins = np.quantile(y_prob, np.linspace(0,1,n_bins+1))
    ece, N = 0.0, len(y_true)
    for i in range(n_bins):
        mask = (y_prob >= bins[i]) & (y_prob <= bins[i+1] if i==n_bins-1 else y_prob < bins[i+1])
        if mask.sum() == 0: 
            continue
        p_mean = y_prob[mask].mean()
        y_rate = y_true[mask].mean()
        ece += (mask.sum()/N)*abs(p_mean - y_rate)
    return float(ece)

ece = ece_score(y, oof_pred, n_bins=10)
print({"ECE_10bins": ece, "Brier": brier})
```

> 若发现**明显欠/过置信**（斜率远离 1），可在第11章中加入 **Platt/Isotonic 校准**（`CalibratedClassifierCV`，分组CV内进行），再在本章复评。

### 12.1.5 置信区间（推荐：**按患者分组**的自助法）

```python
rng = np.random.default_rng(42)
unique_subj = np.unique(groups)

def grouped_boot(y, p, groups, n_boot=1000):
    rocs, prs = [], []
    for _ in range(n_boot):
        # 以 subject 为单位有放回采样
        boot_subj = rng.choice(unique_subj, size=len(unique_subj), replace=True)
        idx = np.isin(groups, boot_subj)
        rocs.append(roc_auc_score(y[idx], p[idx]))
        prs.append(average_precision_score(y[idx], p[idx]))
    return (np.percentile(rocs, [2.5,50,97.5]), np.percentile(prs, [2.5,50,97.5]))

ci_roc, ci_pr = grouped_boot(y, oof_pred, groups, n_boot=1000)
print({"AUROC_CI": ci_roc.tolist(), "AUPRC_CI": ci_pr.tolist()})
```

---

## 12.2 临床阈值与决策曲线（DCA）

> **阈值选择**必须与**临床场景**对齐：
>
> * **高敏感度**（漏诊代价高）：固定灵敏度≥0.85，取最小 FP 的阈值；
> * **高精确度**（资源有限）：固定 PPV≥0.5，最大化灵敏度；
> * **F1/Youden’s J**：综合考虑；
> * **稳健性**：在外部/holdout 集上复核同一阈值下的表现。

### 12.2.1 目标阈值的几种策略

```python
# 1) 固定灵敏度目标（如 >= 0.85）
def threshold_for_sensitivity(y_true, y_prob, target_sens=0.85):
    prec, rec, thr = precision_recall_curve(y_true, y_prob)
    ok = np.where(rec[:-1] >= target_sens)[0]
    if len(ok)==0: return 0.0
    # 在满足灵敏度的阈值里选 PPV 最大的
    pick = ok[np.argmax(prec[ok])]
    return float(thr[pick])

t_sens = threshold_for_sensitivity(y, oof_pred, 0.85)

# 2) 固定 PPV 目标（如 >= 0.5）
def threshold_for_ppv(y_true, y_prob, target_ppv=0.5):
    prec, rec, thr = precision_recall_curve(y_true, y_prob)
    ok = np.where(prec[:-1] >= target_ppv)[0]
    if len(ok)==0: return 1.0
    # 满足 PPV 的阈值里选 Recall 最大的
    pick = ok[np.argmax(rec[ok])]
    return float(thr[pick])

t_ppv = threshold_for_ppv(y, oof_pred, 0.5)
```

### 12.2.2 决策曲线分析（Decision Curve Analysis, DCA）

* **净获益（Net Benefit）**：

  $$
  \text{NB}(\text{pt}) = \frac{TP}{N} - \frac{FP}{N}\cdot \frac{\text{pt}}{1-\text{pt}}
  $$

  其中 **pt** 为决策阈值（将概率阈值视作“干预阈值”），`TP/FP/N` 来自以 **pt** 为阈值的混淆矩阵。
* **参考曲线**：**Treat None（0）** 与 **Treat All（prevalence - (1-prevalence)\*pt/(1-pt)）**。
* **解读**：在某个阈值区间，若模型的 NB 高于两条参考曲线，说明**使用模型**优于“全治/不治”。

```python
def decision_curve(y_true, y_prob, pts=np.linspace(0.01, 0.99, 99)):
    N = len(y_true); prev = y_true.mean()
    nb_model, nb_all, nb_none = [], [], []
    for pt in pts:
        y_hat = (y_prob >= pt).astype(int)
        tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()
        nb = (tp/N) - (fp/N)*(pt/(1-pt))
        nb_model.append(nb)
        nb_all.append(prev - (1-prev)*(pt/(1-pt)))  # treat all
        nb_none.append(0.0)
    return pts, np.array(nb_model), np.array(nb_all), np.array(nb_none)

pts, nb_m, nb_a, nb_n = decision_curve(y, oof_pred)

plt.figure()
plt.plot(pts, nb_m, label="Model")
plt.plot(pts, nb_a, "--", label="Treat All")
plt.plot(pts, nb_n, ":", label="Treat None")
plt.xlabel("Threshold probability (pt)"); plt.ylabel("Net benefit")
plt.title("Decision Curve (OOF)")
plt.legend(); plt.tight_layout()
plt.savefig(DER/"decision_curve_oof.png", dpi=160)
```

> **实践建议**
>
> * 和临床讨论**pt 合理区间**（如 0.1–0.3）：在该区间内，选择 NB 最大的阈值。
> * 把所选阈值应用于 **holdout/外部** 集，报告**稳定性**。
> * 输出“代价表”（每 100 人中：TP、FP、FN、TN 的期望数量）辅助资源评估。

---

## 12.3 亚组分析与稳健性（肾功能基线、年龄/性别/诊断亚组）

> 目的：检查模型在**关键人群**上的一致性与可解释性，发现潜在**偏倚/脆弱性**。

### 12.3.1 建议的亚组维度

* **基线肌酐来源**（第6章路线B生成的 `baseline_source`: `7d/48h/0_24h`）
* **年龄分层**：`<40`、`40–64`、`65–79`、`≥80`（或你在第8章的 `age_bin_10yr`）
* **性别**：`M/F`
* **诊断/合并症**：**CKD/糖尿病/心衰** 等（由 `diagnoses_icd` 或 derived 合并症）
* **ICU 单位**：`first_careunit`（MICU/SICU/CCU/CSRU/TSICU…）
* **入院类型**：Emergency/Elective/Transfer

> 注：亚组标签与特征必须来自 **24h 截止前可得信息**；合并症若来源于整次住院诊断，需在方法学中解释其时间性假设（第8章已讨论）。

### 12.3.2 代码模板：分组指标 + 组间对比

```python
# oof_pred / y / df 可直接复用
def subgroup_metrics(df, y, p, by):
    out = []
    for g, d in df.groupby(by):
        idx = d.index.values
        if y[idx].sum() == 0 or (len(idx)-y[idx].sum()) == 0:
            continue  # 全0或全1组跳过
        out.append({
            by: g,
            "n": int(len(idx)),
            "prev": float(y[idx].mean()),
            "auroc": float(roc_auc_score(y[idx], p[idx])),
            "auprc": float(average_precision_score(y[idx], p[idx])),
            "brier": float(brier_score_loss(y[idx], p[idx]))
        })
    return pd.DataFrame(out).sort_values("n", ascending=False)

# 示例：基线来源/年龄段/性别/ICU 单位
if "baseline_source" in df.columns:
    m_base = subgroup_metrics(df, y, oof_pred, "baseline_source")
m_age  = subgroup_metrics(df, y, oof_pred, pd.cut(df["age"], bins=[0,40,65,80,150], right=False))
m_sex  = subgroup_metrics(df, y, oof_pred, "sex_m")  # 或直接对 sex 列分组
if "first_careunit" in df.columns:
    m_unit = subgroup_metrics(df, y, oof_pred, "first_careunit")

# 组间差异的粗检（如 AUROC 差值 >0.1 触发关注）
def flag_diff(tab, metric="auroc", gap=0.1):
    if tab is None or tab.empty: return None
    return tab.assign(flag=lambda d: (d[metric].max()-d[metric].min())>gap)

flag_diff(m_age, "auroc", 0.1)
```

### 12.3.3 稳健性与灵敏度分析建议

* **阈值迁移**：将验证期选定阈值迁移到 **外部/holdout**，对比灵敏度/PPV 变化。
* **标签敏感性**：

  * **SCr-only vs SCr+UO** 标签对模型的影响；
  * **排除 RRT** 后再评估（第6章）。
* **数据可得性**：在“低化验频次”人群中性能是否明显变差？可纳入“测量次数”作为协变量或分层。
* **去极值/单位转换**策略改变时的稳定性。
* **乐观偏倚防范**：亚组分析**不要**用于调参；仅作为**报告与审计**。

---

## 本章产出与自检

**建议写出：**

* `derived/metrics_oof.json`：AUROC、AUPRC、Brier、ECE、校准截距/斜率、最佳阈值
* `derived/calibration_reliability_oof.png`：可靠性图
* `derived/decision_curve_oof.png`：决策曲线
* `derived/subgroup_metrics.csv`：各亚组 AUROC/AUPRC/Brier/样本数/阳性率
* `derived/thresholds.json`：不同策略得到的阈值（F1 最大、固定敏感度/PPV、DCA 最优 pt）

**自检清单**

* [ ] 指标在 **分组CV（subject\_id）** 框架下计算，OOF 概率可复现
* [ ] 阈值**仅**在验证数据上选择，并在外部/holdout 上复核
* [ ] 报告 **AUROC + AUPRC + Brier + 校准（图/截距/斜率/ECE）**
* [ ] DCA 在临床讨论的 **pt 区间** 内给出净获益对比
* [ ] 亚组指标覆盖 **基线来源/年龄/性别/ICU 单位/诊断**，记录显著差异
* [ ] 所有结果（图/表/JSON）写入快照，保证**可追溯与可复现**

---

### 下一步（第13章预告）

* **模型解释与可审计性**：全局/个体 **SHAP**、特征重要性稳定性、误差案例审阅。
* **部署就绪**：固定阈值与**推理管线**（仅 0–24h 输入），给出“代价表”与告警策略。
