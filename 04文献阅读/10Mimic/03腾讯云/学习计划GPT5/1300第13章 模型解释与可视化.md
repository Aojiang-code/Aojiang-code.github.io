下面是**第13章：模型解释与可视化**的详细学习笔记。
始终遵循你的技术约束：**DuckDB + CSV/Parquet + Python（pandas/Polars）+ Jupyter（VSCode）**，**不使用 SQL / Postgres**。
范式：**按患者分组的交叉验证** + **sklearn Pipeline**，解释在**验证/测试数据**上完成，避免数据泄漏。

---

# 第13章 模型解释与可视化

## 13.1 全局与局部解释：特征重要度、SHAP

### 13.1.1 为什么要多视角解释

* **系数/重要度**：快速、成本低，但易受多重共线/编码影响。
* **Permutation importance**：模型无关、解释直观，但对相关特征“分摊”效应。
* **SHAP**（加性特征归因）：同时给**全局**（排序/分布）和**局部**（单个预测的贡献）解释，更贴近“个体风险说明”。

> 实战建议：**至少给出两类全球解释**（Permutation + SHAP bar/beeswarm），并在**个别病例**上给出 SHAP **waterfall**（或 force）图。

---

### 13.1.2 从 Pipeline 中取“可读的特征名”

我们在第11章用的是 `ColumnTransformer`（数值：插补+稳健缩放；类别：插补+OHE）。为了让系数/重要度/SHAP更好读，需要**展开后的列名**：

```python
# 工具函数：从 ColumnTransformer 取展开后的列名（兼容 OHE）
def get_feature_names(preprocess, num_cols, cat_cols):
    names = []
    if num_cols:
        names += list(num_cols)  # 数值列名保持不变（经过缩放但不改变数量）
    if cat_cols:
        ohe = preprocess.named_transformers_["cat"].named_steps["ohe"]
        cat_names = ohe.get_feature_names_out(cat_cols).tolist()
        names += cat_names
    return names
```

---

### 13.1.3 线性基线（Logistic）：系数与 SHAP（LinearExplainer）

> **注意**：解释应在**每个验证折**或**独立测试集**上完成；不要把训练拟合的信息“看穿”到验证集。

```python
import json, numpy as np, pandas as pd, polars as pl
from pathlib import Path
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, RobustScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedGroupKFold
from sklearn.metrics import average_precision_score
import shap

DER = Path("data/derived")
df = pl.read_parquet(DER/"model_table_latest.parquet").to_pandas()
with open(DER/"feature_columns.json","r",encoding="utf-8") as f:
    meta = json.load(f)
NUM_COLS, CAT_COLS = [c for c in meta["num_cols"] if c in df], [c for c in meta["cat_cols"] if c in df]

X = df[NUM_COLS + CAT_COLS].copy()
y = df["aki_label"].astype(int).values
groups = df["subject_id"].values

num_pipe = Pipeline([("imp", SimpleImputer(strategy="median")), ("scaler", RobustScaler(quantile_range=(25,75)))])
cat_pipe = Pipeline([("imp", SimpleImputer(strategy="most_frequent")),
                     ("ohe", OneHotEncoder(handle_unknown="ignore", sparse_output=False))])
pre = ColumnTransformer([("num", num_pipe, NUM_COLS), ("cat", cat_pipe, CAT_COLS)], remainder="drop")

clf = LogisticRegression(penalty="l2", solver="liblinear", class_weight="balanced", max_iter=200)
pipe = Pipeline([("pre", pre), ("clf", clf)])

cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)

global_coef = []
shap_global = None  # 存储 |SHAP| 的平均值
for k, (tr, te) in enumerate(cv.split(X, y, groups)):
    Xtr, Xte, ytr, yte = X.iloc[tr], X.iloc[te], y[tr], y[te]
    pipe.fit(Xtr, ytr)

    # 1) 系数（映射到展开后的特征名）
    Xte_mat = pipe.named_steps["pre"].transform(Xte)
    names = get_feature_names(pipe.named_steps["pre"], NUM_COLS, CAT_COLS)
    coef = pipe.named_steps["clf"].coef_.ravel()
    global_coef.append(pd.DataFrame({"feature": names, f"coef_fold{k}": coef}))

    # 2) SHAP（线性解释器，对标准化后的输入；background 用训练折的子样本）
    bg_idx = np.random.RandomState(0).choice(len(tr), size=min(2000, len(tr)), replace=False)
    bg = pipe.named_steps["pre"].transform(X.iloc[tr].iloc[bg_idx])
    expl = shap.LinearExplainer(pipe.named_steps["clf"], bg)
    shap_vals = expl.shap_values(Xte_mat)  # (n_te, n_features)
    # 全局：按 |SHAP| 平均
    fold_abs = np.abs(shap_vals).mean(axis=0)
    shap_df = pd.DataFrame({"feature": names, f"|shap|_fold{k}": fold_abs})
    shap_global = shap_df if shap_global is None else shap_global.merge(shap_df, on="feature", how="outer")

# 汇总
coef_table = global_coef[0]
for t in global_coef[1:]:
    coef_table = coef_table.merge(t, on="feature", how="outer")
coef_table["coef_mean"] = coef_table.filter(like="coef_fold").mean(axis=1)

shap_global["abs_shap_mean"] = shap_global.filter(like="|shap|_fold").mean(axis=1)

# Top-20（系数与SHAP）
top_coef = (coef_table.reindex(coef_table["coef_mean"].abs().sort_values(ascending=False).index)
                     .head(20)[["feature","coef_mean"]])
top_shap = (shap_global.reindex(shap_global["abs_shap_mean"].sort_values(ascending=False).index)
                      .head(20)[["feature","abs_shap_mean"]])
```

**解读要点**

* Logistic 的 `coef_mean` **方向**直观（正/负风险），但前提是**特征已标准化/单位一致**。
* SHAP 的 `abs_shap_mean` 是**影响力**大小排序，能跨模型对齐。

> **一热编码聚合**：对某个类别变量（如 `first_careunit`）的多个 one-hot 列，**可把 |SHAP| 求和**得到类级贡献；便于报告。

---

### 13.1.4 树模型（XGBoost/LightGBM）：SHAP（TreeExplainer）+ Permutation

对树模型，SHAP **高效**、**稳定**。Permutation importance 作为**交叉验证外推**的第二证据。

```python
import numpy as np, pandas as pd
from sklearn.model_selection import StratifiedGroupKFold
from sklearn.inspection import permutation_importance
from xgboost import XGBClassifier
import shap

# 复用 pre（ColumnTransformer）
def make_xgb(spw):
    return XGBClassifier(
        n_estimators=2000, max_depth=4, learning_rate=0.03,
        subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,
        tree_method="hist", eval_metric="aucpr", scale_pos_weight=spw, random_state=42
    )

cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)
perm_list, shap_list = [], []

for k, (tr, te) in enumerate(cv.split(X, y, groups)):
    Xtr, Xte, ytr, yte = X.iloc[tr], X.iloc[te], y[tr], y[te]
    # 先拟合预处理（避免数据泄漏：仅在训练折拟合）
    Xtr_mat = pre.fit_transform(Xtr)
    Xte_mat = pre.transform(Xte)
    names = get_feature_names(pre, NUM_COLS, CAT_COLS)

    spw = (len(ytr)-ytr.sum())/max(1,ytr.sum())
    xgb = make_xgb(spw)
    xgb.fit(Xtr_mat, ytr, eval_set=[(Xte_mat, yte)], verbose=False, early_stopping_rounds=100)

    # Permutation（在当前验证折上）
    pmi = permutation_importance(xgb, Xte_mat, yte, n_repeats=10, random_state=42, scoring="average_precision")
    perm_list.append(pd.DataFrame({"feature": names, f"perm_fold{k}": pmi.importances_mean}))

    # SHAP（TreeExplainer）
    expl = shap.TreeExplainer(xgb)
    sv = expl.shap_values(Xte_mat)   # (n_te, n_features)
    shap_list.append(pd.DataFrame({"feature": names, f"|shap|_fold{k}": np.abs(sv).mean(axis=0)}))

perm = perm_list[0]
for t in perm_list[1:]: perm = perm.merge(t, on="feature", how="outer")
perm["perm_mean"] = perm.filter(like="perm_fold").mean(axis=1)

shap_g = shap_list[0]
for t in shap_list[1:]: shap_g = shap_g.merge(t, on="feature", how="outer")
shap_g["abs_shap_mean"] = shap_g.filter(like="|shap|_fold").mean(axis=1)

top_perm = perm.sort_values("perm_mean", ascending=False).head(20)
top_shap = shap_g.sort_values("abs_shap_mean", ascending=False).head(20)
```

**局部解释（单病例）**

```python
# 选择一个验证样本做局部解释
i = int(np.argmax(xgb.predict_proba(Xte_mat)[:,1]))  # 风险最高的一个
shap.plots.waterfall(shap.Explanation(values=sv[i], base_values=expl.expected_value,
                                      feature_names=names, data=Xte_mat[i]))
```

> **发布友好**：局部解释图（waterfall/force）请**隐藏或替换可识别个体信息**；数值显示**保留单位与窗口**（如 “SCr\_last\_\_0\_24h (mg/dL)”）。

---

## 13.2 误差剖析：混淆样本、对比图

### 13.2.1 构建误差表（基于第12章的“最佳阈值”）

```python
import numpy as np, pandas as pd
from sklearn.metrics import precision_recall_curve, confusion_matrix

# 假设已有 OOF 概率 oof_pred（第12章）
prec, rec, thr = precision_recall_curve(y, oof_pred)
f1 = 2*prec*rec/(prec+rec+1e-9)
t_star = float(thr[np.nanargmax(f1[:-1])])

df_eval = df.copy()
df_eval["p"] = oof_pred
df_eval["y"] = y
df_eval["yhat"] = (df_eval["p"] >= t_star).astype(int)
df_eval["err_type"] = np.select(
    [
        (df_eval["y"]==1) & (df_eval["yhat"]==1),
        (df_eval["y"]==0) & (df_eval["yhat"]==0),
        (df_eval["y"]==1) & (df_eval["yhat"]==0),
        (df_eval["y"]==0) & (df_eval["yhat"]==1),
    ],
    ["TP","TN","FN","FP"],
    default="?"
)
df_eval["err_type"].value_counts()
```

### 13.2.2 哪些特征导致 FN/FP？（基于 SHAP 的对比）

> 做法：比较 **FN vs TP**、**FP vs TN** 的**平均 |SHAP|** 或**方向性 SHAP**，列出差异最大的前 N 项。

```python
def shap_gap_table(shap_df, err_df, kind=("FN","TP"), topn=15):
    # shap_df: 行=样本索引，列=特征名；值=SHAP（正负）
    idx_a = err_df.index[err_df["err_type"]==kind[0]]
    idx_b = err_df.index[err_df["err_type"]==kind[1]]
    a = shap_df.loc[idx_a].abs().mean(axis=0)
    b = shap_df.loc[idx_b].abs().mean(axis=0)
    out = pd.DataFrame({"feature": a.index, f"{kind[0]}": a.values, f"{kind[1]}": b.values})
    out["gap"] = out[f"{kind[0]}"] - out[f"{kind[1]}"]
    return out.sort_values("gap", ascending=False).head(topn)

# 以 LightGBM 的最后一折为例（示意）；生产中建议拼接所有验证折的 SHAP
# shap_matrix_te: DataFrame( n_te × n_features )，列名=names
# gap_fn = shap_gap_table(shap_matrix_te, df_eval.iloc[te], ("FN","TP"))
# gap_fp = shap_gap_table(shap_matrix_te, df_eval.iloc[te], ("FP","TN"))
```

**解读**

* **FN**（漏报）：看哪些特征在 FN 中**贡献较小**或**方向与期望相反**，可能提示**阈值偏高/特征缺失/测量不足**。
* **FP**（误报）：看哪些特征**过度推高**风险，可能需要**稳健聚合/去极值**或在训练中**加强校准**。

### 13.2.3 对比图与分布

* **风险分布直方图**：按 `y=0/1` 分组；可叠加阈值线 `t_star`。
* **校准分层**：按十分位分箱，画“预测 vs 真实”点图（第12章已有可靠性图）。
* **特征对比**：在 FN/TP、FP/TN 之间对关键特征画箱线/小提琴（论文图常用）。
* **相邻病例对比**：在相近风险区域取一对（`p` 接近）的 TP 与 FP，画**雷达图**或**表格**对比 Top-K 贡献特征（来自局部 SHAP）。

> 图像导出：`plt.savefig("xxx.png", dpi=300, bbox_inches="tight")`；论文首选 **.pdf/.svg** 矢量图。

---

## 13.3 报告图表规范（科研发表友好）

### 13.3.1 通用规范

* **标题/注释**：标注**任务**（0–24h 预测 24–48h AKI）、**队列**（首次 ICU、成人/科室）、**窗口**与**单位**。
* **图例与轴**：写清**变量单位**（如 “SCr (mg/dL)”）、**统计量**（median/IQR/last）、**样本量 n**。
* **可读性**：字号≥9 pt；线宽≥1 pt；DPI≥300；颜色对色盲友好（蓝/橙/灰等简单配色）。
* **一致性**：所有图保持**同一字体/字号/配色**；同类图的坐标范围/分箱一致。
* **隐私**：不展示可识别个体信息；病例图以**匿名 ID**展示，数值可四舍五入到临床无害粒度。

### 13.3.2 指标图

* **ROC/PR 曲线**：报告 **AUROC/AUPRC（均附95% CI）**；基线（prevalence）虚线。
* **可靠性图**：同时报告 **Brier、截距、斜率、ECE**。
* **DCA**：在临床讨论的阈值区间（例如 **0.1–0.3**）突出显示净获益最高的点，并在图注解释 pt 的含义。

### 13.3.3 解释图

* **全局**：

  * SHAP **bar**（Top-20 abs SHAP）+ **beeswarm**（展示方向性与密度）。
  * 如使用一热，**聚合到原始变量层级**（把同一前缀的 |SHAP| 求和），避免“同一变量多条小棒”。
* **局部**：

  * **waterfall**（单病例 Top-K 贡献）、必要时**force**；
  * 在图注中标注病例的 `p`、阈值 `t_star`、真实标签与关键观测时间点。

### 13.3.4 表格

* **总体性能表**：AUROC/AUPRC/Brier（均含 CI），**训练/验证/外部**并列；
* **阈值表**：不同策略的阈值（F1 最大、固定灵敏度/PPV、DCA最优），对应的敏感度/特异度/PPV/NPV；
* **亚组表**：按年龄/性别/ICU 单位/基线来源列出 AUROC/AUPRC/Brier 与样本数。

---

## 产出与自检（本章落地）

**建议写出**

* `derived/feature_importance_coef_lr.csv`、`feature_importance_perm_{model}.csv`、`feature_importance_shap_{model}.csv`
* `derived/plots/`：`shap_bar.png`、`shap_beeswarm.png`、`shap_waterfall_case123.pdf`、`risk_hist_by_label.png`、`confusion_counts.png`
* `derived/error_tables/`：`gap_FN_vs_TP.csv`、`gap_FP_vs_TN.csv`

**自检清单**

* [ ] 解释均在**验证/测试数据**上完成（无训练泄漏）
* [ ] 一热特征已**聚合回变量层级**以便解读
* [ ] 全局：Permutation + SHAP 均一致指向核心特征
* [ ] 局部：给出至少 1–3 个病例 waterfall/force 图，配阈值与单位说明
* [ ] 误差剖析覆盖 **FN/FP**，并将结论回写到**特征工程或阈值策略**
* [ ] 图表与表格满足**论文规范**（单位、窗口、样本量、CI、DPI）

---

### 下一步（收官预告）

* **第14章：部署与推理管线（可选）**：将第10–12章固化为推理脚本（仅 0–24h 输入），输出**风险分数 + 可解释摘要**。
* **补充材料**：把**数据与代码快照**、**图表与表格**、**方法学决策**（基线选择/标签规则）写进 README/Methods，确保可复现与可审计。
