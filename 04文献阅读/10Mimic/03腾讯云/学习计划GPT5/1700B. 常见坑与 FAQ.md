下面是\*\*附录 B：常见坑与 FAQ（时间戳、单位换算、极端值、合并键）\*\*的详细学习笔记。
坚持主线：**DuckDB-free、数据帧工作流（Polars/pandas + Parquet）**，示例在 VSCode + Jupyter 可直接用。

---

# B.1 时间戳与时间窗：最容易踩坑的地方

## B.1.1 关键事实与术语

* **去标识与时间偏移**：MIMIC 对每位患者的绝对日期做了**患者级偏移**；**跨患者不可比较绝对时间**。建模一律用**相对窗口**（锚点 `icustays.intime` 或 `admissions.admittime`）。
* **常见时间列**

  * 住院：`admittime/dischtime/deathtime`
  * ICU：`intime/outtime`
  * 事件：`charttime`（记录发生时刻）≠ `storetime`（入库时刻，可能滞后）
  * OMR：`chartdate`（**只有日期**）
* **窗口边界**：统一采用 **\[0h, 24h)** 半开区间，避免双计数。

## B.1.2 典型错误与修复

**错误 1：把 `storetime` 当作事件发生时间**
→ 用 `charttime` 做对齐；只有特殊场景才参考 `storetime`。

**错误 2：解析出“带时区”的时间**
→ 所有时间当**naive timestamp** 处理；避免自动加本地时区。

**错误 3：窗口越界或越窗泄漏**
→ 坚持用 `dt = charttime - intime`，过滤 `0h ≤ dt < 24h`。

**错误 4：多次 ICU 停留混淆**
→ 以 `stay_id` 为样本单位；需要**首次 ICU**时对 `icustays` 按 `subject_id` + `intime` 取首条。

**错误 5：OMR 的 `chartdate` 当 timestamp 用**
→ 只能做**天级**对齐（例如“住院当天/前后±N天”），勿混入小时级窗口。

## B.1.3 快速自检（Polars）

```python
import polars as pl

# 1) 时间类型、是否存在 tz
def assert_naive(df, cols):
    for c in cols:
        assert "Datetime" in str(df.schema[c]), f"{c} 不是时间类型"
        # Polars 的 Datetime 不带 tz，若读取为字符串需显式 parse

# 2) 窗口检查：任何特征表都应满足 0 ≤ dt < 24h
def window_sanity(df, t_evt="charttime", t_anchor="intime"):
    chk = (df
      .with_columns((pl.col(t_evt) - pl.col(t_anchor)).alias("dt"))
      .select([
        (pl.col("dt") < pl.duration(hours=0)).any().alias("has_negative"),
        (pl.col("dt") >= pl.duration(hours=24)).any().alias("has_over_24h"),
      ])
      .row(0))
    print({"negative": chk[0], "over_24h": chk[1]})

# 3) 首次 ICU 选取
icu_first = (icu.sort("intime")
               .groupby("subject_id").agg(pl.all().first()))
```

---

# B.2 单位换算与字典对齐：隐形踩坑王

## B.2.1 必背换算（示例）

| 指标                | 常见单位          | 目标单位      | 换算                       |
| ----------------- | ------------- | --------- | ------------------------ |
| **SCr（肌酐）**       | mg/dL, μmol/L | **mg/dL** | `mg/dL = μmol/L ÷ 88.4`  |
| **BUN**           | mg/dL, mmol/L | **mg/dL** | `mg/dL = mmol/L ÷ 0.357` |
| **Na/K/Cl/HCO₃⁻** | mmol/L        | mmol/L    | 通常无需换算                   |
| **pH**            | —             | —         | 无单位                      |
| **体温**            | °C, °F        | **°C**    | `°C = (°F - 32) × 5/9`   |
| **尿量**            | mL, L         | **mL**    | `mL = L × 1000`          |
| **体重**            | kg, lb        | **kg**    | `kg = lb × 0.453592`     |

> 关键：**先用字典筛 itemid → 再换算单位**。
> 字典：`mimiciv_hosp.d_labitems`（化验），`mimiciv_icu.d_items`（ICU 项目）。

## B.2.2 代码模板：稳健换算 & 监控

```python
import polars as pl

def standardize_labs(df, ids_scr, ids_bun):
    u = pl.col("valueuom").str.to_lowercase()
    return (df
      .with_columns([
        pl.when(pl.col("itemid").is_in(ids_scr) & u.is_in(["µmol/l","umol/l","μmol/l"]))
          .then(pl.col("valuenum")/88.4)
          .when(pl.col("itemid").is_in(ids_scr) & (u=="mg/dl"))
          .then(pl.col("valuenum"))
          .otherwise(pl.col("valuenum"))
          .alias("scr_mgdl"),
        pl.when(pl.col("itemid").is_in(ids_bun) & (u=="mmol/l"))
          .then(pl.col("valuenum")/0.357)
          .when(pl.col("itemid").is_in(ids_bun) & (u=="mg/dl"))
          .then(pl.col("valuenum"))
          .otherwise(pl.col("valuenum"))
          .alias("bun_mgdl"),
      ]))

# 单位异常监控：若 SCr 的 uom 不是 {mg/dL, μmol/L}，报警
def unit_audit(df, ids, allowed):
    bad = (df.filter(pl.col("itemid").is_in(ids))
             .select(pl.col("valueuom").str.to_lowercase().alias("uom"))
             .unique())
    bad = bad.filter(~pl.col("uom").is_in([s.lower() for s in allowed]))
    if bad.height > 0:
        print("⚠️ 未预期单位：", bad)
```

---

# B.3 极端值、重复与稳健统计：别被“脏数据”骗了

## B.3.1 极端值常见来源

* **设备抖动/录入错误**：温度 0°C、SpO₂ 250%、心率 500 等；
* **重复记录**：同一时刻的重复采集或系统写入；
* **单位未统一**：°F 混入 °C，μmol/L 混入 mg/dL；
* **医学不可能值**：负尿量、负实验室值（除少数指标）。

## B.3.2 策略优先级

1. **字典与单位统一**（B.2）；
2. **稳健统计**：聚合时优先 `median/IQR/last`；
3. **安全剪裁（clip）**：依据**临床合理范围**；
4. **去重**：同 `stay_id + itemid + charttime` 的近重复可先取中位；
5. **不要删除整行**（除非无法挽救），防止样本量骤减。

## B.3.3 代码片段

```python
# 轻量去重：同时刻多条 → 取中位
dedup = (df.groupby(["stay_id","itemid","charttime"])
           .agg(pl.col("valuenum").median().alias("val")))

# 医学安全剪裁（示例范围，可按人群调整）
CLIP = {
  "hr_":(20,250),"rr_":(4,80),"temp_c_":(25,45),"spo2_":(0,100),
  "sbp_":(40,300),"dbp_":(20,200),"map_":(20,200),
  "scr_":(0,20),"bun_":(0,200),"na_":(100,180),"k_":(1,10),"cl_":(60,140),"hco3_":(0,60)
}
def clip_by_prefix(df, rules=CLIP):
    out = df
    for p,(lo,hi) in rules.items():
        for c in df.columns:
            if c.startswith(p) and df[c].dtype.is_numeric():
                out = out.with_columns(pl.col(c).clip(lo,hi))
    return out
```

---

# B.4 合并键与连接：行爆炸与泄漏的“元凶”

## B.4.1 三层键与正确姿势

* **患者**：`subject_id`
* **住院**：`hadm_id`（`labevents` 贴住这里）
* **ICU 停留**：`stay_id`（`chartevents` 贴住这里）

**推荐连接路径**
1）先定 ICU 样本：`icustays (stay_id, hadm_id, intime)`
2）对化验：`labevents` **按 `hadm_id` 半连接** → 再用 `intime` 做 0–24h 窗口；
3）对 ICU 生命体征：`chartevents` **按 `stay_id` 连接** → 再做窗口。

> 反例：直接用 `hadm_id` 连接 `chartevents` 会把**同住院的多次 ICU 停留混在一起**。

## B.4.2 防止行爆炸（many-to-many join）

* 在连接前**先聚合**或**去重**（保证右表键唯一）；
* 写一个“**安全左连接**”工具：右表若不唯一先收敛到一行。

```python
def left_join_unique(a: pl.DataFrame, b: pl.DataFrame, on="stay_id"):
    if b.select(on).n_unique() != b.height:
        b = b.groupby(on).agg([pl.all().first()])
        b = b.explode(pl.all().exclude(on))
    return a.join(b, on=on, how="left")
```

## B.4.3 连接后自检（必须做）

```python
before = base.height
after = base.join(fea, on="stay_id", how="left").height
assert after == before, f"行数变化：{before} -> {after}，疑似行爆炸"

# 漏对齐检查：哪些 stay_id 没有命中右表
missing = base.join(fea.select(["stay_id"]), on="stay_id", how="anti").height
print("右表未命中条数：", missing)
```

---

# B.5 FAQ：十连问十连答

**Q1：为什么我 0–24h 的化验/生命体征是空的？**
A：多半是用错了时间列或窗口。检查：

* 是否用 `charttime`（不是 `storetime`）；
* 是否先按 `hadm_id` 连接再用 `intime` 过滤（对 `labevents`）；
* 窗口是 **\[0,24)** 而不是 (0,24]；
* 时间被读成字符串？先 `strptime`。

**Q2：为什么 SCr/BUN 数值离谱？**
A：单位没统一。确认 `valueuom`，按 B.2 换算；同时排查 °F/°C、L/mL 混用。

**Q3：特征统计“平均数很好看，IQR 却很大”？**
A：有极端值或多峰。报告中以 `median/IQR` 为主，必要时对“可疑设备段”单独处理。

**Q4：训练集 AUPRC 异常高，测试掉崖？**
A：高概率**泄漏**：

* 使用了 `dischtime/outtime/deathtime` 等**未来信息**；
* 标签窗信息误入特征（24–48h 的变量泄到 0–24h 特征）。重查窗口和列清单。

**Q5：join 后行数翻倍？**
A：many-to-many 连接。连接前对右表先**聚合到唯一键**；或用上面的 `left_join_unique`。

**Q6：尿量为什么几乎全空？**
A：你的 itemid 白名单可能不完整，或尿量记录集中在 `mimic-iv-derived`。先用 `d_items.label ~ 'urine|urinary output'` 扩大筛选，再看 0–24h 命中率。

**Q7：为什么“同一个变量多个 itemid”？**
A：来自不同表/设备/单位。建立**白名单映射**，并写到配置里（YAML）；聚合前做单位统一。

**Q8：分层/分组交叉验证提示“某折只有一个类别”？**
A：阳性太少或分组切分不均。使用 `StratifiedGroupKFold` 并调大折数/随机种子；或在训练前做**样本充足性检查**。

**Q9：为什么 cohort 样本比预期少？**
A：你启用了“首次 ICU”“最短 ICU 48h”“成人限定”等过滤；逐条关掉排查。

**Q10：如何快速定位“哪一步坏了”？**
A：每个阶段写 **Parquet 中间件** + **快照 JSON**（第10章）；对比**行数/缺失率**，用 anti-join 找丢失的键。

---

# B.6 Debug Recipe：三板斧

### B.6.1 键一致性

```python
def key_stats(df, key="stay_id"):
    return {
        "n_rows": df.height,
        "n_unique": df.select(key).n_unique(),
        "dup_rate": 1 - df.select(key).n_unique()/max(df.height,1)
    }
print(key_stats(cohort))
print(key_stats(features, "stay_id"))
```

### B.6.2 时间窗热力（命中率）

```python
# 每个 stay 的 0–24h 命中条数（例：SCr）
scr_hits = (scr_0_24h.groupby("stay_id").count().rename({"count":"n_scr"}))
scr_hits.describe()
```

### B.6.3 单位/范围巡检

```python
# 单位分布
(df.filter(pl.col("itemid").is_in(ids_scr))
   .select(pl.col("valueuom").str.to_lowercase().alias("uom"))
   .to_series().value_counts())

# 范围巡检（示例：SCR）
scr = features.select([c for c in features.columns if c.startswith("scr_")])
scr.select([pl.all().min(), pl.all().median(), pl.all().max()])
```

---

## 一页清单（落地前自检）

* [ ] **时间**：只用 `charttime` 与 **\[0,24)**；全为 naive timestamp；跨患者不比较绝对日期
* [ ] **单位**：SCr/BUN/体温/尿量/体重统一单位；`unit_audit` 无异常
* [ ] **极端值**：聚合用 `median/IQR/last`；按规则剪裁；重复按 `stay+item+time` 去重
* [ ] **键与连接**：`labevents` 按 `hadm_id` 半连接→按 `intime` 过滤；`chartevents` 用 `stay_id`；连接后行数不变
* [ ] **无泄漏**：不把 `outtime/dischtime/deathtime` 等未来列用于特征；标签窗严格隔离
* [ ] **中间件**：每一步物化 Parquet + 快照 JSON，记录行数/缺失率/输入 MD5

---

这份附录覆盖了 MIMIC-IV 项目里最常见、最“坑爹”的细节。建议把**单位白名单、医学范围、itemid 映射**写进你的 `default.yaml`，并在第14章的 DAG 中加入**单位审计与窗口审计**作为自动化检查步骤。
