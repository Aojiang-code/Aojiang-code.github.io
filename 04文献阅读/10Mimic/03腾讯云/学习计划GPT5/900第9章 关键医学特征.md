下面是**第9章：关键医学特征**的详细学习笔记。
全程遵循你的技术约束：**DuckDB + CSV/Parquet + Python（pandas/Polars）+ Jupyter（VSCode）**，**不使用 SQL / Postgres**。
本章产物：在 **特征窗 0–24h（以 `icustays.intime` 为锚）** 内生成**化验 / 生命体征 / 尿量与液体 / 药物暴露**等特征，并形成标准化 Parquet 输出，供第11章建模直接使用。

---

# 第9章 关键医学特征

> 变量命名约定：`<信号>_<统计量>__0_24h`，如 `scr_mean__0_24h`、`hr_iqr__0_24h`。
> 绝不越窗：**所有特征必须来自 `[intime, intime+24h)`**；标签来自 `[24h, 48h)`（见第6–7章）。

通用依赖与路径（以下代码片段默认可在同一 Notebook 复用）：

```python
from pathlib import Path
import polars as pl

RAW = Path("data/raw")
INTERIM = Path("data/interim"); INTERIM.mkdir(parents=True, exist_ok=True)
DERIVED = Path("data/derived"); DERIVED.mkdir(parents=True, exist_ok=True)

ICU = RAW/"mimiciv_icu/icustays.csv.gz"
D_LAB = RAW/"mimiciv_hosp/d_labitems.csv.gz"
LAB   = RAW/"mimiciv_hosp/labevents.csv.gz"
D_ITEMS = RAW/"mimiciv_icu/d_items.csv.gz"
CHART   = RAW/"mimiciv_icu/chartevents.csv.gz"
OMR = RAW/"mimiciv_hosp/omr.csv.gz"                   # 若存在
PRESC = RAW/"mimiciv_hosp/prescriptions.csv.gz"       # 药嘱（可选）
PROC  = RAW/"mimiciv_hosp/procedures_icd.csv.gz"      # 操作（可选）

# 基础 cohort（第7章产物，或现场构建）——最少字段
icu = (pl.scan_csv(ICU)
         .select(["subject_id","hadm_id","stay_id","intime","outtime","first_careunit"])
         .collect())

# 方便：把 intime 贴给后续数据，统一用 dt=charttime-intime 做窗过滤
stays = icu.select(["stay_id","hadm_id","subject_id","intime"])
```

---

## 9.1 化验：SCr、BUN、电解质、酸碱（均值/最大/最小/最近值/变化率）

### 9.1.1 选择项目与单位统一

* **SCr（肌酐）**：关键词 `creatin`；单位统一为 **mg/dL**（`mg/dL = μmol/L ÷ 88.4`）。
* **BUN（尿素氮）**：关键词 `bun`；统一 **mg/dL**（`mg/dL = mmol/L ÷ 0.357`）。
* **电解质**：`sodium|potassium|chloride`（常为 mmol/L）；
* **酸碱**：`bicarbonate|hco3|base excess|ph`（pH 无单位，bicarbonate 常 mmol/L）。

> 做法：对 `d_labitems` 用小写关键词筛 itemid → 在 `labevents` 惰性扫描时只读这些 item → 统一单位。

```python
# 1) 找 itemid
d_lab = pl.scan_csv(D_LAB).select(["itemid","label","fluid","category"]).collect()
def find_itemids(df, patterns):
    m = df.with_columns(pl.col("label").str.to_lowercase())
    keep = None
    for pat in patterns:
        cond = m["label"].str.contains(pat)
        keep = cond if keep is None else (keep | cond)
    return m.filter(keep).select("itemid","label").unique()

ids_scr = find_itemids(d_lab, ["creatin"]).select("itemid").to_series().to_list()
ids_bun = find_itemids(d_lab, [r"\bbun\b"]).select("itemid").to_series().to_list()
ids_na  = find_itemids(d_lab, ["sodium"]).select("itemid").to_series().to_list()
ids_k   = find_itemids(d_lab, ["potassium"]).select("itemid").to_series().to_list()
ids_cl  = find_itemids(d_lab, ["chloride"]).select("itemid").to_series().to_list()
ids_hco3= find_itemids(d_lab, ["bicarbonate","hco3"]).select("itemid").to_series().to_list()
ids_ph  = find_itemids(d_lab, [r"\bph\b"]).select("itemid").to_series().to_list()
lab_ids = set(ids_scr + ids_bun + ids_na + ids_k + ids_cl + ids_hco3 + ids_ph)
```

```python
# 2) 拉取 0–24h 化验明细并统一单位（只读必要列）
lab_core = (
    pl.scan_csv(LAB)
      .select(["hadm_id","itemid","charttime","valuenum","valueuom"])
      .filter(pl.col("itemid").is_in(list(lab_ids)))
      .filter(pl.col("valuenum").is_not_null())
      .collect(streaming=True)
      .join(stays, on="hadm_id", how="inner")
      .with_columns((pl.col("charttime") - pl.col("intime")).alias("dt"))
      .filter((pl.col("dt") >= pl.duration(hours=0)) & (pl.col("dt") < pl.duration(hours=24)))
)

# 单位统一
def standardize_units(df: pl.DataFrame) -> pl.DataFrame:
    u = pl.col("valueuom").str.to_lowercase()
    is_scr = df["itemid"].is_in(ids_scr)
    is_bun = df["itemid"].is_in(ids_bun)
    df = df.with_columns([
        pl.when(is_scr & u.is_in(["µmol/l","umol/l","μmol/l"]))
          .then(pl.col("valuenum")/88.4)
          .when(is_scr & (u=="mg/dl"))
          .then(pl.col("valuenum"))
          .otherwise(pl.col("valuenum")).alias("scr_val"),
        pl.when(is_bun & (u=="mmol/l"))
          .then(pl.col("valuenum")/0.357)
          .when(is_bun & (u=="mg/dl"))
          .then(pl.col("valuenum"))
          .otherwise(pl.col("valuenum")).alias("bun_val"),
    ])
    # 其它（Na/K/Cl/HCO3/pH）多数已统一，无需换算；保持原 valuenum 即可。
    df = df.with_columns(pl.col("valuenum").alias("val"))
    return df

lab_std = standardize_units(lab_core)
```

### 9.1.2 聚合统计与“变化率/趋势”

* **基础统计**：`mean/max/min/median/IQR/last/count`
* **变化率（rate）**：`(last - first) / 小时数`
* **斜率近似**：`(percentile(75) - percentile(25)) / 24h` 可作为稳健“坡度”近似

```python
def stat_block(col: str, prefix: str):
    return [
        pl.col(col).mean().alias(f"{prefix}_mean__0_24h"),
        pl.col(col).median().alias(f"{prefix}_median__0_24h"),
        (pl.col(col).quantile(0.75) - pl.col(col).quantile(0.25)).alias(f"{prefix}_iqr__0_24h"),
        pl.col(col).min().alias(f"{prefix}_min__0_24h"),
        pl.col(col).max().alias(f"{prefix}_max__0_24h"),
        pl.col(col).count().alias(f"{prefix}_n__0_24h"),
    ]

# 为每个 stay + 指标族生成宽表
def agg_lab(df: pl.DataFrame, ids: list[int], val_col: str, prefix: str):
    sub = df.filter(pl.col("itemid").is_in(ids))
    if sub.height == 0:
        return pl.DataFrame({"stay_id":[],})
    # last/first 需要按时间排序
    sub = sub.sort(["stay_id","charttime"])
    by = ["stay_id"]
    agg = (sub.groupby(by)
        .agg(
            stat_block(val_col, prefix) +
            [
              pl.col(val_col).first().alias(f"{prefix}_first__0_24h"),
              pl.col(val_col).last().alias(f"{prefix}_last__0_24h"),
            ]
        )
        .with_columns(
            (pl.col(f"{prefix}_last__0_24h") - pl.col(f"{prefix}_first__0_24h")).alias(f"{prefix}_delta__0_24h"),
            # 简单“每小时变化率”，以 24h 近似（若需要可用实际时间跨度替换 24）
            (pl.col(f"{prefix}_delta__0_24h") / 24.0).alias(f"{prefix}_rate__0_24h")
        )
    )
    return agg

F_scr = agg_lab(lab_std, ids_scr, "scr_val", "scr")
F_bun = agg_lab(lab_std, ids_bun, "bun_val", "bun")
F_na  = agg_lab(lab_std, ids_na,  "val",     "na")
F_k   = agg_lab(lab_std, ids_k,   "val",     "k")
F_cl  = agg_lab(lab_std, ids_cl,  "val",     "cl")
F_hco3= agg_lab(lab_std, ids_hco3,"val",     "hco3")
F_ph  = agg_lab(lab_std, ids_ph,  "val",     "ph")

FEA_LABS = (
    F_scr.join(F_bun, on="stay_id", how="outer")
         .join(F_na,  on="stay_id", how="outer")
         .join(F_k,   on="stay_id", how="outer")
         .join(F_cl,  on="stay_id", how="outer")
         .join(F_hco3,on="stay_id", how="outer")
         .join(F_ph,  on="stay_id", how="outer")
         .fill_null(None)  # 保留缺失，后续统一插补
)
FEA_LABS.write_parquet(INTERIM/"features_labs_0_24h.parquet")
```

---

## 9.2 生命体征：心率、呼吸、血压、体温、SpO₂（聚合与稳健统计）

### 9.2.1 选择 ICU 项目

* 用 `d_items.label` 关键字筛 `heart rate`, `respiratory rate`, `non invasive blood pressure systolic/diastolic` 或 `mean arterial pressure`, `temperature`, `spo2`（含 `oxygensaturation` 关键词）。
* 与 `chartevents` 连接后，仅取 **`[0,24h)`** 内的条目。

```python
d_items = pl.scan_csv(D_ITEMS).select(["itemid","label","unitname"]).collect()
def itemids_from_items(df, pats):
    m = df.with_columns(pl.col("label").str.to_lowercase())
    keep = None
    for p in pats:
        k = m["label"].str.contains(p)
        keep = k if keep is None else (keep | k)
    return m.filter(keep).select("itemid").to_series().to_list()

ids_hr  = itemids_from_items(d_items, ["heart rate"])
ids_rr  = itemids_from_items(d_items, ["respiratory rate"])
ids_temp= itemids_from_items(d_items, ["temperature"])
ids_spo2= itemids_from_items(d_items, ["spo2","oxygen saturation"])
ids_sbp = itemids_from_items(d_items, ["non invasive blood pressure systolic","systolic blood pressure"])
ids_dbp = itemids_from_items(d_items, ["non invasive blood pressure diastolic","diastolic blood pressure"])
ids_map = itemids_from_items(d_items, ["mean arterial pressure"])
```

```python
vital_core = (
    pl.scan_csv(CHART)
      .select(["stay_id","itemid","charttime","valuenum","valueuom"])
      .filter(pl.col("itemid").is_in(ids_hr + ids_rr + ids_temp + ids_spo2 + ids_sbp + ids_dbp + ids_map))
      .filter(pl.col("valuenum").is_not_null())
      .collect(streaming=True)
      .join(stays.select(["stay_id","intime"]), on="stay_id", how="inner")
      .with_columns((pl.col("charttime") - pl.col("intime")).alias("dt"))
      .filter((pl.col("dt") >= pl.duration(hours=0)) & (pl.col("dt") < pl.duration(hours=24)))
)

# 稳健预处理：去极值/单位统一（体温：若部分为 Fahrenheit → 转为 Celsius）
def clean_vitals(df: pl.DataFrame) -> pl.DataFrame:
    u = pl.col("valueuom").str.to_lowercase()
    val = pl.col("valuenum")
    # 温度转换（简化阈值判断）：若单位为 'f' 或值 > 80，认为华氏
    df = df.with_columns(
        pl.when((u.str.contains("f")) | (val > 80) & df["itemid"].is_in(ids_temp))
          .then((val - 32.0) * 5.0/9.0)
          .otherwise(val)
          .alias("val")
    )
    # 轻量去极值（winsorize 到 [1, 99] 百分位; 分项目做更精细更好）
    # 这里演示低成本方法：按 stay_id+itemid 先不 winsorize，聚合时用 median/IQR 替代平均
    return df

vital_std = clean_vitals(vital_core)
```

### 9.2.2 聚合（median/IQR 为主，辅以 min/max/last）

```python
def agg_vital(df: pl.DataFrame, ids: list[int], prefix: str):
    sub = df.filter(pl.col("itemid").is_in(ids)).sort(["stay_id","charttime"])
    if sub.height == 0:
        return pl.DataFrame({"stay_id": []})
    return (sub.groupby("stay_id")
        .agg([
            pl.col("val").median().alias(f"{prefix}_median__0_24h"),
            (pl.col("val").quantile(0.75) - pl.col("val").quantile(0.25)).alias(f"{prefix}_iqr__0_24h"),
            pl.col("val").min().alias(f"{prefix}_min__0_24h"),
            pl.col("val").max().alias(f"{prefix}_max__0_24h"),
            pl.col("val").last().alias(f"{prefix}_last__0_24h"),
            pl.count().alias(f"{prefix}_n__0_24h"),
        ]))

F_hr   = agg_vital(vital_std, ids_hr,   "hr")
F_rr   = agg_vital(vital_std, ids_rr,   "rr")
F_temp = agg_vital(vital_std, ids_temp, "temp_c")
F_spo2 = agg_vital(vital_std, ids_spo2, "spo2")
F_sbp  = agg_vital(vital_std, ids_sbp,  "sbp")
F_dbp  = agg_vital(vital_std, ids_dbp,  "dbp")
F_map  = agg_vital(vital_std, ids_map,  "map")

FEA_VITALS = (
    F_hr.join(F_rr, on="stay_id", how="outer")
       .join(F_temp, on="stay_id", how="outer")
       .join(F_spo2, on="stay_id", how="outer")
       .join(F_sbp, on="stay_id", how="outer")
       .join(F_dbp, on="stay_id", how="outer")
       .join(F_map, on="stay_id", how="outer")
)
FEA_VITALS.write_parquet(INTERIM/"features_vitals_0_24h.parquet")
```

---

## 9.3 尿量与液体平衡（若可得）：滚动窗口与体重归一化

### 9.3.1 数据来源与单位

* 尿量通常在 `chartevents` 中若干 item（标签含 `urine`/`output`）；或在 `mimic-iv-derived` 已有尿量聚合表。
* 体重来自 `omr`（门诊/体重）或 ICU 体重项（`d_items` 中 `weight`）；选择**接近 ICU 入科**的记录。
* 统一单位：尿量 **mL**；体重 **kg**。

```python
# 体重近似：从 OMR 取最近一次（简化示例）
if OMR.exists():
    omr = pl.scan_csv(OMR).select(["subject_id","chartdate","result_name","result_value","result_unit"]).collect()
    weight = (
        omr.filter(pl.col("result_name").str.to_lowercase().str.contains("weight"))
           .with_columns(pl.col("result_value").cast(pl.Float64))
           .drop_nulls(["result_value"])
           .groupby("subject_id").agg(pl.col("result_value").last().alias("weight_kg"))  # 近似
    )
else:
    weight = pl.DataFrame({"subject_id":[], "weight_kg":[]})
```

```python
# 尿量 itemid（示例正则）
ids_uo = itemids_from_items(d_items, ["urine", "urinary output", "urine output", "urine volume"])

uo = (
    pl.scan_csv(CHART)
      .select(["stay_id","itemid","charttime","valuenum","valueuom"])
      .filter(pl.col("itemid").is_in(ids_uo))
      .filter(pl.col("valuenum").is_not_null())
      .collect(streaming=True)
      .join(stays.select(["stay_id","subject_id","intime"]), on="stay_id", how="inner")
      .with_columns((pl.col("charttime") - pl.col("intime")).alias("dt"))
      .filter((pl.col("dt") >= pl.duration(hours=0)) & (pl.col("dt") < pl.duration(hours=24)))
)

# 单位统一到 mL（通常已是 mL；若见 'L' 则 ×1000）
uo = uo.with_columns(
    pl.when(pl.col("valueuom").str.to_lowercase().str.contains(r"\bl\b"))
      .then(pl.col("valuenum")*1000.0)
      .otherwise(pl.col("valuenum"))
      .alias("urine_ml")
)

# 0–24h 总尿量与 mL/kg/h（如有体重）
uo_agg = (uo.groupby("stay_id").agg([
            pl.col("urine_ml").sum().alias("uo_sum_ml__0_24h"),
            pl.count().alias("uo_n__0_24h"),
         ])
         .join(stays.select(["stay_id","subject_id"]), on="stay_id", how="left")
         .join(weight, on="subject_id", how="left")
         .with_columns(
             (pl.col("uo_sum_ml__0_24h") / (pl.col("weight_kg") * 24.0)).alias("uo_mlkgph__0_24h")
         ))

uo_agg.write_parquet(INTERIM/"features_urine_0_24h.parquet")
```

> **滚动窗口（6h/12h）**：可在 `uo` 明细上构造 6 小时滑窗累计并取最小值（KDIGO 尿量准则常看最低 6h/12h/24h 段）。在 0–24h 内滚动即可，避免越窗。

---

## 9.4 药物与干预（可选）：利尿剂、血管活性药、造影剂、RRT 指标

> 原则：**只统计 0–24h 内的“暴露”**（存在即 1），或统计**累计剂量**/**是否使用过**。
> 可能来源：`prescriptions/pharmacy`（药嘱/剂量），`procedures_icd`（造影、透析/CRRT），`chartevents`（用药事件，视表结构）。

示例：**利尿剂、血管活性药**（关键字法；产出二元暴露与累计剂量）

```python
if PRESC.exists():
    rx = (pl.scan_csv(PRESC)
            .select(["subject_id","hadm_id","starttime","stoptime","drug","dose_val_rx","dose_unit_rx"])
            .collect()
            .join(stays.select(["hadm_id","stay_id","intime"]), on="hadm_id", how="inner")
            .with_columns([
                (pl.col("starttime") - pl.col("intime")).alias("dt_start"),
                (pl.col("stoptime")  - pl.col("intime")).alias("dt_stop"),
                pl.col("drug").str.to_lowercase().alias("drug_lc")
            ])
            .filter((pl.col("dt_start") < pl.duration(hours=24)) & (pl.col("dt_stop") > pl.duration(hours=0))) # 与窗有交集
         )
    diuretics = rx.filter(pl.col("drug_lc").str.contains("furosemide|bumetanide|torsemide|hydrochlorothiazide"))
    vasopress = rx.filter(pl.col("drug_lc").str.contains("norepinephrine|epinephrine|vasopressin|dopamine|phenylephrine"))

    def rx_agg(df, prefix):
        if df.height==0: 
            return pl.DataFrame({"stay_id":[]})
        return (df.groupby("stay_id")
                 .agg([
                    pl.count().alias(f"{prefix}_any__0_24h"),
                    pl.col("dose_val_rx").sum().alias(f"{prefix}_dose_sum__0_24h"),
                 ])
                 .with_columns((pl.col(f"{prefix}_any__0_24h")>0).cast(pl.Int8).alias(f"{prefix}_used__0_24h"))
                )
    F_diur = rx_agg(diuretics, "diuretic")
    F_vaso = rx_agg(vasopress, "vaso")

    FEA_RX = F_diur.join(F_vaso, on="stay_id", how="outer").fill_null(0)
    FEA_RX.write_parquet(INTERIM/"features_rx_0_24h.parquet")
else:
    FEA_RX = pl.DataFrame({"stay_id":[]})
```

**造影剂/RRT 指标（可行路径）**

* 造影暴露：`prescriptions` 中含 `iodinated contrast`、或 `procedures_icd` 里与影像造影相关的代码（关键字/映射表）。
* RRT：`procedures_icd` 中透析相关代码；或 ICU 事件（若有 CRRT/HD 流程记录）。在 **0–24h** 内暴露可做二元特征 `rrt_used__0_24h=1`。

---

## 9.5 缺失机制与插补：MCAR/MAR/MNAR 讨论与实践策略

### 9.5.1 缺失机制

* **MCAR**（完全随机缺失）：少见；
* **MAR**（条件随机缺失）：更常见，缺失与已观测变量相关（如病轻者少抽血）；
* **MNAR**（非随机缺失）：缺失与未观测或变量自身相关（如很危重才监测特定指标）。

**在 EHR 中常见缺失并非 MCAR**，因此**将“缺失本身”作为信息**很重要。

### 9.5.2 实操策略（与第11章建模配合）

1. **缺失指示器**：为关键数值特征添加 `_missing` 二元列（缺失=1）。
2. **插补**：

   * 线性模型/距离模型（如逻辑回归）需要完整矩阵 → **训练集上**用 `median`/`most_frequent` 拟合插补器，再应用到验证/测试；
   * 树模型（XGBoost/LightGBM）对缺失较鲁棒，但 scikit-learn 的 RF/GB 仍需插补。
3. **稳健缩放**：对明显偏态变量（如 SCr、BUN）可在模型管道中做 `RobustScaler`（仅在训练集拟合）。
4. **不要泄漏**：所有“**拟合**”步骤（分布、插补器、缩放器、目标编码等）必须只在训练折/训练集上完成。

```python
# 为 features 表添加缺失指示器（示例：对 labs 与 vitals）
FEA_LABS = pl.read_parquet(INTERIM/"features_labs_0_24h.parquet")
FEA_VITALS = pl.read_parquet(INTERIM/"features_vitals_0_24h.parquet")
cols_num = [c for c in FEA_LABS.columns if c!="stay_id"] + [c for c in FEA_VITALS.columns if c!="stay_id"]

def add_missing_flags(df: pl.DataFrame, cols):
    flags = {f"{c}__missing": df[c].is_null().cast(pl.Int8) for c in cols if c in df.columns}
    return df.with_columns(list(flags.values()))

FEA_LABS_M = add_missing_flags(FEA_LABS, FEA_LABS.columns)
FEA_VITALS_M = add_missing_flags(FEA_VITALS, FEA_VITALS.columns)

# 合并为“临床特征层”
FEA_CLINICAL = (FEA_LABS_M.join(FEA_VITALS_M, on="stay_id", how="outer")
                              .join(pl.read_parquet(INTERIM/"features_urine_0_24h.parquet"), on="stay_id", how="left")
                              .join(pl.read_parquet(INTERIM/"features_rx_0_24h.parquet") if (INTERIM/"features_rx_0_24h.parquet").exists() else pl.DataFrame({"stay_id":[]}),
                                    on="stay_id", how="left"))

FEA_CLINICAL.write_parquet(DERIVED/"features_clinical_0_24h.parquet")
```

> **在第11章**我们会把 `features_basic_0_24h.parquet`（第8章）与本章的 `features_clinical_0_24h.parquet`、以及你可能已有的其他 0–24h 特征（如合并症、用药等）拼成**统一训练矩阵**，并演示**训练内拟合的插补与缩放管道**（`Pipeline`/`ColumnTransformer`）。

---

## 本章产出与自检

**写入文件**

* `interim/features_labs_0_24h.parquet`
* `interim/features_vitals_0_24h.parquet`
* `interim/features_urine_0_24h.parquet`（若可得）
* `interim/features_rx_0_24h.parquet`（若可得）
* `derived/features_clinical_0_24h.parquet`

**自检清单**

* [ ] 所有特征均来自 `[0h,24h)`；无标签窗/未来信息
* [ ] 化验单位统一（`scr/bun` 已换算），聚合含 `median/IQR/last` 与 `delta/rate`
* [ ] 生命体征用稳健统计（`median/IQR`），体温统一到 °C
* [ ] 尿量以 mL 基础，若有体重则给出 `mL/kg/h`；滚动窗不越界
* [ ] 药物/干预暴露限定在 `0–24h` 并给出二元/剂量特征
* [ ] 已添加 `_missing` 缺失指示器；数值缺失**留到建模管道**中用训练集拟合插补
* [ ] 所有中间结果物化为 Parquet，便于复用与审计

---

如果这章的风格与深度符合你的预期，下一步我可以把以上代码**整理成两份可直接运行的 Notebook**：

1. `09_labs_vitals_features.ipynb`（化验 + 生命体征 + 尿量）
2. `09_med_exposure_features.ipynb`（药物/干预）
   并加上一个小型 `config.yaml`（包含关键词/白名单 itemid、是否启用尿量/药物等），方便你在腾讯云上“一键跑完 0–24h 特征层”。
