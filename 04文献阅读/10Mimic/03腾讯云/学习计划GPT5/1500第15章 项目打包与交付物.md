下面是**第15章：项目打包与交付物**的详细学习笔记。
始终遵循你的技术约束：**DuckDB + CSV/Parquet + Python（pandas/Polars）+ Jupyter（VSCode）**，**不使用 SQL / Postgres**。目标是让他人拿到你的仓库后，**一键从 MIMIC-IV CSV 跑到评估指标与图表**，并且每一步都**可复现、可审计**。

---

# 第15章 项目打包与交付物

## 15.1 最终目录树与 README 模板

### 15.1.1 目录树（交付版）

```
project/
├─ data/
│  ├─ raw/                      # 放 MIMIC-IV 原始 CSV（只读，不提交）
│  │  ├─ mimiciv_hosp/*.csv.gz
│  │  ├─ mimiciv_icu/*.csv.gz
│  │  └─ (可选) mimiciv_derived/*.csv.gz
│  ├─ interim/                  # 中间特征（Parquet，自动生成）
│  └─ derived/                  # 建模表/标签/评估输出（Parquet/JSON/PNG）
│
├─ notebooks/
│  ├─ 06_labels_scr_only.ipynb
│  ├─ 07_build_cohort.ipynb
│  ├─ 09_features_labs_vitals.ipynb
│  ├─ 10_model_table_build.ipynb
│  ├─ 11_baselines_cv.ipynb
│  ├─ 12_eval_and_calibration.ipynb
│  └─ 13_explainability.ipynb
│
├─ src/
│  ├─ configs/
│  │  ├─ default.yaml
│  │  ├─ dev.small.yaml           # 小样本/快速验证
│  │  └─ prod.full.yaml           # 全量跑
│  ├─ pipeline/
│  │  ├─ dag.py                   # 极简任务引擎（第14章）
│  │  ├─ io.py                    # 原子写/读取封装
│  │  ├─ features.py              # 第8–9章函数
│  │  ├─ labels.py                # 第6章函数
│  │  ├─ model.py                 # 第11–12章训练/评估
│  │  └─ utils.py                 # 公共小工具（计时/日志等）
│  └─ utils/
│     ├─ hashing.py               # 配置/文件指纹
│     └─ logging.py
│
├─ scripts/
│  ├─ unzip_mimiciv_data.sh       # 你已提供（落盘到 data/raw/*）
│  └─ run_all.sh                  # 一键从 CSV → 指标（调用 run.py）
│
├─ reports/
│  ├─ figures/                    # ROC/PR/校准/DCA/SHAP 图
│  ├─ metrics/                    # JSON/CSV 指标、cache_index.json
│  └─ tables/                     # 子组指标/阈值表等
│
├─ run.py                         # 命令行入口（任务编排）
├─ README.md                      # 交付文档（模板见下）
├─ requirements.txt 或 pyproject.toml
├─ LICENSE                        # 代码许可（与 MIMIC 数据协议无冲突）
└─ .gitignore / .gitattributes / .gitkeep
```

> **不提交**：`data/raw/` 及任何可能含受限数据的文件。用 README 说明“如何把 MIMIC CSV 放到正确位置”。

### 15.1.2 README 模板（可直接粘贴）

```markdown
# AKI Prediction from MIMIC-IV (DuckDB-free, DataFrame Workflow)

**Task**: Use features in ICU first 24h to predict AKI (KDIGO ≥ Stage 1) in 24–48h.  
**Stack**: Python + Polars/pandas + PyArrow + scikit-learn + Parquet；No SQL/Postgres；可在 VSCode + Jupyter 运行。

## 1. Compliance & Data
- **MIMIC-IV** 数据需遵循 PhysioNet/CITI/DUA。仓库不包含任何原始数据或受限文件。
- 将原始 CSV 放入：
```

data/raw/mimiciv\_hosp/*.csv.gz
data/raw/mimiciv\_icu/*.csv.gz
(可选) data/raw/mimiciv\_derived/\*.csv.gz

````
- （可选）执行 `scripts/unzip_mimiciv_data.sh` 将下载的压缩包展开到上述目录。

## 2. Environment
```bash
# 任选其一
pip install -r requirements.txt
# 或
pip install uv && uv pip install -r requirements.txt
````

> 建议 Python ≥ 3.10；CPU 16GB+ 内存更稳。

## 3. One-Click Run

```bash
# 小样例（快速验证）
python run.py --config src/configs/dev.small.yaml --tasks all

# 全量（耗时更长）
python run.py --config src/configs/prod.full.yaml --tasks all
```

## 4. Outputs

* 中间特征：`data/interim/*.parquet`
* 建模表：`data/derived/model_table_*.parquet`
* 指标：`reports/metrics/*.json`（含 AUROC/AUPRC/Brier/ECE…）
* 图表：`reports/figures/*.png`（ROC/PR/校准/DCA/SHAP）
* 快照：`snapshot_*.json`（输入/参数/代码指纹）

## 5. Reproducibility

* 每次运行生成 `RUN_ID`，固定随机种子、配置指纹、输入文件 MD5。
* 禁止将 `data/raw/` 纳入版本控制；代码与配置受 Git 管理。

## 6. Clinical Disclaimer

本项目仅用于科研/教学，**不用于临床决策**。详见“Ethics & Limitations”。

## 7. License

代码许可见 `LICENSE`；MIMIC 数据遵循 PhysioNet 相关政策。

````

---

## 15.2 可复现实验脚本：一键从 CSV 到评估指标

### 15.2.1 `run.py`（最小可用骨架）
> 利用第14章的极简 DAG 缓存：**输入 MD5 + 参数 + 代码签名** 变化才重算。

```python
# run.py
import argparse
from pathlib import Path
from src.pipeline.dag import Task, run_tasks
from src.utils.hashing import load_yaml, Config
from src.pipeline import io
import polars as pl

# === 任务函数（示例：实际内部调用你在第6–12章写好的函数） ===
def task_labels(params):
    from src.pipeline.labels import build_labels_scr_only  # or read derived
    out = Path("data/derived/label_24_48h.parquet")
    df = build_labels_scr_only(params)  # 返回 pl.DataFrame
    io.write_parquet_atomic(df, out)

def task_cohort(params):
    from src.pipeline.features import build_cohort_first_icu
    out = Path("data/derived/cohort_base.parquet")
    df = build_cohort_first_icu(params)
    io.write_parquet_atomic(df, out)

def task_features_basic(params):
    from src.pipeline.features import build_basic_features
    out = Path("data/derived/features_basic_0_24h.parquet")
    df = build_basic_features(params)
    io.write_parquet_atomic(df, out)

def task_features_clinical(params):
    from src.pipeline.features import build_clinical_features
    out = Path("data/derived/features_clinical_0_24h.parquet")
    df = build_clinical_features(params)
    io.write_parquet_atomic(df, out)

def task_model_table(params):
    from src.pipeline.features import assemble_model_table
    out = Path("data/derived/model_table_latest.parquet")
    df = assemble_model_table(params)
    io.write_parquet_atomic(df, out)

def task_train_eval(params):
    from src.pipeline.model import train_and_eval_cv
    # 内部写出 metrics json、figures png、oof parquet 等
    train_and_eval_cv(params)

# === CLI ===
if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--config", required=True, help="YAML config path")
    ap.add_argument("--tasks", default="all", help="comma sep: labels,cohort,feat_basic,feat_clin,model_table,train,all")
    args = ap.parse_args()

    CFG = Config(load_yaml(args.config)).data
    RAW = Path("data/raw"); DER = Path("data/derived"); INTERIM = Path("data/interim")
    tasks_map = {
        "labels": Task("labels", task_labels,
                       inputs=[RAW/"mimiciv_hosp/labevents.csv.gz", Path(args.config)],
                       outputs=[DER/"label_24_48h.parquet"],
                       params=CFG),
        "cohort": Task("cohort", task_cohort,
                       inputs=[RAW/"mimiciv_icu/icustays.csv.gz", RAW/"mimiciv_hosp/admissions.csv.gz", Path(args.config)],
                       outputs=[DER/"cohort_base.parquet"],
                       params=CFG),
        "feat_basic": Task("features_basic", task_features_basic,
                       inputs=[DER/"cohort_base.parquet", RAW/"mimiciv_hosp/patients.csv.gz", Path(args.config)],
                       outputs=[DER/"features_basic_0_24h.parquet"],
                       params=CFG),
        "feat_clin": Task("features_clinical", task_features_clinical,
                       inputs=[DER/"cohort_base.parquet", RAW/"mimiciv_hosp/labevents.csv.gz", RAW/"mimiciv_icu/chartevents.csv.gz", Path(args.config)],
                       outputs=[DER/"features_clinical_0_24h.parquet"],
                       params=CFG),
        "model_table": Task("model_table", task_model_table,
                       inputs=[DER/"label_24_48h.parquet", DER/"features_basic_0_24h.parquet", DER/"features_clinical_0_24h.parquet", Path(args.config)],
                       outputs=[DER/"model_table_latest.parquet"],
                       params=CFG),
        "train": Task("train_eval", task_train_eval,
                       inputs=[DER/"model_table_latest.parquet", Path(args.config)],
                       outputs=[Path("reports/metrics/metrics_oof.json")],
                       params=CFG),
    }

    order = ["labels","cohort","feat_basic","feat_clin","model_table","train"]
    chosen = order if args.tasks=="all" else [t.strip() for t in args.tasks.split(",")]
    run_tasks([tasks_map[x] for x in chosen])
````

### 15.2.2 `scripts/run_all.sh`（一键脚本）

```bash
#!/usr/bin/env bash
set -euo pipefail
CFG=${1:-"src/configs/dev.small.yaml"}

# 1) 校验数据位置（只提醒，不拷贝受限数据）
test -d data/raw/mimiciv_hosp || { echo "Put MIMIC hosp CSVs in data/raw/mimiciv_hosp"; exit 1; }
test -d data/raw/mimiciv_icu  || { echo "Put MIMIC icu  CSVs in data/raw/mimiciv_icu";  exit 1; }

# 2) 从标签→评估
python run.py --config "$CFG" --tasks all

echo "Done. See reports/metrics and reports/figures"
```

### 15.2.3 交付检查（CI/本地脚本）

* **冒烟测试**（dev.small.yaml）：限制样本数/时间窗子集，验证**能完整跑通**，并在 `reports/metrics` 产生日志与 JSON。
* **清理脚本**：`scripts/clean.sh` 删除 `data/interim/*` 与 `data/derived/*`（保留 `raw/`）。

---

## 15.3 伦理与局限、未来工作清单

### 15.3.1 伦理与合规

* **数据访问**：严格遵循 PhysioNet/CITI/DUA；交付中不包含任何 MIMIC 原始数据或受限派生。
* **去标识与时间偏移**：跨患者绝对日期不可比较；报告中仅以**相对时间窗**描述分析。
* **仅限科研/教学**：README 与页眉显著位置声明**不得用于临床诊断/治疗**。
* **再现性**：提供**配置文件原文、RUN\_ID、输入 MD5、代码指纹**；别名化病例示例，避免可识别信息。
* **模型公平与偏倚**：在第12章的**亚组分析**报告基础上，加入**性别/年龄/ICU 单位**等分层的性能与校准差异提示；避免夸大结论。

### 15.3.2 方法学局限

* **标签不确定性**：KDIGO 基于 SCr（±尿量）易受**基线估计**与**测量频次**影响；RRT/造影等干预可能改变 SCr 动态。
* **缺失并非 MCAR**：检测与治疗路径影响观测概率（MNAR），模型可能“学到流程”而非病理。
* **外部泛化**：MIMIC 为单中心/特定时间背景，外推到其他医院/时段需外部验证。
* **合并症时间性**：若用整次住院 ICD 生成 Charlson/Elixhauser，可能混入住院内并发；已在方法中说明并建议敏感性分析。
* **阈值迁移**：不同科室/资源下的阈值（pt）应重估并与**决策曲线**共同讨论。

### 15.3.3 未来工作清单

* **外部验证与域适配**：在 eICU 或多中心数据上评估，考虑校准迁移/域自适应。
* **标签增强**：引入尿量派生表/护理记录，完善 KDIGO；对 RRT 进行显式处理（排除或单列为结局/协变量）。
* **时间序列建模**：在不违背约束的前提下（仍用 Parquet/数据帧），扩展到**逐小时特征**或**滑窗序列**（GRU-D/TabTransformer 等作为对比）。
* **阈值与资源约束**：与临床联合设定 pt 区间（0.1–0.3 等），形成**可执行的代价表**（每100人 TP/FP/FN/TN 期望数）。
* **解释稳定性**：跨折/重抽样评估 SHAP 一致性；按变量族聚合解释，减少多重共线影响。
* **自动化升级**：将第14章 DAG 接到 `make`/`pre-commit`/简易 CI；对大表采用**分区增量**与**缓存命中率报告**。

---

## 交付打包清单（建议）

* ✅ **代码与配置**：`src/`、`run.py`、`requirements.txt`/`pyproject.toml`、`scripts/`。
* ✅ **文档**：`README.md`、`LICENSE`、方法学说明（可在 README 的 “Methods” 段）。
* ✅ **示例产物（不含原始数据）**：用 `dev.small.yaml` 生成的一套 `reports/figures/*`、`reports/metrics/*`、`data/derived/*`（小样）以证明工作流可跑。
* ✅ **快照**：`data/derived/snapshot_*.json`、`reports/metrics/env_*.json`、`reports/metrics/cache_index.json`。
* ✅ **清单文件**：`MANIFEST.json`（枚举交付内文件、尺寸、MD5、生成时间）。
* ⛔ **不包含**：`data/raw/*` 与任何可能含受限信息的中间件。

---

### 小结

本章给出了**目录规范 + README 模板 + 一键脚本 + 伦理/局限/未来工作**。配合第14章的**缓存与增量机制**，别人拿到你的仓库后，只需把 MIMIC CSV 放到 `data/raw/`，即可用一条命令**从 CSV 跑到评估与图表**，并能**复现实验结果**。如果你愿意，我可以把 `run.py` 与 `scripts/run_all.sh`、`README.md` 模板根据你当前仓库结构**定制化生成**到项目里。
