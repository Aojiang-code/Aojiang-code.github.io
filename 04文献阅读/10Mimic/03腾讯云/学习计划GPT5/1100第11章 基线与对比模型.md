下面是**第11章：基线与对比模型**的详细学习笔记。
全程遵循你的技术约束：**DuckDB + CSV/Parquet + Python（pandas/Polars）+ Jupyter（VSCode）**，**不使用 SQL / Postgres**。
范式：**数据帧 + sklearn Pipeline**，严格**按患者分组**验证，杜绝数据泄漏。

---

# 第11章 基线与对比模型

> **任务回顾**：用 **0–24h** 特征预测 **24–48h** 是否发生 AKI（≥Stage 1）。
> **输入**（来自第10章）：
>
> * `derived/model_table_latest.parquet`：1 行/`stay_id` 的建模表
> * `derived/feature_columns.json`：`num_cols`（数值列）、`cat_cols`（类别列）

通用导入与数据准备（Polars→pandas，便于 sklearn）：

```python
from pathlib import Path
import json, numpy as np, polars as pl, pandas as pd

DER = Path("data/derived")

# 读建模表与列清单
df = pl.read_parquet(DER/"model_table_latest.parquet").to_pandas()
with open(DER/"feature_columns.json","r",encoding="utf-8") as f:
    cols_meta = json.load(f)
NUM_COLS = [c for c in cols_meta["num_cols"] if c in df.columns]
CAT_COLS = [c for c in cols_meta["cat_cols"] if c in df.columns]

ID_COLS   = ["stay_id","subject_id","hadm_id"]
TARGETS   = ["aki_label","aki_stage"]
FEATURES  = NUM_COLS + CAT_COLS

X = df[FEATURES].copy()
y = df["aki_label"].astype(int).values
groups = df["subject_id"].values  # 用于 GroupKFold
```

---

## 11.1 基线：逻辑回归（类不平衡：权重/重采样）

### 11.1.1 设计要点

* **Pipeline**（避免泄漏）：
  `ColumnTransformer([ 数值: SimpleImputer(median) → RobustScaler, 类别: SimpleImputer(most_frequent) → OneHotEncoder ]) → LogisticRegression`
* **不平衡处理**：

  * 首选 **`class_weight='balanced'`**（简洁稳健）；
  * 或 `sample_weight = compute_sample_weight('balanced', y_train)`；
  * **不建议**先行上采样/下采样（易引入折间泄漏），若用 **imblearn**，务必放在 **Pipeline** 内并在每折训练数据上拟合。
* **正则**：`penalty='l2'`（默认）或 `l1`（可做稀疏筛特征，solver 用 `liblinear/saga`）。
* **阈值**：默认 0.5 不一定最优，建议基于验证集 **PR 曲线** 或 **Youden’s J** 选阈值。

### 11.1.2 分组交叉验证 & 评估模板

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, RobustScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedGroupKFold
from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, precision_recall_curve, roc_curve

# 预处理
num_pipe = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler",  RobustScaler(quantile_range=(25,75)))
])
cat_pipe = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("ohe",     OneHotEncoder(handle_unknown="ignore", sparse_output=False))
])

pre = ColumnTransformer(
    transformers=[
        ("num", num_pipe, NUM_COLS),
        ("cat", cat_pipe, CAT_COLS)
    ],
    remainder="drop",
    n_jobs=None
)

logreg = LogisticRegression(
    penalty="l2", solver="liblinear", class_weight="balanced", max_iter=200
)

pipe_lr = Pipeline(steps=[("pre", pre), ("clf", logreg)])

# 分层+分组 K 折（确保同一 subject 只在一个折）
cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)

metrics = []
fold_preds = np.zeros(len(y), dtype=float)

for k, (tr, te) in enumerate(cv.split(X, y, groups)):
    Xtr, Xte = X.iloc[tr], X.iloc[te]
    ytr, yte = y[tr], y[te]
    pipe_lr.fit(Xtr, ytr)                 # 预处理 + 模型均在训练折拟合
    p = pipe_lr.predict_proba(Xte)[:,1]   # 预测概率
    fold_preds[te] = p

    roc = roc_auc_score(yte, p)
    pr  = average_precision_score(yte, p)
    brier = brier_score_loss(yte, p)
    metrics.append({"fold":k, "roc_auc":roc, "pr_auc":pr, "brier":brier})

pd.DataFrame(metrics).assign(
    mean=lambda d: d[["roc_auc","pr_auc","brier"]].mean(axis=1)
)
print("OOF ROC-AUC:", roc_auc_score(y, fold_preds), " PR-AUC:", average_precision_score(y, fold_preds))
```

### 11.1.3 阈值选择与校准（可选）

```python
# 基于 OOF 选择阈值（最大化 F1 或 Youden’s J）
from sklearn.metrics import f1_score

prec, rec, th = precision_recall_curve(y, fold_preds)
f1s = 2*prec*rec/(prec+rec+1e-9)
best_t = th[np.argmax(f1s[:-1])]
print("Best threshold (PR-F1):", float(best_t))

# 概率校准（Platt/sigmoid），建议用“内层 CV”或保留集；这里演示 OOF 拟合后再全量重训
from sklearn.calibration import CalibratedClassifierCV
calibrated = CalibratedClassifierCV(pipe_lr, method="sigmoid", cv=cv)  # 分组CV内做校准
calibrated.fit(X, y)
```

---

## 11.2 树模型：RandomForest、XGBoost/LightGBM（可选）

### 11.2.1 RandomForest（sklearn）

* 对尺度不敏感，但 **仍需插补**（sklearn RF 不接受 NaN）。
* 特征重要性易解释（`feature_importances_`），但在高度相关特征下会分摊权重。
* 参数要点：`n_estimators`、`max_depth`、`min_samples_leaf`、`max_features`。

```python
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(
    n_estimators=400,
    max_depth=None,
    min_samples_leaf=20,
    class_weight="balanced_subsample",
    n_jobs=-1,
    random_state=42
)

pipe_rf = Pipeline(steps=[("pre", pre), ("clf", rf)])

# 与 11.1 相同的 StratifiedGroupKFold 循环评估
```

### 11.2.2 XGBoost / LightGBM（梯度提升，推荐）

* **优点**：处理非线性/高维稀疏、可设 `scale_pos_weight` 适配不平衡、支持**早停**。
* **输入**：仍建议用 `ColumnTransformer` 做 OHE（便于类别特征）。
* **不平衡**：

  * `scale_pos_weight = n_neg / n_pos`（每折单独估计更严谨）；或 `is_unbalance=True`（LightGBM）。
  * 也可结合 `sample_weight`（训练时传入）。

**XGBoost 模板**

```python
from xgboost import XGBClassifier

def make_xgb(scale_pos_weight):
    return XGBClassifier(
        n_estimators=2000, 
        max_depth=4,
        learning_rate=0.03,
        subsample=0.8,
        colsample_bytree=0.8,
        reg_lambda=1.0,
        tree_method="hist",
        eval_metric="aucpr",        # 对不平衡更敏感
        scale_pos_weight=scale_pos_weight,
        random_state=42
    )

# CV with early stopping
oof = np.zeros(len(y))
for k, (tr, te) in enumerate(cv.split(X, y, groups)):
    Xtr, Xte = X.iloc[tr], X.iloc[te]
    ytr, yte = y[tr], y[te]
    spw = (len(ytr)-ytr.sum())/max(1, ytr.sum())  # n_neg/n_pos
    xgb = make_xgb(spw)

    # 预处理分别拟合在训练折
    Xtr_mat = pre.fit_transform(Xtr)
    Xte_mat = pre.transform(Xte)

    xgb.fit(
        Xtr_mat, ytr,
        eval_set=[(Xte_mat, yte)],
        verbose=False,
        early_stopping_rounds=100
    )
    p = xgb.predict_proba(Xte_mat)[:,1]
    oof[te] = p

roc = roc_auc_score(y, oof); pr = average_precision_score(y, oof)
print("XGB OOF ROC-AUC:", roc, " PR-AUC:", pr)
```

**LightGBM 模板**

```python
import lightgbm as lgb

def make_lgb():
    return lgb.LGBMClassifier(
        n_estimators=5000,
        learning_rate=0.02,
        num_leaves=63,
        subsample=0.8,
        colsample_bytree=0.8,
        reg_lambda=1.0,
        objective="binary",
        metric="average_precision",   # PR-AUC
        random_state=42
    )

oof = np.zeros(len(y))
for k, (tr, te) in enumerate(cv.split(X, y, groups)):
    Xtr, Xte = X.iloc[tr], X.iloc[te]
    ytr, yte = y[tr], y[te]
    # 每折设不平衡
    scale_pos_weight = (len(ytr)-ytr.sum())/max(1,ytr.sum())
    lgbm = make_lgb()
    lgbm.set_params(is_unbalance=True, scale_pos_weight=scale_pos_weight)

    Xtr_mat = pre.fit_transform(Xtr)
    Xte_mat = pre.transform(Xte)

    lgbm.fit(
        Xtr_mat, ytr,
        eval_set=[(Xte_mat, yte)],
        callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=False)]
    )
    p = lgbm.predict_proba(Xte_mat)[:,1]
    oof[te] = p

print("LGB OOF ROC-AUC:", roc_auc_score(y,oof), " PR-AUC:", average_precision_score(y,oof))
```

> **提示**：提升类模型对特征量纲不敏感，但 OHE 产生的稀疏列很多时，适度收缩（`max_depth/num_leaves`、`min_child_samples`）能防止过拟合。

---

## 11.3 调参与验证：时间感知/GroupKFold、早停与网格/贝叶斯搜索

### 11.3.1 验证策略

* **首选**：`StratifiedGroupKFold`（按 `subject_id` 分组 + 保持阳性率）。
* **时间感知**：MIMIC 的日期被偏移，**跨患者全球时间不可比**；可用**结构化 holdout**（第7章）或 **anchor\_year\_group 分层**做外部域近似。
* **避免泄漏**：所有**拟合**（插补器、缩放器、编码器、参数选择、早停）仅在训练折内完成；**早停的验证集就是本折的验证划分**，不能用全局 OOF 或另一个折的数据。

### 11.3.2 早停（提升类）

* XGBoost：`early_stopping_rounds` + `eval_set=[(X_valid,y_valid)]`
* LightGBM：`callbacks=[early_stopping(...)]`
* **注意**：早停**不等于**超参搜索；超参仍需在外层 CV 中调。

### 11.3.3 超参搜索（示例：RandomizedSearchCV + 分组）

```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import loguniform, randint

# 以 LightGBM 为例（也可换 XGB/RF/LR）
lgbm = make_lgb()

pipe_lgb = Pipeline(steps=[("pre", pre), ("clf", lgbm)])
param_dist = {
    "clf__learning_rate": loguniform(1e-3, 1e-1),
    "clf__num_leaves": randint(31, 255),
    "clf__subsample":   [0.6, 0.8, 1.0],
    "clf__colsample_bytree": [0.6, 0.8, 1.0],
    "clf__reg_lambda":  loguniform(1e-3, 10),
}

rnd = RandomizedSearchCV(
    estimator=pipe_lgb,
    param_distributions=param_dist,
    n_iter=25,
    scoring="average_precision",            # PR-AUC 作为目标
    cv=cv,                                  # StratifiedGroupKFold
    refit=True,                             # 最优参数在全量上重新拟合（注意：正式报告需在外部测试集评估）
    n_jobs=-1,
    random_state=42
)

# 传入 groups 以启用“分组 CV”
rnd.fit(X, y, groups=groups)
print("Best PR-AUC (CV):", rnd.best_score_)
print("Best params:", rnd.best_params_)
best_model = rnd.best_estimator_
```

> **若使用贝叶斯搜索**：可采用 `skopt.BayesSearchCV` 或 `optuna`，同样需传入 `cv=cv` 与 `fit(..., groups=groups)`。

### 11.3.4 评估指标与阈值

* **主要指标**：PR-AUC（不平衡推荐）、ROC-AUC；
* **次要**：Brier 分数（标定）、敏感度/特异度/F1（阈值相关）；
* **阈值选择**：基于验证集 PR 曲线（最大 F1）或根据临床资源设置**固定 PPV/敏感度**目标；
* **校准**：`CalibratedClassifierCV`（sigmoid/isotonic），用**分组 CV**。

### 11.3.5 特征重要性与解释（简述）

* **Logistic**：`coef_`（配合标准化解释方向与相对强度）；
* **RF/LGB/XGB**：`feature_importances_`（gain/weight/shap）；
* **SHAP（可选）**：`shap.TreeExplainer` 对提升类可解释全局/个体；注意运行成本与隐私导出。

---

## 产出与自检（本章落地）

**建议保存**

* `derived/cv_metrics_lr.json`, `..._rf.json`, `..._xgb.json`, `..._lgb.json`：每折 ROC-AUC/PR-AUC/Brier
* `derived/oof_pred_{model}.parquet`：OOF 概率/阈值/真实标签（审计复现）
* `derived/best_model_{model}.pkl`（仅在合规的本地/私有环境保存）

**自检清单**

* [ ] 使用 **StratifiedGroupKFold**（基于 `subject_id`）
* [ ] 预处理（插补/缩放/编码）置于 **Pipeline** 并仅在训练折拟合
* [ ] 不平衡处理采用 `class_weight` / `scale_pos_weight` / `sample_weight`（折内计算）
* [ ] 早停的验证集 == 当前折验证划分
* [ ] 阈值选择基于验证集，不用测试集调阈
* [ ] 评估至少报告 **PR-AUC/ROC-AUC/Brier** + 校准曲线
* [ ] 结果/模型/阈值/参数已写入快照，保证可复现

---

### 下一步（第12章预告）

* **统一训练脚本**：封装 CV、早停、阈值选择与快照输出。
* **外部验证 / 结构化 holdout**：用第7章的 holdout 切分或未见 ICU 单位做域外评估。
* **误差与公平性分析**：分层（年龄、性别、careunit、基线来源）报告性能与校准。
