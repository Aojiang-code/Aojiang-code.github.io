# 学习计划书大纲：从 MIMIC-IV 入门到 AKI（急性肾损伤）预测（DuckDB + CSV + Python + Jupyter in VSCode）

> 说明：全程**不依赖 Postgres**；以 **DuckDB + CSV + Python** 为主线，配合 pandas/Polars 与 Jupyter（VSCode）。尽量走“**无 SQL**”的数据帧风格；必要时仅在附录提供等价的 DuckDB SQL 参考。

## Part I · 准备与规范

### 第1章 研究合规与数据伦理

* 1.1 访问资质与合规：PhysioNet/CITI/数据使用协议
* 1.2 去标识化与时间偏移的影响
* 1.3 隐私保护与可重复研究声明（README/许可/排除临床用途）

### 第2章 开发环境搭建（VSCode + Jupyter）

* 2.1 VSCode + Python 环境与扩展（Jupyter、Python、Remote-SSH）
* 2.2 虚拟环境与依赖：Python 版本、pip/uv、`requirements.txt`/`pyproject.toml`
* 2.3 安装与验证：duckdb、pandas/Polars、pyarrow、matplotlib/scikit-learn
* 2.4 目录规范与数据落盘：`/data/raw`、`/data/interim`、`/data/derived`、`/notebooks`、`/src`

### 第3章 DuckDB 的“无SQL”使用范式

* 3.1 为何选择 DuckDB：零服务、列存执行、向量化、并行
* 3.2 数据帧工作流：DuckDB ↔ pandas/Polars 的互操作
* 3.3 按需读取 CSV：列裁剪、行过滤、延迟执行、分块策略
* 3.4 性能与容量：从 CSV 到 Parquet 的渐进式转换与缓存

## Part II · 认识 MIMIC-IV 数据

### 第4章 MIMIC-IV 模块与关键表（概览）

* 4.1 模块：`hosp`、`icu`、（可选）`ed`、`note`、`derived`
* 4.2 关联键与时间字段：`subject_id`、`hadm_id`、`stay_id`、`intime/outtime`
* 4.3 常用表速览与字段字典：`patients`、`admissions`、`labevents`、`chartevents`、`diagnoses_icd` 等

### 第5章 CSV 数据准备与质量校验

* 5.1 文件清单、体量评估与磁盘规划
* 5.2 完整性检查：字段、行数、去重、异常时间戳
* 5.3 基础 EDA：患者计数、住院计数、ICU 停留、化验与生命体征分布
* 5.4 数据字典对齐与单位规范（SCr、尿量、电解质等）

## Part III · 任务定义：AKI 标签与样本构建

### 第6章 AKI（KDIGO）定义与实现路径

* 6.1 KDIGO 标准要点与算法选择
* 6.2 两条路线

  * A. 使用 `mimic-iv-derived`（若有 CSV/Parquet 版）：直接读取 KDIGO 标签
  * B. 教学向自建标签：基于 SCr（±尿量）的 KDIGO 分级（时间窗/基线选择/排除规则）
* 6.3 风险与偏倚：基线肌酐、入院前记录缺失、RRT 干预

### 第7章 研究队列与时间窗

* 7.1 目标：**预测 ICU 入科后 24–48 小时是否发生 AKI（≥Stage 1）**
* 7.2 样本选择：首次 ICU 停留/按科室/按诊断过滤（可选）
* 7.3 窗口设计：特征窗（0–24h）与标签窗（24–48h）的**严格隔离**
* 7.4 训练/验证/测试切分：按时间、按患者分组、避免数据泄漏

## Part IV · 特征工程（“无SQL”数据帧流程）

### 第8章 基础特征

* 8.1 人口学：年龄（去标识规则下的计算）、性别
* 8.2 就诊信息：入出院、ICU 停留、转运
* 8.3 合并症：Charlson/Elixhauser（优先读取 derived；否则从 ICD 派生）

### 第9章 关键医学特征

* 9.1 化验：SCr、BUN、电解质、酸碱（均值/最大/最小/最近值/变化率）
* 9.2 生命体征：心率、呼吸、血压、体温、SpO₂（聚合与稳健统计）
* 9.3 尿量与液体平衡（若可得）：滚动窗口与体重归一化
* 9.4 药物与干预（可选）：利尿剂、血管活性药、造影剂、RRT 指标
* 9.5 缺失机制与插补：MCAR/MAR/MNAR 讨论与实践策略

### 第10章 数据集成与特征矩阵构建

* 10.1 以 `stay_id` 为索引的样本表
* 10.2 列裁剪、类型统一、异常值处理与稳健缩放
* 10.3 写入中间数据（Parquet）与版本化（数据快照）

## Part V · 建模、评估与解释

### 第11章 基线与对比模型

* 11.1 基线：逻辑回归（类不平衡：权重/重采样）
* 11.2 树模型：RandomForest、XGBoost/LightGBM（可选）
* 11.3 调参与验证：时间感知/GroupKFold、早停与网格/贝叶斯搜索

### 第12章 评估指标与临床可用性

* 12.1 AUROC、AUPRC、灵敏度/特异度、F1、校准（可靠性图、Brier）
* 12.2 临床阈值与决策曲线（DCA）
* 12.3 亚组分析与稳健性（肾功能基线、年龄/性别/诊断亚组）

### 第13章 模型解释与可视化

* 13.1 全局与局部解释：特征重要度、SHAP
* 13.2 误差剖析：混淆样本、对比图
* 13.3 报告图表规范（科研发表友好）

## Part VI · 复现与交付

### 第14章 实验记录与自动化

* 14.1 Notebooks 结构与命名规范
* 14.2 配置与参数管理（YAML/JSON）
* 14.3 结果缓存与增量计算（DuckDB + Parquet 管线）

### 第15章 项目打包与交付物

* 15.1 最终目录树与 README 模板
* 15.2 可复现实验脚本：一键从 CSV 到评估指标
* 15.3 伦理与局限、未来工作清单

## Part VII · 附录（可选，非必需）

### A. DuckDB SQL 对照速查（仅参考，不在主体中使用）

### B. 常见坑与 FAQ（时间戳、单位换算、极端值、合并键）

### C. 计算资源与性能建议（CSV→Parquet、列裁剪、并行）

---

## 里程碑与产出（与大纲对齐）

* 里程碑1（Part I–II）：完成环境搭建与数据质检 Notebook
* 里程碑2（Part III）：确定 AKI 标签与样本构建 Notebook
* 里程碑3（Part IV）：生成特征矩阵 Parquet（无SQL数据帧流水线）
* 里程碑4（Part V）：完成基线与对比模型 + 评估与解释
* 里程碑5（Part VI）：打包交付与复现验证

如果这个大纲符合你的预期，我就按顺序从**第1章**开始，给出每节的详细学习笔记与随后可直接在 VSCode 里运行的 **Jupyter Notebook（DuckDB + CSV + Python，尽量无 SQL）** 代码。你觉得如何？
