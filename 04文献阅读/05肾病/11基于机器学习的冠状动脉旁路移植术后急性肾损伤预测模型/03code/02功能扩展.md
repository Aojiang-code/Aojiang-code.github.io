# âœ… æ–°å¢åŠŸèƒ½è®¡åˆ’

### 1. **äº¤å‰éªŒè¯å¹³å‡æ€§èƒ½è¯„ä¼°ï¼ˆ5-foldï¼‰**

* è¾“å‡ºå„æ¨¡å‹çš„ `AUC`, `Accuracy`, `Recall`, `F1` çš„å¹³å‡å€¼ä¸æ ‡å‡†å·®
* ç”¨äºå¢å¼ºå¯¹æ¨¡å‹ç¨³å¥æ€§çš„è¯„ä¼°

### 2. **ç»˜åˆ¶äº¤äº’å¼ ROC æ›²çº¿å›¾ï¼ˆPlotlyï¼‰**

* æä¾›å¯ç¼©æ”¾ã€å¯ä¿å­˜çš„ HTML äº¤äº’å¼å›¾è¡¨
* æ”¯æŒå¯¹æ¯”å¤šä¸ªæ¨¡å‹çš„ ROC æ›²çº¿è¡¨ç°

### 3. **AKI åˆ†çº§é¢„æµ‹ï¼ˆStage 1/2/3ï¼‰**

* ä½¿ç”¨ `LogisticRegression` + `OrdinalClassifier` æˆ– `XGBClassifier` è¿›è¡Œå¤šåˆ†ç±»
* æˆ–è€…è¾“å‡º AKI ç­‰çº§æ¦‚ç‡ï¼Œæ¨¡æ‹Ÿæ›´å¤æ‚æ ‡ç­¾ç»“æ„

### 4. **ä¿å­˜å®Œæ•´ SHAP åˆ†æç»“æœï¼ˆsummary + dependenceï¼‰**

* ä¾ç…§æ–‡çŒ®ä¸­çš„ SHAP importance æ’åå‰ 10 å˜é‡é€ä¸€ç»˜åˆ¶ dependence plot

---

å¾ˆå¥½ï¼Œæˆ‘ä»¬ä»ç¬¬ä¸€ä¸ªæ¨¡å—å¼€å§‹ï¼š

---

# âœ… æ¨¡å— 1ï¼š5-Fold äº¤å‰éªŒè¯å¹³å‡æ€§èƒ½è¯„ä¼°

### ğŸ“ æ–‡ä»¶åå»ºè®®ï¼š

`model_crossval_evaluation.py`

---

### ğŸ“Œ åŠŸèƒ½è¯´æ˜ï¼š

* é’ˆå¯¹æ¯ä¸ªæ¨¡å‹ï¼Œè¿›è¡Œ `StratifiedKFold(n_splits=5)` äº¤å‰éªŒè¯
* è¾“å‡ºä»¥ä¸‹æŒ‡æ ‡çš„å¹³å‡å€¼ä¸æ ‡å‡†å·®ï¼š

  * `AUC`
  * `Accuracy`
  * `Precision`
  * `Recall`
  * `F1 Score`
* è‡ªåŠ¨ä¿å­˜ä¸º `.csv` æ–‡ä»¶

---

### âœ… è„šæœ¬å†…å®¹å¦‚ä¸‹ï¼š

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
)
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler

# ==== åŠ è½½æ•°æ® ====
df = pd.read_csv("04æ–‡çŒ®é˜…è¯»/05è‚¾ç—…/11åŸºäºæœºå™¨å­¦ä¹ çš„å† çŠ¶åŠ¨è„‰æ—è·¯ç§»æ¤æœ¯åæ€¥æ€§è‚¾æŸä¼¤é¢„æµ‹æ¨¡å‹/01data/simulated_cabg_aki_data.csv")
X = df.drop(columns=["AKI"])
y = df["AKI"]

# ==== æ ‡å‡†åŒ–è¿ç»­å˜é‡ ====
numeric_cols = X.select_dtypes(include=np.number).columns
scaler = StandardScaler()
X[numeric_cols] = scaler.fit_transform(X[numeric_cols])

# ==== å®šä¹‰æ¨¡å‹ ====
models = {
    "LogisticRegression": LogisticRegression(max_iter=1000),
    "DecisionTree": DecisionTreeClassifier(),
    "RandomForest": RandomForestClassifier(),
    "AdaBoost": AdaBoostClassifier(),
    "GradientBoosting": GradientBoostingClassifier(),
    "LightGBM": LGBMClassifier(),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric="logloss"),
    "SVM": SVC(probability=True),
    "KNN": KNeighborsClassifier()
}

# ==== äº¤å‰éªŒè¯ç­–ç•¥ ====
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# ==== æ¨¡å‹è¯„ä¼° ====
def evaluate_model_cv(model, X, y, cv):
    scores = {
        "AUC": [],
        "Accuracy": [],
        "Precision": [],
        "Recall": [],
        "F1": []
    }
    for train_idx, test_idx in cv.split(X, y):
        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]

        model.fit(X_train, y_train)
        pred = model.predict(X_val)
        proba = model.predict_proba(X_val)[:, 1]

        scores["AUC"].append(roc_auc_score(y_val, proba))
        scores["Accuracy"].append(accuracy_score(y_val, pred))
        scores["Precision"].append(precision_score(y_val, pred))
        scores["Recall"].append(recall_score(y_val, pred))
        scores["F1"].append(f1_score(y_val, pred))

    return {metric: (np.mean(values), np.std(values)) for metric, values in scores.items()}

# ==== æ±‡æ€»æ‰€æœ‰æ¨¡å‹ç»“æœ ====
results = []
for name, model in models.items():
    metrics = evaluate_model_cv(model, X, y, cv)
    result = {"Model": name}
    for metric, (mean_val, std_val) in metrics.items():
        result[f"{metric}_mean"] = round(mean_val, 4)
        result[f"{metric}_std"] = round(std_val, 4)
    results.append(result)

results_df = pd.DataFrame(results)

# ==== ä¿å­˜ç»“æœ ====
output_path = "04æ–‡çŒ®é˜…è¯»/05è‚¾ç—…/11åŸºäºæœºå™¨å­¦ä¹ çš„å† çŠ¶åŠ¨è„‰æ—è·¯ç§»æ¤æœ¯åæ€¥æ€§è‚¾æŸä¼¤é¢„æµ‹æ¨¡å‹/02output/crossval_model_performance.csv"
results_df.to_csv(output_path, index=False)

print("âœ… 5-fold äº¤å‰éªŒè¯è¯„ä¼°å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š", output_path)
```

---

### âœ… è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼ˆCSVï¼‰ï¼š

| Model              | AUC\_mean | AUC\_std | Accuracy\_mean | Accuracy\_std | ... |
| ------------------ | --------- | -------- | -------------- | ------------- | --- |
| RandomForest       | 0.7356    | 0.0152   | 0.8371         | 0.0123        | ... |
| LogisticRegression | 0.7204    | 0.0181   | ...            | ...           | ... |

# âœ… æ¨¡å— 2ï¼šPlotly ç»˜åˆ¶äº¤äº’å¼ ROC æ›²çº¿

### ğŸ“ æ–‡ä»¶åå»ºè®®ï¼š

`plotly_roc_curves.py`

---

## ğŸ¯ åŠŸèƒ½ç›®æ ‡

* ä½¿ç”¨ `Plotly` ç»˜åˆ¶å¤šä¸ªæ¨¡å‹çš„ ROC æ›²çº¿å›¾ï¼›
* å¯äº¤äº’æŸ¥çœ‹æ¯ä¸ªæ¨¡å‹çš„æ›²çº¿ã€AUCï¼›
* è‡ªåŠ¨ä¿å­˜ä¸º HTML æ–‡ä»¶ï¼›
* æ•°æ®æ¥æºç»Ÿä¸€è¯»å–ä¸Šä¸€æ­¥äº¤å‰éªŒè¯ä½¿ç”¨çš„æ•°æ®å’Œæ¨¡å‹ã€‚

---

## ğŸ”§ å®‰è£…ä¾èµ–

å¦‚å°šæœªå®‰è£…ï¼Œè¯·åœ¨ç»ˆç«¯è¿è¡Œï¼š

```bash
pip install plotly scikit-learn
```

---

## âœ… è„šæœ¬å†…å®¹å¦‚ä¸‹ï¼š

```python
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
import os

# ==== åŠ è½½æ•°æ® ====
data_path = "04æ–‡çŒ®é˜…è¯»/05è‚¾ç—…/11åŸºäºæœºå™¨å­¦ä¹ çš„å† çŠ¶åŠ¨è„‰æ—è·¯ç§»æ¤æœ¯åæ€¥æ€§è‚¾æŸä¼¤é¢„æµ‹æ¨¡å‹/01data/simulated_cabg_aki_data.csv"
df = pd.read_csv(data_path)
X = df.drop(columns=["AKI"])
y = df["AKI"]

# ==== æ ‡å‡†åŒ– ====
scaler = StandardScaler()
numeric_cols = X.select_dtypes(include=np.number).columns
X[numeric_cols] = scaler.fit_transform(X[numeric_cols])

# ==== åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›† ====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# ==== æ¨¡å‹å®šä¹‰ ====
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "AdaBoost": AdaBoostClassifier(),
    "Gradient Boosting": GradientBoostingClassifier(),
    "LightGBM": LGBMClassifier(),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric="logloss"),
    "SVM": SVC(probability=True),
    "KNN": KNeighborsClassifier()
}

# ==== ç»˜åˆ¶ Plotly ROC å›¾ ====
fig = go.Figure()

for name, model in models.items():
    model.fit(X_train, y_train)
    y_proba = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    auc_score = auc(fpr, tpr)

    fig.add_trace(
        go.Scatter(
            x=fpr, y=tpr,
            mode='lines',
            name=f"{name} (AUC={auc_score:.3f})"
        )
    )

# ==== å›¾åƒé…ç½® ====
fig.update_layout(
    title="Interactive ROC Curves for AKI Prediction Models",
    xaxis_title="False Positive Rate",
    yaxis_title="True Positive Rate",
    legend_title="Models",
    width=800,
    height=600,
    template="plotly_white"
)
fig.add_shape(
    type="line", line=dict(dash="dash"),
    x0=0, x1=1, y0=0, y1=1
)

# ==== ä¿å­˜å›¾è¡¨ ====
output_path = "04æ–‡çŒ®é˜…è¯»/05è‚¾ç—…/11åŸºäºæœºå™¨å­¦ä¹ çš„å† çŠ¶åŠ¨è„‰æ—è·¯ç§»æ¤æœ¯åæ€¥æ€§è‚¾æŸä¼¤é¢„æµ‹æ¨¡å‹/02output/roc_plotly.html"
os.makedirs(os.path.dirname(output_path), exist_ok=True)
fig.write_html(output_path)

print("âœ… äº¤äº’å¼ ROC å›¾å·²ä¿å­˜ä¸º HTMLï¼š", output_path)
```

---

## ğŸ“‚ è¾“å‡ºå†…å®¹

ç”Ÿæˆæ–‡ä»¶ï¼š

```
ğŸ“„ roc_plotly.html  â†’ å¯äº¤äº’æµè§ˆå’Œä¿å­˜çš„æ¨¡å‹ ROC æ›²çº¿å›¾
```

# âœ… æ¨¡å— 3ï¼šAKI åˆ†çº§é¢„æµ‹ï¼ˆå¤šåˆ†ç±»ï¼‰

### ğŸ“ æ–‡ä»¶åå»ºè®®ï¼š

`aki_stage_multiclass.py`

---

## ğŸ¯ åŠŸèƒ½ç›®æ ‡

* æ¨¡æ‹Ÿ AKI ç­‰çº§ï¼ˆStage 0/1/2/3ï¼‰æ ‡ç­¾ï¼›
* æ„å»ºå¤šåˆ†ç±»æ¨¡å‹ï¼ˆæ”¯æŒ XGBoostã€LightGBMã€RandomForestï¼‰ï¼›
* è¾“å‡ºå„ç­‰çº§é¢„æµ‹ç»“æœçš„ï¼š

  * å¤šåˆ†ç±»å‡†ç¡®ç‡
  * å®å¹³å‡ F1ã€ç²¾ç¡®ç‡ã€å¬å›ç‡
  * æ··æ·†çŸ©é˜µå¯è§†åŒ–

---

## ğŸ“Œ æ­¥éª¤æ¦‚è§ˆ

1. **æ¨¡æ‹Ÿ AKI Stage æ ‡ç­¾**ï¼ˆå¦‚æ— çœŸå®æ•°æ®ï¼Œå¯æŒ‰é£é™©åˆ†æ•°åˆ’åˆ†ä¸º0\~3çº§ï¼‰ï¼›
2. **è®­ç»ƒå¤šåˆ†ç±»æ¨¡å‹**ï¼ˆä½¿ç”¨ `XGBClassifier` æˆ– `RandomForestClassifier` with `multi_class='ovr'`ï¼‰ï¼›
3. **è¾“å‡ºè¯„ä¼°æŒ‡æ ‡**ï¼›
4. **ç»˜åˆ¶æ··æ·†çŸ©é˜µ**ã€‚

---

## âœ… è„šæœ¬å†…å®¹å¦‚ä¸‹

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import os

# ==== åŠ è½½æ•°æ® ====
df = pd.read_csv("04æ–‡çŒ®é˜…è¯»/05è‚¾ç—…/11åŸºäºæœºå™¨å­¦ä¹ çš„å† çŠ¶åŠ¨è„‰æ—è·¯ç§»æ¤æœ¯åæ€¥æ€§è‚¾æŸä¼¤é¢„æµ‹æ¨¡å‹/01data/simulated_cabg_aki_data.csv")
X = df.drop(columns=["AKI"])
y_bin = df["AKI"]

# ==== æ¨¡æ‹Ÿ AKI åˆ†çº§æ ‡ç­¾ ====
# å‡è®¾ä¾æ®æ–‡çŒ®æåˆ°é£é™©å¾—åˆ†åˆ’åˆ†ç­‰çº§
risk_score = (
    0.02 * df["Age"] -
    0.015 * df["eGFR"] +
    0.005 * df["UA"] +
    0.01 * df["ALT"] +
    0.004 * df["BNP"] +
    0.1 * df["Operation_time"] +
    0.3 * df["Use_IABP"]
)
# æŒ‰åˆ†ä½æ•°åˆ’åˆ†ä¸º Stage 0~3
y_stage = pd.qcut(risk_score, q=4, labels=[0, 1, 2, 3]).astype(int)

# ==== æ ‡å‡†åŒ–è¿ç»­ç‰¹å¾ ====
numeric_cols = X.select_dtypes(include=np.number).columns
scaler = StandardScaler()
X[numeric_cols] = scaler.fit_transform(X[numeric_cols])

# ==== åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›† ====
X_train, X_test, y_train, y_test = train_test_split(
    X, y_stage, test_size=0.3, stratify=y_stage, random_state=42
)

# ==== å¤šåˆ†ç±»æ¨¡å‹ ====
model = XGBClassifier(objective='multi:softprob', num_class=4, eval_metric='mlogloss', use_label_encoder=False)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# ==== è¾“å‡ºåˆ†ç±»æŒ‡æ ‡ ====
report = classification_report(y_test, y_pred, digits=4, output_dict=True)
report_df = pd.DataFrame(report).transpose()

# ==== ä¿å­˜ç»“æœ ====
output_dir = "04æ–‡çŒ®é˜…è¯»/05è‚¾ç—…/11åŸºäºæœºå™¨å­¦ä¹ çš„å† çŠ¶åŠ¨è„‰æ—è·¯ç§»æ¤æœ¯åæ€¥æ€§è‚¾æŸä¼¤é¢„æµ‹æ¨¡å‹/02output"
os.makedirs(output_dir, exist_ok=True)
report_df.to_csv(os.path.join(output_dir, "aki_stage_classification_report.csv"))

# ==== æ··æ·†çŸ©é˜µå¯è§†åŒ– ====
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Stage 0", "Stage 1", "Stage 2", "Stage 3"])
disp.plot(cmap="Blues")
plt.title("AKI Stage Prediction - Confusion Matrix")
plt.tight_layout()
plt.savefig(os.path.join(output_dir, "aki_stage_confusion_matrix.png"))
plt.close()

print("âœ… å¤šåˆ†ç±»æ¨¡å‹å®Œæˆï¼Œç»“æœä¸å›¾è¡¨å·²ä¿å­˜è‡³ï¼š", output_dir)
```

---

## ğŸ“„ è¾“å‡ºå†…å®¹

| æ–‡ä»¶                                    | æè¿°                    |
| ------------------------------------- | --------------------- |
| `aki_stage_classification_report.csv` | åŒ…å«æ¯ä¸ªç­‰çº§çš„ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1ã€æ”¯æŒæ•° |
| `aki_stage_confusion_matrix.png`      | å¤šåˆ†ç±»é¢„æµ‹çš„æ··æ·†çŸ©é˜µå›¾           |

# âœ… æ¨¡å— 4ï¼šSHAP è§£é‡Šåˆ†æä¸å˜é‡å¯è§†åŒ–è‡ªåŠ¨åŒ–

### ğŸ“ æ–‡ä»¶åå»ºè®®ï¼š

`shap_feature_interpretation.py`

---

## ğŸ¯ åŠŸèƒ½ç›®æ ‡

* ä½¿ç”¨ TreeSHAP è§£é‡Šæœ€ä½³æ¨¡å‹ï¼ˆé»˜è®¤ï¼šRandomForestï¼‰ï¼›
* è¾“å‡ºï¼š

  * SHAP Summary Plotï¼ˆå˜é‡å…¨æ™¯é‡è¦æ€§ï¼‰ï¼›
  * Top N å˜é‡ Dependence Plotï¼ˆå˜é‡-é¢„æµ‹å…³ç³»ï¼‰ï¼›
* è‡ªåŠ¨ä¿å­˜æ‰€æœ‰å›¾ç‰‡è‡³æŒ‡å®šæ–‡ä»¶å¤¹ï¼›
* å¯çµæ´»æŒ‡å®š `top_n_features`ã€‚

---

## âœ… è„šæœ¬å†…å®¹å¦‚ä¸‹ï¼š

```python
import pandas as pd
import numpy as np
import shap
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import os

# ==== å‚æ•°è®¾ç½® ====
top_n_features = 10
output_dir = "04æ–‡çŒ®é˜…è¯»/05è‚¾ç—…/11åŸºäºæœºå™¨å­¦ä¹ çš„å† çŠ¶åŠ¨è„‰æ—è·¯ç§»æ¤æœ¯åæ€¥æ€§è‚¾æŸä¼¤é¢„æµ‹æ¨¡å‹/02output"
os.makedirs(output_dir, exist_ok=True)

# ==== åŠ è½½æ•°æ® ====
df = pd.read_csv("04æ–‡çŒ®é˜…è¯»/05è‚¾ç—…/11åŸºäºæœºå™¨å­¦ä¹ çš„å† çŠ¶åŠ¨è„‰æ—è·¯ç§»æ¤æœ¯åæ€¥æ€§è‚¾æŸä¼¤é¢„æµ‹æ¨¡å‹/01data/simulated_cabg_aki_data.csv")
X = df.drop(columns=["AKI"])
y = df["AKI"]

# ==== æ ‡å‡†åŒ–è¿ç»­å˜é‡ ====
numeric_cols = X.select_dtypes(include=np.number).columns
scaler = StandardScaler()
X[numeric_cols] = scaler.fit_transform(X[numeric_cols])

# ==== åˆ’åˆ†æ•°æ® ====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# ==== è®­ç»ƒæ¨¡å‹ ====
model = RandomForestClassifier().fit(X_train, y_train)

# ==== SHAPè§£é‡Š ====
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# ==== Summary Plot ====
shap.summary_plot(shap_values[1], X_test, show=False)
plt.tight_layout()
plt.savefig(os.path.join(output_dir, "shap_summary_plot.png"))
plt.close()

# ==== Top N å˜é‡åç§° ====
shap_abs = np.abs(shap_values[1])
mean_importance = shap_abs.mean(axis=0)
top_features_idx = np.argsort(mean_importance)[-top_n_features:][::-1]
top_feature_names = X_test.columns[top_features_idx]

# ==== Dependence Plot for Top N ====
for feature in top_feature_names:
    shap.dependence_plot(feature, shap_values[1], X_test, show=False)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"shap_dependence_{feature}.png"))
    plt.close()

print(f"âœ… SHAPè§£é‡Šå®Œæˆï¼Œsummary å’Œå‰{top_n_features}ä¸ªå˜é‡å¯è§†åŒ–å›¾å·²ä¿å­˜è‡³ï¼š{output_dir}")
```

---

## ğŸ“‚ è¾“å‡ºå†…å®¹

| æ–‡ä»¶                          | æè¿°                  |
| --------------------------- | ------------------- |
| `shap_summary_plot.png`     | å±•ç¤ºæ‰€æœ‰å˜é‡å¯¹é¢„æµ‹å½±å“çš„æ€»ä½“å›¾     |
| `shap_dependence_<var>.png` | å‰Nä¸ªå˜é‡çš„SHAP-å€¼ä¸å˜é‡å€¼å…³ç³»å›¾ |

---

## âœ… çµæ´»ç‚¹

å¦‚éœ€æ”¹åŠ¨ï¼š

* åˆ‡æ¢å…¶ä»–æ¨¡å‹å¦‚ XGBoost â†’ `model = XGBClassifier()`
* è§£é‡Š AKI åˆ†çº§é¢„æµ‹ï¼ˆ`multi:softprob`ï¼‰ â†’ å¯ä½¿ç”¨ SHAP çš„å¤šç±»åˆ«è¾“å‡ºï¼ˆéœ€è°ƒæ•´ç»´åº¦ï¼‰

---
ç°åœ¨æˆ‘ä»¬è¿›å…¥æœ€åä¸€ä¸ªæ¨¡å—ï¼š

---

# âœ… æ¨¡å— 5ï¼šé£é™©åˆ†å±‚ä¸å¯è§†åŒ–

### ğŸ“ æ–‡ä»¶åå»ºè®®ï¼š

`risk_stratification_visualization.py`

---

## ğŸ¯ åŠŸèƒ½ç›®æ ‡

* åŸºäºé¢„æµ‹æ¦‚ç‡ï¼ˆAKI é£é™©å€¼ï¼‰ï¼Œå°†æ‚£è€…åˆ’åˆ†ä¸ºï¼š

  * ä½é£é™©ï¼ˆ<33åˆ†ä½ï¼‰
  * ä¸­é£é™©ï¼ˆ33\~66åˆ†ä½ï¼‰
  * é«˜é£é™©ï¼ˆ>66åˆ†ä½ï¼‰
* è¾“å‡ºï¼š

  * å„é£é™©ç­‰çº§æ‚£è€…æ•°é‡ã€AKIå‘ç”Ÿç‡ï¼›
  * æŸ±çŠ¶å›¾ï¼ˆäººæ•°ï¼‰+ é¥¼å›¾ï¼ˆæ„æˆæ¯”ï¼‰+ çƒ­åŠ›å›¾ï¼ˆæ··æ·†çŸ©é˜µï¼‰ï¼›
  * å¯è§†åŒ–å­˜å‚¨ä¸º `.png` æ–‡ä»¶ã€‚

---

## âœ… è„šæœ¬å†…å®¹å¦‚ä¸‹ï¼š

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

# ==== åŠ è½½æ•°æ® ====
df = pd.read_csv("04æ–‡çŒ®é˜…è¯»/05è‚¾ç—…/11åŸºäºæœºå™¨å­¦ä¹ çš„å† çŠ¶åŠ¨è„‰æ—è·¯ç§»æ¤æœ¯åæ€¥æ€§è‚¾æŸä¼¤é¢„æµ‹æ¨¡å‹/01data/simulated_cabg_aki_data.csv")
X = df.drop(columns=["AKI"])
y = df["AKI"]

# ==== æ ‡å‡†åŒ–è¿ç»­ç‰¹å¾ ====
scaler = StandardScaler()
numeric_cols = X.select_dtypes(include=np.number).columns
X[numeric_cols] = scaler.fit_transform(X[numeric_cols])

# ==== åˆ†å‰²æ•°æ® ====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# ==== æ¨¡å‹è®­ç»ƒä¸é¢„æµ‹æ¦‚ç‡ ====
model = RandomForestClassifier()
model.fit(X_train, y_train)
proba = model.predict_proba(X_test)[:, 1]

# ==== é£é™©åˆ†å±‚ ====
quantiles = np.quantile(proba, [0.33, 0.66])
risk_group = pd.cut(
    proba,
    bins=[-np.inf, quantiles[0], quantiles[1], np.inf],
    labels=["Low", "Medium", "High"]
)

# ==== ç»Ÿè®¡ä¿¡æ¯ ====
risk_df = pd.DataFrame({
    "True_AKI": y_test.values,
    "Predicted_Prob": proba,
    "Risk_Group": risk_group
})

summary = risk_df.groupby("Risk_Group").agg(
    Count=("True_AKI", "count"),
    AKI_Positive_Rate=("True_AKI", "mean")
).reset_index()

# ==== ä¿å­˜è¾“å‡ºç›®å½• ====
output_dir = "04æ–‡çŒ®é˜…è¯»/05è‚¾ç—…/11åŸºäºæœºå™¨å­¦ä¹ çš„å† çŠ¶åŠ¨è„‰æ—è·¯ç§»æ¤æœ¯åæ€¥æ€§è‚¾æŸä¼¤é¢„æµ‹æ¨¡å‹/02output"

# ==== æŸ±çŠ¶å›¾ ====
plt.figure(figsize=(6, 4))
sns.barplot(data=summary, x="Risk_Group", y="Count", palette="Blues_d")
plt.title("Patient Count by Risk Level")
plt.tight_layout()
plt.savefig(f"{output_dir}/risk_group_barplot.png")
plt.close()

# ==== é¥¼å›¾ ====
plt.figure(figsize=(5, 5))
plt.pie(summary["Count"], labels=summary["Risk_Group"], autopct="%1.1f%%", startangle=90)
plt.title("Risk Group Proportions")
plt.savefig(f"{output_dir}/risk_group_pie.png")
plt.close()

# ==== æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾ ====
pred_bin = (proba >= 0.5).astype(int)
cm = confusion_matrix(y_test, pred_bin)
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["No AKI", "AKI"], yticklabels=["No AKI", "AKI"])
plt.title("Confusion Matrix (Threshold=0.5)")
plt.tight_layout()
plt.savefig(f"{output_dir}/confusion_matrix_heatmap.png")
plt.close()

print("âœ… é£é™©åˆ†å±‚ä¸å¯è§†åŒ–å·²å®Œæˆï¼Œå›¾åƒå·²ä¿å­˜è‡³ï¼š", output_dir)
```

---

## ğŸ“Š è¾“å‡ºå†…å®¹

| æ–‡ä»¶                             | æè¿°         |
| ------------------------------ | ---------- |
| `risk_group_barplot.png`       | æ¯ä¸ªé£é™©ç­‰çº§æ‚£è€…äººæ•° |
| `risk_group_pie.png`           | é£é™©ç­‰çº§åˆ†å¸ƒæ¯”ä¾‹   |
| `confusion_matrix_heatmap.png` | æ¨¡å‹é¢„æµ‹æ··æ·†çŸ©é˜µå›¾  |

---

## âœ… è‡³æ­¤ï¼Œäº”å¤§æ¨¡å—å·²å…¨éƒ¨å®Œæˆï¼

æ˜¯å¦å¸Œæœ›æˆ‘æ•´ç†å¹¶æ‰“åŒ… `.py` æ¨¡å—ä¾›ä½ ä¸‹è½½ï¼Ÿæˆ–è€…ç”Ÿæˆä¸€ä¸ªä¸»è„šæœ¬ä¸€é”®è¿è¡Œæ‰€æœ‰æ¨¡å—ï¼Ÿä½ ä¹Ÿå¯ä»¥æå‡ºåç»­åŠŸèƒ½å¼€å‘æ–¹å‘ï¼ˆå¦‚æ¨¡å‹èåˆã€è‡ªåŠ¨è°ƒå‚ã€æ¨¡å‹å¯¼å‡ºç­‰ï¼‰ã€‚


