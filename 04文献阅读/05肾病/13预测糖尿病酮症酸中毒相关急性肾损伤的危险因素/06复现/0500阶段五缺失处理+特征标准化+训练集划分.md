非常好，我们现在进入：

---

# 📁 阶段五：缺失处理 + 特征标准化 + 训练集划分

🎯 目标：构建适合机器学习建模的数据集，完成以下操作：

* ✂️ 剔除高缺失变量（>20%）
* 🧩 填补低缺失变量（KNN 插补或中位数填充）
* 📐 特征标准化（StandardScaler）
* 🔄 分层划分训练集与测试集（85%/15%）

所有步骤均严格参考原论文方法与最佳实践。

---

## ✅ 一、准备：读取完整特征表（合并输出）

假设我们已有以下三部分数据：

| 数据表           | 说明                                        |
| ------------- | ----------------------------------------- |
| `cohort_df`   | 基础人口信息（stay\_id, age, gender, aki\_label） |
| `lab_pivot`   | 实验室指标                                     |
| `vital_pivot` | 生命体征指标                                    |

### 合并为总表：

```python
features_df = (
    cohort_df
    .merge(lab_pivot, on='stay_id', how='left')
    .merge(vital_pivot, on='stay_id', how='left')
)
```

---

## ✅ 二、缺失值处理

### 📊 步骤 1：统计每列缺失比例

```python
missing_pct = features_df.isnull().mean().sort_values(ascending=False)
print(missing_pct)
```

### ✂️ 步骤 2：删除缺失 >20% 的变量

```python
high_missing_cols = missing_pct[missing_pct > 0.2].index.tolist()
features_df = features_df.drop(columns=high_missing_cols)
print(f"删除变量：{high_missing_cols}")
```

---

## ✅ 三、类别变量转换（性别）

```python
features_df['gender'] = features_df['gender'].map({'M': 1, 'F': 0})
```

---

## ✅ 四、填补缺失值（中位数 / KNN）

如按论文方法保守处理，采用中位数填充：

```python
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='median')
X = features_df.drop(columns=['subject_id', 'hadm_id', 'stay_id', 'aki_label'])  # 特征列
X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)
```

📌 若想使用更先进的 KNNImputer：

```python
from sklearn.impute import KNNImputer
imputer = KNNImputer(n_neighbors=5)
X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)
```

---

## ✅ 五、特征标准化（Z-score）

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X_imputed.columns)
```

---

## ✅ 六、提取标签 + 构建训练集 & 验证集

```python
y = features_df['aki_label']

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(
    X_scaled, y, test_size=0.15, random_state=42, stratify=y
)
```

---

## ✅ 七、检查结果维度与分布

```python
print(f"训练集样本数: {len(X_train)}")
print(f"验证集样本数: {len(X_val)}")
print("标签分布（训练）:\n", y_train.value_counts(normalize=True))
print("标签分布（验证）:\n", y_val.value_counts(normalize=True))
```

---

## 🧾 阶段五输出成果

| 对象                   | 内容           |
| -------------------- | ------------ |
| `X_train`, `y_train` | 训练数据（标准化后）   |
| `X_val`, `y_val`     | 验证数据         |
| 特征数量                 | 原始变量 – 高缺失变量 |

---

## 📘 说明补充（符合原文方法）：

| 步骤        | 是否符合原论文方法         |
| --------- | ----------------- |
| 删除缺失率>20% | ✅ 明确说明            |
| 填补缺失值     | ✅ 原文使用了插补（KNN或均值） |
| 标准化处理     | ✅ 原文为机器学习建模必须前置步骤 |
| 分层抽样      | ✅ 保障训练测试集标签平衡     |
| 训练/验证比例   | ✅ 原文使用 85%/15%    |

---

是否继续进入：

# 📁 阶段六：特征选择（LASSO）+ 建模与性能评估？

我将给出 `LassoCV` 特征选择 + 8 种机器学习模型的训练与交叉验证完整代码。准备好了吗？
