非常好，既然您准备使用 **MIMIC-IV 数据库**来完全复现论文《Predicting the risk factors of DKA-associated AKI》，我将为您制定一个**结构清晰、按阶段分步骤推进**的复现大纲，完全适配您在 **VSCode + Jupyter Notebook + Python** 的开发环境中操作。

---

# ✅ MIMIC-IV 复现大纲：《Predicting the risk factors of DKA-associated AKI》

---

## 📁 阶段一：数据准备与提取

### 🧩 第一步：准备所需的 MIMIC-IV 表格（核心 7 张）

您需要使用如下 **MIMIC-IV 核心表格**来完成数据提取：

| 表名                                 | 用途说明                            |
| ---------------------------------- | ------------------------------- |
| `patients`                         | 获取年龄、性别、死亡时间等                   |
| `admissions`                       | 获取入院时间、ICU 停留时间                 |
| `icu_stays`（或 `icustays`）          | 获取 ICU 住院记录                     |
| `diagnoses_icd`                    | 筛选 DKA 患者（ICD-9/10 编码）          |
| `labevents`                        | 获取实验室指标（如 BUN、Scr、PLT、BG）       |
| `chartevents`                      | 获取生命体征（如 HR、RR、尿量）              |
| `prescriptions` / `procedures_icd` | 获取治疗信息（如 vasoactive drugs、CRRT） |

> 📌 注意：部分表格可能因安装方式不同而存放在 `mimiciv_hosp`, `mimiciv_icu` 等 schema 下，查询时需指定 schema。

---

## 📁 阶段二：数据清洗与构建分析数据集

### 🧩 第二步：筛选 DKA 患者

* 使用 `diagnoses_icd` 表中 **ICD-9/10 编码** 筛选糖尿病酮症酸中毒（DKA）患者。
* 常见编码示例：

  * ICD-9: `250.10`, `250.11`, `250.12`
  * ICD-10: `E10.10`, `E11.10`, `E13.10` 等

### 🧩 第三步：定义 AKI 发生（KDIGO 标准）

* 基于 `labevents` 中的 Serum Creatinine（itemid 通常为 `50912`）或 `chartevents` 中的尿量：

  * 血清肌酐升高 ≥ 0.3 mg/dL within 48h
  * 或 ≥ 1.5× baseline within 7 days
  * 或 24h 尿量 < 0.5 mL/kg/h

### 🧩 第四步：提取所需特征变量

按论文提取以下变量，按“入ICU 24h”内采集：

| 类型    | 变量                           |
| ----- | ---------------------------- |
| 人口统计  | 年龄、性别、体重                     |
| 生命体征  | HR、RR、SBP、DBP、GCS、尿量         |
| 实验室检查 | BUN、Scr、PLT、WBC、Na、Glucose 等 |
| 评分    | OASIS、SOFA、SAPS-II（如有）       |
| 干预    | 是否使用CRRT、NaHCO₃、是否通气、输液量等    |
| 合并症   | CKD、AMI、感染、UTI 等             |
| 结局    | 是否发生 AKI（作为标签）               |

---

## 📁 阶段三：特征工程与标签构造

### 🧩 第五步：处理缺失值与构建最终特征表

* 删除缺失值 > 20% 的变量；
* 其余变量使用 KNN 插补或均值/中位数插补；
* 所有变量标准化（建议使用 `StandardScaler`）；
* 标签列为 `AKI = 1 / 0`；

### 🧩 第六步：划分训练集与测试集

* 训练集：85%
* 测试集：15%
* 分层采样 stratify=y，确保类别均衡

---

## 📁 阶段四：建模与验证（完全复现论文）

### 🧩 第七步：特征选择（使用 LASSO）

* 使用 `LassoCV` 进行自动变量筛选，保留非零权重特征；
* 可视化 LASSO 系数柱状图；

### 🧩 第八步：训练 8 个 ML 模型，比较性能

| 模型名称                | sklearn 接口              |
| ------------------- | ----------------------- |
| Logistic Regression | `LogisticRegression`    |
| XGBoost             | `XGBClassifier`         |
| LightGBM            | `LGBMClassifier`        |
| AdaBoost            | `AdaBoostClassifier`    |
| GaussianNB          | `GaussianNB`            |
| ComplementNB        | `ComplementNB`          |
| MLP                 | `MLPClassifier`         |
| SVM                 | `SVC(probability=True)` |

* 使用 10 折交叉验证（`StratifiedKFold(n_splits=10)`）；
* 用以下指标进行比较：

  * AUC
  * Accuracy
  * Recall
  * Specificity
  * Precision
  * F1 Score

---

## 📁 阶段五：模型评估与可视化

### 🧩 第九步：绘图展示

* ROC 曲线（训练集 / 验证集 / 测试集）
* 校准曲线（`calibration_curve`）
* DCA（需自定义 net benefit 函数）
* SHAP 特征重要性解释（`shap.summary_plot`, `force_plot`）

---

## 📁 阶段六：保存结果与输出

### 🧩 第十步：保存内容

* 最优模型（`.pkl`）；
* 图像（`ROC`, `SHAP`, `Calibration`）；
* 结果表格（训练/测试集指标）保存为 `.xlsx`；
* SHAP 解释值保存为 `.csv`；

---

## 📘 最终目标输出

* 一套完整复现实验 pipeline；
* 可复用的 `.ipynb` 文件；
* 与论文一致的评估指标与图表；
* 所有可复用代码块模块化（数据提取/建模/评估分块编写）；

---

