æ ¹æ®æ‚¨å½“å‰çš„éœ€æ±‚ï¼ˆâ—ä¸ä½¿ç”¨ SQL / Postgresï¼Œè€Œæ˜¯ä½¿ç”¨ DuckDB + CSV æ–‡ä»¶ + Python + Jupyter Notebook åœ¨ VSCode ä¸­å¤„ç† MIMIC-IV æ•°æ®ï¼‰ï¼Œæˆ‘å·²ä¸ºæ‚¨**é‡æ–°è®¾è®¡äº†å®Œæ•´çš„å¤ç°å¤§çº²**ï¼Œå®Œå…¨åŸºäºè®ºæ–‡ã€ŠPredicting the risk factors of DKA-associated AKIã€‹çš„æ–¹æ³•ï¼Œä¸”å…¼å®¹ DuckDB å¤„ç†å¤§è§„æ¨¡æ•°æ®çš„èƒ½åŠ›ã€‚

---

# âœ… MIMIC-IV æ•°æ®å¤ç°å¤§çº²ï¼ˆDuckDB ç‰ˆæœ¬ï¼‰

ğŸ“˜ è®ºæ–‡æ ‡é¢˜ï¼š*Predicting the risk factors of DKA-associated AKI: A machine learning approach using XGBoost*

---

## ğŸ§© é˜¶æ®µä¸€ï¼šç¯å¢ƒå‡†å¤‡ä¸ DuckDB è®¾ç½®

### æ­¥éª¤ 1ï¼šç¯å¢ƒå‡†å¤‡

* âœ… ä½¿ç”¨ `duckdb` Python åº“ï¼ˆæ— éœ€å®‰è£… SQL æœåŠ¡ï¼‰ï¼š

```bash
pip install duckdb pandas scikit-learn xgboost lightgbm shap matplotlib seaborn imbalanced-learn
```

### æ­¥éª¤ 2ï¼šDuckDB å¼•æ“åˆå§‹åŒ–

```python
import duckdb
con = duckdb.connect(database=':memory:')  # æˆ–ä¿å­˜ä¸º 'mimiciv.duckdb'
```

---

## ğŸ“ é˜¶æ®µäºŒï¼šæ•°æ®åŠ è½½ä¸ DKA æ‚£è€…ç­›é€‰

### æ­¥éª¤ 3ï¼šè¯»å–å¹¶æ³¨å†Œ CSV è¡¨æ ¼ï¼ˆä½¿ç”¨ DuckDB å¤„ç†å¤§è¡¨ï¼‰

| CSV æ–‡ä»¶è·¯å¾„ç¤ºä¾‹                | è¡¨åå»ºè®®            | åŠŸèƒ½                                           |
| ------------------------- | --------------- | -------------------------------------------- |
| `hosp/patients.csv`       | patients        | è·å– anchor\_ageã€genderã€dod                    |
| `hosp/admissions.csv`     | admissions      | è·å– hadm\_idã€admittimeã€hospital\_expire\_flag |
| `icu/icustays.csv`        | icustays        | è·å– ICU stay\_idã€intimeã€outtime               |
| `hosp/diagnoses_icd.csv`  | diagnoses\_icd  | ç”¨äº DKA ICD ç¼–ç ç­›é€‰                              |
| `icu/labevents.csv`       | labevents       | è·å– Scrã€BUNã€WBCã€PLTã€Naã€BG ç­‰                   |
| `icu/chartevents.csv`     | chartevents     | è·å– HRã€RRã€å°¿é‡ã€ä½“é‡ã€GCS                           |
| `hosp/procedures_icd.csv` | procedures\_icd | ç”¨äºè¯†åˆ« CRRT ç­‰æ“ä½œ                                |
| `hosp/prescriptions.csv`  | prescriptions   | ç”¨äºè¯†åˆ«ä½¿ç”¨ NaHCOâ‚ƒ ç­‰è¯ç‰©                            |

ç¤ºä¾‹ä»£ç ï¼š

```python
con.execute("INSTALL httpfs; LOAD httpfs;")  # å¦‚æœä»è¿œç¨‹è¯»å– CSV
con.execute("CREATE VIEW patients AS SELECT * FROM read_csv_auto('/path/to/patients.csv');")
# ä¾æ­¤æ³¨å†Œå„è¡¨...
```

---

## ğŸ“ é˜¶æ®µä¸‰ï¼šæ„å»ºåˆ†ææ•°æ®é›†

### æ­¥éª¤ 4ï¼šç­›é€‰ DKA æ‚£è€…

```sql
-- ICD9/10 ç¼–ç 
SELECT DISTINCT hadm_id
FROM diagnoses_icd
WHERE icd_code IN ('25010', '25011', '25012', 'E1010', 'E1110', 'E1310');
```

### æ­¥éª¤ 5ï¼šåˆå¹¶ ICU ä¸äººå£ç»Ÿè®¡ä¿¡æ¯

ä½¿ç”¨ SQL æˆ– pandas åˆå¹¶ `icustays` + `admissions` + `patients`ï¼Œç”Ÿæˆ dka\_icustay cohortï¼Œå¹¶ç­›é€‰ age â‰¥ 18ã€‚

---

## ğŸ“ é˜¶æ®µå››ï¼šæ„å»º AKI æ ‡ç­¾

### æ­¥éª¤ 6ï¼šAKI åˆ¤å®šï¼ˆæ ¹æ® KDIGOï¼‰

åŸºäºä»¥ä¸‹è§„åˆ™æ„å»º AKI æ ‡ç­¾ï¼š

* Scr å‡é«˜ â‰¥ 0.3 mg/dL in 48hï¼Œæˆ– â‰¥ 1.5Ã—baseline in 7dï¼›
* æˆ–å°¿é‡ < 0.5 ml/kg/h Ã— 6 å°æ—¶ï¼›
* å¯å‚è€ƒå·²æœ‰ [AKI label æ„å»ºä»£ç ](https://github.com/YerevaNN/mimic3-benchmark/blob/master/mimic3benchmark/scripts/extract_aki_label.py)ã€‚

---

## ğŸ“ é˜¶æ®µäº”ï¼šç‰¹å¾æå–ä¸é¢„å¤„ç†

### æ­¥éª¤ 7ï¼š24å°æ—¶å†…å˜é‡æå–

ä»…ä¿ç•™å…¥ ICU åå‰ 24h çš„è®°å½•ï¼Œé€‰å–é¦–æ¬¡è®°å½•ï¼š

```sql
SELECT subject_id, hadm_id, stay_id, itemid, valuenum, charttime
FROM labevents
WHERE charttime <= DATETIME_ADD(intime, INTERVAL 24 HOUR);
```

æå–å˜é‡åŒ…æ‹¬ï¼š

* Vital signs: HR, RR, SBP, DBP, GCS, urine output
* Labs: BUN, Scr, WBC, Na, Glucose, PLT, Hb, Ca, Cl, AG, Phos, BG
* Others: infusion volume, OASIS/SOFA/SAPS-IIï¼ˆæ¥è‡ª `scores.csv` æˆ–è®¡ç®—ï¼‰

---

## ğŸ“ é˜¶æ®µå…­ï¼šç‰¹å¾å¤„ç†ä¸å»ºæ¨¡å‡†å¤‡

### æ­¥éª¤ 8ï¼šå¤„ç†ç¼ºå¤±å€¼

* åˆ é™¤ç¼ºå¤±æ¯”ä¾‹ >20% çš„å˜é‡ï¼›
* å‰©ä½™å˜é‡ä½¿ç”¨ï¼š

  * KNNImputer / Median å¡«å……ï¼›
  * `StandardScaler` æ ‡å‡†åŒ–æ‰€æœ‰è¿ç»­å˜é‡ï¼›

### æ­¥éª¤ 9ï¼šè®­ç»ƒé›†/éªŒè¯é›†åˆ’åˆ†

```python
from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)
```

---

## ğŸ“ é˜¶æ®µä¸ƒï¼šæ¨¡å‹è®­ç»ƒä¸æ€§èƒ½è¯„ä¼°

### æ­¥éª¤ 10ï¼šLASSO ç‰¹å¾é€‰æ‹©

```python
from sklearn.linear_model import LassoCV
lasso = LassoCV(cv=10).fit(X_train, y_train)
selected_features = X.columns[lasso.coef_ != 0]
```

### æ­¥éª¤ 11ï¼š8 æ¨¡å‹è®­ç»ƒä¸æ¯”è¾ƒ

åŒ…æ‹¬ï¼š

* XGBoost
* Logistic Regression
* LightGBM
* AdaBoost
* GaussianNB
* ComplementNB
* MLP
* SVM

ä½¿ç”¨ `cross_val_score` + `StratifiedKFold(n_splits=10)` è¯„ä¼°ï¼š

* AUC, Accuracy, Sensitivity, Specificity, F1 Score

---

## ğŸ“ é˜¶æ®µå…«ï¼šæ¨¡å‹è§£é‡Šä¸ç»“æœä¿å­˜

### æ­¥éª¤ 12ï¼šå¯è§†åŒ–ä¸è§£é‡Š

* ROC æ›²çº¿
* æ ¡å‡†æ›²çº¿
* DCAï¼ˆè‡ªå®šä¹‰ net benefit å‡½æ•°ï¼‰
* SHAP å¯è§£é‡Šæ€§åˆ†æ

```python
import shap
explainer = shap.Explainer(xgb_model)
shap_values = explainer(X_val)
shap.summary_plot(shap_values, X_val)
```

### æ­¥éª¤ 13ï¼šä¿å­˜ç»“æœ

```python
import joblib
joblib.dump(best_model, "model/xgb_model.pkl")
X_val.to_csv("output/X_val.csv")
```

---

## âœ… æ€»ç»“ï¼šè¾“å‡ºæ–‡ä»¶

| å†…å®¹       | æ–‡ä»¶ç±»å‹    |
| -------- | ------- |
| è®­ç»ƒæ¨¡å‹     | `.pkl`  |
| SHAP å›¾   | `.png`  |
| æ¨¡å‹æŒ‡æ ‡è¡¨æ ¼   | `.xlsx` |
| ç‰¹å¾é‡è¦æ€§æ’åè¡¨ | `.csv`  |

---

å¦‚æ‚¨ç¡®è®¤åï¼Œæˆ‘å¯ç«‹å³ä¸ºæ‚¨ç”Ÿæˆæ¯ä¸€é˜¶æ®µçš„ **DuckDB + pandas + sklearn å®ç°ä»£ç æ¨¡æ¿**ã€‚æ˜¯å¦ç»§ç»­è¿›å…¥é˜¶æ®µä¸€ï¼Ÿ
