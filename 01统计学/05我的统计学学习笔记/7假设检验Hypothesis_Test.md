# 7假设检验Hypothesis Test
<!-- > 求人如吞三尺剑，靠人如上九重天。

> 生活，就像夏天的柑橘树上挂着青皮的果，苦是一定的，但甜也会有。

> 路漫漫其修远兮，吾将上下而求索。 -->
## 7.1 基本思想
我们还是从问题开始讨论。这回提个接地气的问题——碧桂园曝雷后对全国房价是否有影响？嗯，假设检验其实就是为了解决这类问题。假设检验的基本思想——我们有样本，但是无法获得总体，需要对总体的分布形式或分布参数事先作出某种假设，然后根据样本观测值，运用统计分析的方法来检验这一假设是否正确。分解开来，假设检验=假设+检验（或者假设检验）。假设(hypothesis)——对总体的参数的具体数值（或分布形式）所作的陈述（总体参数包括总体均值、比例、 方差等，分析之前必需陈述）。假设检验(hypothesis test)—先对总体的参数（ 或分布形式）提出某种假设，然后利用样本信息判断假设是否成立的过程（有参数检验和非参数检验；逻辑上运用反证法， 统计上依据小概率原理）。

![[Pasted image 20230819093255.png]]

其实，假设检验，说白了，就是先提出一个假设（提出一个我们想让它被否定的假设，也可以说，提出一个我们认为它是错误的假设），我们先假设这个假设是正确的，然后再去找出和假设矛盾的地方，如果找到了和假设矛盾的地方，那就说明假设是有蹊跷的，是不完全对的，那么它就是错的，如果它是错的，我们就否定它，我们就不接受这个假设。这么说起来感觉有点绕，我都快被绕进去了，算了，直接进入正题吧。

先看一则名为“女士品茶”的小故事吧，假设检验的思想就蕴含其中。

Fisher教授描述有一位女士声称自己在喝英式茶的时候能区分出来是茶先倒进杯子还是奶先倒进杯子。 于是Fisher教授就打算设计一个实验来验证这位女士是否真的具有她描述的这种能力。Fisher教授当时的心情可能就跟我听见我朋友说“我只要抽一口雪茄，就知道这支雪茄的产地”，或者告诉我“我只要看一眼某个女生，我就知道她的size”一样半信半疑吧。

常识告诉我们，如果想得到有意义的结论，就应该随机给女士几杯茶让女士鉴别一番，根据她答对的次数（或者答对的比例）来判断她是否有这个能力。可是问题是，要做多少次实验呢？根据结果我们又如何来给出定量的结论呢？Fisher君在当年就给出了他的一套实验方法：

> 他调配出了八杯其他条件一模一样而仅仅是倒茶倒奶顺序相反的茶，其中两类各四个（为了少打几个字，我在下文中称其为“奶”或者“茶”）。然后他让女士品尝之后告诉他哪四杯是“奶”。当然，剩下的就都是“茶”了。

在分析实验结果的时候，他运用了这样的逻辑：

> 他首先假设女士没有这个能力（这个假设被称为原假设），然后如果女士很好的鉴别了这八杯茶，那就说明在原假设成立的情况下，发生了非常反常的现象，以至于说明原假设是令人怀疑的。==从统计上来说，如果在原假设成立的前提下，发生了非常小概率的事件，那我们就有理由怀疑原假设的真实性。==

这也是Fisher的假设检验的基本思路。在我看来这有点像反证法，我首先假设我想推翻的命题成立，然后试图找出矛盾，找出不合理的地方来证明否命题为假命题。不同之处在于在随机实验中，经常找不到完全不可能发生的事情。

Fisher君的原假设是：
> ==$H_{0}$ : 女士没有这样的能力。==

实验可能出现的结果是：

设女士选对了X杯“奶”。因为两种各4杯，所以X可能出现的值是集合 {0,1,2,3,4}{0,1,2,3,4}  中的一个。在原假设的前提下，女士是毫无根据的瞎猜，这就好比一个袋子里放了8个球，红黑各4个。不放回的情况下随机的抽取4个球，其中红色球数目X的概率分布是多少？

   好熟悉的感觉，这让我不禁想起了高二那天在夕阳下的奔跑。对，这仅仅就是个高二课后作业题。答案如下：


|情况 |排列组合| 概率 | 
|---|---|---|
|$P=(0)$|$C_{4}^{0}$\*$C_{4}^{4}$|$\dfrac{1}{70}$|
|$P=(1)$|$C_{4}^{1}$\*$C_{4}^{3}$|$\dfrac{16}{70}$|
|$P=(2)$|$C_{4}^{2}$\*$C_{4}^{2}$|$\dfrac{36}{70}$|
|$P=(3)$|$C_{4}^{3}$\*$C_{4}^{1}$|$\dfrac{16}{70}$|
|$P=(4)$|$C_{4}^{4}$\*$C_{4}^{0}$|$\dfrac{1}{70}$|

对于这样的分布，Fisher又说了，即使X=3，女士鉴别出来了6杯茶，我们也不能拒绝原假设（认为女士有鉴别能力）。因为如果在X=3的情况下拒绝了原假设，那在X=4的情况下（女士鉴别出了8杯茶！）也要拒绝原假设。所以在原假设成立的前提下，拒绝原假设的概率变成了$\dfrac{17}{70}$。也就是说如果女士没有这个能力，但是她侥幸靠瞎猜通过了测试，使我们我们错误的认为她有这个能力的概率居然有$\dfrac{17}{70}$！这种错误被称为第一类错误，一般来说不希望这个错误发生的概率超过5%。在这里说明一下，这种错误叫弃真错误，顾名思义，”把真的结论丢弃“，”放弃真正的结论“。

我想你一定对上面这段话有疑惑吧（因为我也没看懂，如果你问我我为什么没看懂，那是因为，上面的文字根本不是我写的qwq），如果你对上面的文字没有疑惑，并且能读懂的话，那就不用看下面的文字了。

好了，废话就写到这里了，接下来讲正事。

第一，先解释一下下面这个表格的意思，

|情况 |排列组合| 概率 | 
|---|---|---|
|$P=(0)$|$C_{4}^{0}C_{4}^{4}$|$\dfrac{1}{70}$|
|$P=(1)$|$C_{4}^{1}C_{4}^{3}$|$\dfrac{16}{70}$|
|$P=(2)$|$C_{4}^{2}C_{4}^{2}$|$\dfrac{36}{70}$|
|$P=(3)$|$C_{4}^{3}C_{4}^{1}$|$\dfrac{16}{70}$|
|$P=(4)$|$C_{4}^{4}C_{4}^{0}$|$\dfrac{1}{70}$|

这个表格是说，假如我们找一个没有鉴别能力的女士，让她同样鉴别这八杯茶，那么她会怎样去鉴别呢？你猜猜看。

很简单，换位思考一下，假如你是她，你会怎么做呢？当然是凭直觉咯！哈哈哈，我又忍不住写了几句废话，哈哈哈。可是啊，人类的直觉在这个时候往往是不准的哦，所以，基本只能靠运气咯！说到运气，就说到点子上了，因为，运气是可以用概率算出来的，此话怎讲呢？或者说，怎么算概率呢？

你想一下，一共八杯茶，你的目标是从中选出四杯先加奶后加茶的奶茶，只要你选出了四杯先加奶后加茶的奶茶，那么，剩下的四杯茶自然是先加茶后加奶的茶奶咯！

把这个问题等价替换一下，相当于在一个箱子中，有八个球，其中四个红球，四个黑球，你需要从这个箱子中一次性抓取四个球，并且要尽可能多得抓到红球。那么有五种结果，
- 你抓到了0个红球，也就是说，你抓到的4个球都是黑球
- 你抓到了1个红球，也就是说，你抓到了1个红球和3个黑球
- 你抓到了2个红球，也就是说，你抓到了2个红球和2个黑球
- 你抓到了3个红球，也就是说，你抓到了3个红球和1个黑球
- 你抓到了4个红球，也就是说，你抓到的4个球都是红球

只可能出现上述的5种情况，也就是五种分类，即五种排列组合方式。接下来算概率（关于排列组合的计算方法，我懒得写了，我想你应该能看懂），

总排列情况$=C_{8}^{4}=\dfrac{8*7*6*5}{4*3*2*1}=70$
- 抓到0个红球，也就是抓到0个红球，并抓到4个黑球的情况$=C_{4}^{0}$\*$C_{4}^{4}=1*1=1$，所以抓到0个红球的概率为$\dfrac{C_{4}^{0}C_{4}^{4}}{C_{8}^{4}}=\dfrac{1*1}{\dfrac{8*7*6*5}{4*3*2*1}}=\dfrac{1}{70}$
- 抓到1个红球，也就是抓到1个红球，并抓到3个黑球的情况$=C_{4}^{1}C_{4}^{3}=4*4$,所以抓到1个红球的概率为$\dfrac{C_{4}^{1}C_{4}^{3}}{C_{8}^{4}}=\dfrac{4*4}{\dfrac{8*7*6*5}{4*3*2*1}}=\dfrac{16}{70}$
- 抓到2个红球，也就是抓到2个红球，并抓到2个黑球的情况$=C_{4}^{2}C_{4}^{2}=6*6$,所以抓到2个红球的概率为$\dfrac{C_{4}^{2}C_{4}^{2}}{C_{8}^{4}}=\dfrac{6*6}{\dfrac{8*7*6*5}{4*3*2*1}}=\dfrac{36}{70}$
-  抓到3个红球，也就是抓到3个红球，并抓到1个黑球的情况$=C_{4}^{3}C_{4}^{1}=4*4$,所以抓到3个红球的概率为$\dfrac{C_{4}^{3}C_{4}^{1}}{C_{8}^{4}}=\dfrac{4*4}{\dfrac{8*7*6*5}{4*3*2*1}}=\dfrac{16}{70}$
- 抓到4个红球，也就是抓到4个红球，并抓到0个黑球的情况$=C_{4}^{4}C_{4}^{0}=1*1$,所以抓到4个红球的概率为$\dfrac{C_{4}^{4}C_{4}^{0}}{C_{8}^{4}}=\dfrac{1*1}{\dfrac{8*7*6*5}{4*3*2*1}}=\dfrac{1}{70}$

以上解释了表格的计算过程，也算个是废话的一种类型吧，哈哈哈。

为什么要考虑这个表格呢？接下来是重点，请认真听好，建议拿出本子记好。

|情况 |排列组合| 概率 | 
|---|---|---|
|$P=(0)$|$C_{4}^{0}C_{4}^{4}$|$\dfrac{1}{70}$|
|$P=(1)$|$C_{4}^{1}C_{4}^{3}$|$\dfrac{16}{70}$|
|$P=(2)$|$C_{4}^{2}C_{4}^{2}$|$\dfrac{36}{70}$|
|$P=(3)$|$C_{4}^{3}C_{4}^{1}$|$\dfrac{16}{70}$|
|$P=(4)$|$C_{4}^{4}C_{4}^{0}$|$\dfrac{1}{70}$|

因为这个表格给出了，不依赖鉴别能力辨别出奶茶的概率，即普通人鉴别出奶茶的概率。

如果一个人有一天，你下班之后，有个人跑过来跟你说，他是上帝，现在流落人间，法力微弱，需要你的帮助才能返回天堂，你信还是不信。废话，鬼才信。但你突然慈悲心大发（我也不知道你为什么慈悲心大发），这时你从你的钱包里拿出了一枚一元硬币给他，然后，他为了向你证明他是上帝，于是在你面前抛起了硬币，
- 第一次，正面，你不信
- 第二次，正面，你不信
- 第三次，正面，你还是不信，因为有时候你也能连抛三次正面
- 第四次，正面，你还是不信，他一定有什么抛硬币的技巧
- 第五次，正面，你还是不信，他绝对有什么抛硬币的技巧
- 第六次，正面，你开始动摇了
- 第七次，正面，莫非，他真是上帝？
- 第八次，正面，他绝对有什么抛硬币的技巧！！！

后来，他把硬币交给了你，他让你抛，他猜正反面
- 第一次，他猜对了，你不信
- 第二次，他猜对了，你不信
- 第三次，他猜对了，你还是不信，因为有时候你也能连续三次猜对
- 第四次，他猜对了
- 第五次，他又猜对了
- 第六次，他又双猜对了
- 第七次，他又双叒猜对了
- 第八次，他又双叒叕猜对了

这时候，你说了一声”你真牛逼！“，然后，你相信他就是上帝，接着，你开始给他转账，最后被他骗得倾家荡产！哈哈哈，这个故事我讲完了，又是一堆废话，哈哈哈。

我们先来理一下，为什么他前三次猜对的时候你不相信他就是上帝，到了后面你就相信了呢？

这用统计学中的假设检验很好理解，当他告诉你他是上帝的时候，你是怀疑的，你是不相信他的，所以你在自己的潜意识里告诉自己，”他不是上帝“，这就是原假设，所以==$H_{0}=他不是上帝$==

但是，为什么后来你相信他是上帝了呢？很简单，他办到了凡人办不到的事情，凡人可无法向他一样连续八次都猜对。所以你相信了”他是上帝“。

这用统计学中的假设检验很好理解，他连续八次都猜对，这是违反常识的，这是与原假设矛盾的。为什么矛盾呢？因为，在原假设的条件下，他不是上帝，也就是说他不可能连续八次都猜对，但是事实是他连续八次都猜对，“连续八次都猜对”是一种小概率事件，既然出现了这种小概率事件，那么你就开始怀疑原假设的正确性，既然出现了这种小概率事件，那么你就认为原假设是错误的，即”他不是上帝“是错误的。

接下来给一张概率表

|猜对的次数 |概率|
|---|---|
|1|$(0.5)^{1}=0.5$|
|2|$(0.5)^{2}=0.25$|
|3|$(0.5)^{3}=0.125$|
|4|$(0.5)^{4}=0.0625$|
|5|$(0.5)^{5}=0.03125$|
|6|$(0.5)^{6}=0.015625$|

当他第五次猜对的时候，从统计学上来说，这个时候就可以拒绝原假设了。为什么呢？你仔细看一下上面的表格，如果让一个凡人去猜，让一个凡人凭运气去猜的话，凡人连续五次猜对的概率是$(0.5)^{5}=0.03125$，很明显$0.03125<0.05$，而统计学上规定，发生概率小于$0.05$的事件为小概率事件，是凡人办不到的。==由于出现了小概率事件，所以我们就有理由拒绝原假设。==

现在，让我们回到女士品茶的故事主线，还是这个表

|情况 |排列组合| 概率 | 
|---|---|---|
|$P=(0)$|$C_{4}^{0}C_{4}^{4}$|$\dfrac{1}{70}$|
|$P=(1)$|$C_{4}^{1}C_{4}^{3}$|$\dfrac{16}{70}$|
|$P=(2)$|$C_{4}^{2}C_{4}^{2}$|$\dfrac{36}{70}$|
|$P=(3)$|$C_{4}^{3}C_{4}^{1}$|$\dfrac{16}{70}$|
|$P=(4)$|$C_{4}^{4}C_{4}^{0}$|$\dfrac{1}{70}$|

如果凭运气去猜，那么
- 这位女士猜对4杯奶茶（也就是她选出的四杯茶都是奶茶）的概率为$\dfrac{1}{70}$
- 这位女士猜对3杯奶茶的概率为$\dfrac{16}{70}$
- 这位女士猜对2杯奶茶的概率为$\dfrac{36}{70}$
- 这位女士猜对1杯奶茶的概率为$\dfrac{16}{70}$
- 这位女士猜对0杯奶茶的概率为$\dfrac{1}{70}$

所以
- 这位女士猜对4杯奶茶（也就是她选出的四杯茶都是奶茶）的概率为$\dfrac{1}{70}=0.014286$
- 这位女士猜对3杯以上奶茶的概率为$\dfrac{17}{70}=0.24286$
- 这位女士猜对2杯以上奶茶的概率为$\dfrac{36}{70}=0.75143$
- 这位女士猜对1杯以上奶茶的概率为$\dfrac{69}{70}=0.98571$
- 这位女士猜对0杯以上奶茶的概率为$\dfrac{70}{70}=1$

如果用统计学来理解的话就是，首先，我们先给出一个原假设==$H_{0}$:女士没有这样的能力。==只有发生小概率事件的时候我们才能拒绝原假设。

仔细看上面的表格我们发现， 
- 这位女士猜对2杯以上奶茶的概率为$\dfrac{36}{70}=0.75143$，$0.75143>0.05$，所以这位女士猜对2杯以上奶茶不是小概率事件，所以我们不能拒绝原假设。
- 这位女士猜对3杯以上奶茶的概率为$\dfrac{17}{70}=0.24286$，$0.24286>0.05$，所以这位女士猜对3杯以上奶茶不是小概率事件，所以我们不能拒绝原假设。
- 这位女士猜对4杯奶茶的概率为$\dfrac{1}{70}=0.014286$，$0.014286<0.05$，所以这位女士猜对4杯以上奶茶是小概率事件，所以我们拒绝原假设。

所以，只有当该女士辨别出4杯奶茶的时候，我们才能拒绝原假设==$H_{0}$:女士没有这样的能力。==

以上内容是为了解释：

> 对于这样的分布，Fisher又说了，即使X=3，女士鉴别出来了6杯茶，我们也不能拒绝原假设（认为女士有鉴别能力）。因为如果在X=3的情况下拒绝了原假设，那在X=4的情况下（女士鉴别出了8杯茶！）也要拒绝原假设。所以在原假设成立的前提下，拒绝原假设的概率变成了17/70。也就是说如果女士没有这个能力，但是她侥幸靠瞎猜通过了测试，使我们我们错误的认为她有这个能力的概率居然有17/70！这种错误被称为第一类错误，一般来说不希望这个错误发生的概率超过5%。在这里说明一下，这种错误叫弃真错误，顾名思义，”把真的结论丢弃“，”放弃真正的结论“。

好的，现在再来说说为第一类错误，也叫弃真错误。
如果女士没有这个能力，那她只能凭运气瞎猜，如果她恰巧侥幸靠瞎猜通过了测试，使我们误以为她真的有辨别能力。如果我们此时认为她有这个能力，那么我们就犯错误了，这种错误叫弃真错误。为什么叫弃真错误呢？因为原假设==$H_{0}$:女士没有这样的能力。==是真命题，但是，我们错误地认为原假设是不正确的，所以我们把原假设舍弃了，所以这种错误叫弃真错误

那么，她靠运气通过测试的概率是多少呢？
- 假如她靠运气去猜，那么她猜对2杯以上奶茶的概率为$\dfrac{36}{70}=0.75143$
- 假如她靠运气去猜，那么她猜对3杯以上奶茶的概率为$\dfrac{17}{70}=0.24286$
- 假如她靠运气去猜，那么她猜对4杯奶茶的概率为$\dfrac{1}{70}=0.014286$

- 如果我们规定，只要这位女士猜对2杯奶茶，她就可以通过测试，那么，也就是说，我们犯第一类错误的概率为$\dfrac{36}{70}=0.75143$
- 如果我们规定，只要这位女士猜对3杯奶茶，她就可以通过测试，那么，也就是说，我们犯第一类错误的概率为$\dfrac{17}{70}=0.24286$
- 如果我们规定，只要这位女士猜对3杯奶茶，她就可以通过测试，那么，也就是说，我们犯第一类错误的概率为$\dfrac{1}{70}=0.014286$

但是啊！我们要尽量减小第一类错误的概率，那么要减小到多少呢？统计学上规定，犯第一类错误的概率要小于$0.05$，这就是为什么我们常常在论文中看到$P<0.05$，有时候我们还能看到$P<0.01$，这时说明，犯第一类错误的概率为$0.01$。

当然咯，犯第一类错误的概率不是越小越好，因为在减小第一类错误的同时会增加犯第二类错误的概率，这个我们后面再讲。

女士品茶的故事还没讲完，最后那位女士真的分辨出了那8杯茶！

正如我在前言中提到的那样：

> 女士品茶的故事，其实就是一个妹子说”我能辨别出一杯奶茶是先加奶还是先加茶“，有一个直男说”我不信，你证明给我看“。结果发现女士真的能辨别出来，直男无话可说。

>试想一下，如果那位女士，只辨别出1杯，甚至1杯也没辨别出来，直男会不会狠狠地嘲笑一下那位女士呢？

>再试想一下，如果有一天，你的女朋友问你”我是个小仙女吗？“又或者问你“我有没有林妹妹的气质？”，你又该怎么回答，很简单，首先，原假设是“你是小仙女”“你有林妹妹的气质”，那么如果你是小仙女，请飞一个给我看看，顺便做首诗，什么？不会！身为小仙女尽然不会飞，有林妹妹的气质，竟然不会做诗，这不是传说中的小概率事件吗？既然发生了传说中的小概率事件，那么就说明原假设不正确，原假设错误，则备择假设正确，即"女朋友不是小仙女"，"女朋友没有林妹妹的气质"。这个时候，女朋友不高兴了，她生气了，她要跟你这个不解风情的直男分手，请问现在该怎么办？在线等，挺急的！

以上就是假设检验的基本思想，接下来我们来看假设检验中的原假设和备择假设
## 7.2 原假设和备择假设
从前面的介绍我们知道，假设检验的第一步是建立假设。那么假设分为两种（原假设和备择假设）。那么这二者具体又是什么呢？

看官老爷们莫急，且听我娓娓道来：

- 原假设 (null hypothesis)——原假设又称 “ 0 假设”，总是有符号 =，≥ 或 ≤，表示为 H0。是研究者想收集证据予以反对的假设（生产实践中常对应正常情形，如均值与设计一致）；一般来说，原假设是一旦拒绝便要采取行动的假设。因此，原假设总是 “受到保护的假设” ，没有充分的证据是不能拒绝原假设的。例如，对一家信誉很好的工厂的产品进行检验，原假设一般是 “ 产品合格”。
- 备择假设 (alternative hypothesis)——研究者想收集证据予以支持的假设，一旦发生就要采取行动，是与原假设对立的假设，也称 “研究假设”，总是有符号 ̸=，> 或 <，表示为 H1。

总结起来就是，原假设是统计学史上最悲催角色——它从一开始诞生，就是为了被科学家们发好人卡拒绝而存在的一个假设。而备择假设才是科学家们追求的白富美。

搞明白了这两个假设，下一步我们做假设检验的时候，就要先提出假设了，这里给了一些提出假设
的要点：

> * 原假设和备择假设是一个完备事件组，而且相互对立（在一项假设检验中，原假设和备择假设必有一个成立，而且只有一个成立）。
> * 先确定备择假设，再确定原假设。
> * 等号 “ =”
总是放在原假设上。
> * 因研究目的不同，对同一问题可能提出不同的假设（也可能得出不同的结论）。

好嘚，小小地解释一下上面的内容。原假设和备择假设组成一个完备事件组，是说原假设和备择假设组成一个全集。
不一定先确定备择假设，再确定原假设，但一般来说是先确定备择假设，再确定原假设，根据研究目的，看哪个比较容易确定。

好吧，还是有点不理解。这里说的不理解不是说你不理解，而是说我不理解，因为上面的内容不是我写的，既然不是我写的，我看不懂很正常。那么，看不懂怎么办？很简单，直接上例子
#### 新生儿的例子
例子如下：

由统计资料得知，1989年某地新生儿的平均体重为3190克，现从190年的新生儿中随机抽取100个，测得其平均体重为3210克，问1990年的新生儿与1989年相比，体重有无显著差异？

解：

从调查结果来看，1990年新生儿的平均体重为3210克，比1989年新生儿的平均体重3190克增加了20克，但这20克的差异可能来源于不同的情况：

- 一种情况是，1990年新生儿的平均体重于1989年相比，本质上和1989年相比没有什么差异，20克的差异是抽样的随机性造成的。换言之，样本量太少了，抽出的100名新生儿可能恰巧是体重偏重的新生儿，想要排除这种情况，很简单，增加样本量就行，比如抽取1000名，10000名，甚至100000名，但是增加样本量会增加成本，比如时间成本、经济成本等等。如果你是去记录新生儿的基层工作者，因为统计员的一句“样本量太少，继续记录”，你就要记录成百上千的数据，你愿意吗？反正我是不愿意的，凭什么？当然，如果他给的钱够多，也不是不行，哈哈哈。
- 另一种情况是，抽样的随机性不可能造成20克这样大的差异，1990年新生儿的体重与1989年新生儿的体重相比确实有所增加。

上述问题的关键点是：

> 20克的差异说明了什么？

> 这个差异能不能用抽样的随机性来解释？换言之，这个差异是不是抽样的随机性造成的？

为了回答这个问题，我们可以采取假设的方法。

假设1989年和1990年新生儿的体重没有明显差异（这里的原假设就是“1989年和1990年新生儿的体重没有明显差异”，正如前文所说，原假设是统计学史上最悲催角色——它从一开始诞生，就是为了被科学家们发好人卡拒绝而存在的一个假设，所以后面的步骤就是竭尽全力地去给原假设发好人卡，竭尽全力地去拒绝原假设），如果用$μ_{0}$表示1989年新生儿的平均体重，用$μ$表示1990年新生儿的平均体重我们的假设可以表示为$μ=μ_{0}$或者$μ-μ_{0}=0$，现在要利用1990年新生儿的体重的样本信息（也就是抽取的100名新生儿的平均体重）检验上述假设是否成立。

- 如果成立，说明这两年新生儿的体重没有显著差异
- 如果不成立，说明这两年新生儿的体重有显著差异，说明1990年新生儿的体重有了明显增加。如果你是一个有野心，或者有好奇心的人，那么接下来就是研究是什么原因导致新生儿的体重有了明显增加，以及这种体重的增加是否有危害。不过，这些都是后话了。

在这里，问题是以假设的形式提出的，问题的解决方案是检验提出的假设是否成立。所以假设的实质是检验我们关心 的参数——1990年的新生儿总体平均体重是否等于我们感兴趣的数值。

以上就是新生儿的例子。

在实际应用中，我们有不同的需求，因此又有双侧检验和单侧检验的区分，在这里先浅浅地介绍一下
> * 双侧检验——备择假设没有特定的方向性，并含有符号 “=” 的假设检验，称为双侧检验或双尾检验 (two-tailed test)
> * 单侧检验——备择假设具有特定的方向性，并含有符号 “>” 或 “<” 的假设检验，称为单侧检验或单尾检验 (one-tailed test)。其中备择假设的方向为 “<”，称为左侧检验，备择假设的方向为 “>”，称为右侧检验。

原假设与备择假设形式：
> * 双边检验：H0: µ = 2, H1: µ ̸= 2。
> * 单边检验：左侧检验——H0: µ ≥ 2, H1: µ < 2，右侧检验——H0: µ ≤ 2, H1: µ > 2。

各位看官老爷们，接下来我们看假设的表达式，具体讲一讲原假设和备择假设
### 假设的表达式
> 统计的语言是用一个等式或不等式表示问题的原假设。

让我们再回到新生儿的例子，在新生儿的例子中，原假设采用等式的方式，即
$$H_{0}:µ=3190克$$

这里$H_{0}$表示原假设。由于原假设（H）的下标用0表示，所以有些文献中将原假设称为“零假设”。$µ$是我们要检验的参数，即1990年新生儿总体平均体重的均值。

该表达式提出的命题是，1990年的新生儿与1989年新生儿在体重上没有什么差异。换言之，$H_{0}:µ=3190克$的意思是1990年的新生儿与1989年新生儿在体重上没有什么差异。

显然，3190克是1989年新生儿总体的均值，是我们感兴趣的数值。如果用$µ_{0}$表示感兴趣的数值，原假设的表达式为：

$$H_{0}:µ=µ_{0}$$
或
$$H_{0}:µ-µ_{0}=0$$

尽管原假设陈述的是两个总体的均值相等，却并不表示它是既定的事实，仅是假设而已。

- 如果原假设不成立，就要拒绝原假设，而需要再另一个假设中做出假设，另一个假设与原假设互斥，称为备择假设。

在新生儿的例子中，备择假设的表达式为：
$$H_{0}:µ≠3190克$$

$H_{1}$表示备择假设，它意味着1990年的新生儿与1989年的新生儿在体重上有明显差异。备择假设更一般的表达式为：

$$H_{1}:µ≠µ_{0}$$
或
$$H_{1}:µ-µ_{0}≠0$$

原假设与备择假设互斥，
- 肯定原假设，意味着放弃备择假设
- 否定原假设，意味着接受备择假设

由于假设检验是围绕着对原假设是否成立而展开的，所以有些文献也把备择假设称为替换假设，表明当原假设不成立时的替换。

好的，以上就是原假设与备择假设的全部内容。
既然有了原假设和备择假设，那么下一步干什么呢？
正如前文所说
> 原假设是统计学史上最悲催角色——它从一开始诞生，就是为了被科学家们发好人卡拒绝而存在的一个假设。而备择假设才是科学家们追求的白富美。

下一步就是给原假设发好人卡，去追求白富美咯~

那么，如何给男人发好人卡呢？无非就是，你人挺好的，你是个好人，但我们真的不合适。

如何给原假设发好人卡呢？无非就是，原假设人畜无害，但是发生了小概率事件。

注意，这里提到了小概率事件，如果你忘记了什么是小概率事件，可以看看前文（也可以不用看，因为下面有解释）。

为了增强记忆，下面再来看一个例子，我懒得打字了，直接看图吧：

![[Pasted image 20230819101530.png]]

所以拒绝原假设的理由是假设检验中的小概率原理。那么什么是小概率？

• 在一次试验中，一个几乎不可能发生的事件发生的概率。
• 在一次试验中小概率事件一旦发生，我们就有理由拒绝原假设。
• 小概率由研究者事先确定。

所以拒绝 H0的理由就是

![[Pasted image 20230819105900.png]]

![[Pasted image 20230819105945.png]]

我懒得解释上面的图了，以后再说吧。

接下来到了我觉得比较绕的内容，不过，我想，如果你看了我前文写的有关第一类错误的内容，或许对你理解下面的内容有帮助。下面开始介绍第一类错误和第二类错误。
## 7.3第一类错误和第二类错误
上文介绍了假设检验的过程，但是假设检验过程会不会出现错误呢？其实大家仔细分析拒绝原假设的理由就会发现问题了。通常情况下原假设是小概率事件，但是小概率事件  $≠$ 0 概率事件。小概率事件不是不发生，而是发生概率较小。就像天气预报说明天有 99% 的可能不下雨，结果 1% 的可能性成为了事实，明天下雨了。因此假设检验中会有两类错误（弃真错误和取伪错误）经常出现。

（1）第一类错误 (弃真错误)：
• 原假设为真时拒绝原假设。
• 第一类错误的概率为 α（没错，就是它，我们的好朋友，小 α。咳咳咳，就是显著性水平，一般由研究者事先指定，常用的值有 0.01, 0.05, 0.10）。

（2）第二类错误（取伪错误）：
• 原假设为假时未拒绝原假设。
• 第二类错误的概率记为 β。

看到这里，我想你一定很懵吧，先不管你懵不懵，我已经开始懵了，真的真的看不懂啊！一会第一类错误，一会第二类错误的，一会 α，一会又 β的。一会原假设为真，一会原假设为假，一会拒绝原假设，一会又接受原假设。真是让人费解。

各位看官老爷们，莫慌，请看下一节内容，第一类错误和第二类错误的详解。
### 第一类错误和第二类错误的详解
#### 假设检验中的第一类错误和第二类错误
这是支撑统计学中假设检验的最重要概念。

我们每天都在为选择进行自己的假设，并且按照自己认为最好的方向做出选择，所以假设在我们的生活中是无处不在的，例如：A 路是否会比 B 路花费更少的时间，X 的平均投资回报率是否高于 Y 的投资，以及电影 ABC 是否比电影 XYZ 好。在所有这些情况下，我们都在对我们做出的假设进行检验。

建立假设，使用数据证明/反驳它们，帮助企业做出决策，这是数据科学家的实际工作。人们通常依靠概率来理解偶然观察数据的可能性，并利用它围绕假设得出结论。概率永远（几乎！）不会 100%，这反过来意味着我们永远无法 100% 确定我们的结论。所以在围绕我们假设的假设得出结论时，总是会出现错误的情况。

下面的就是对统计假设检验期间发生的 Type-I和 Type-II 错误的直观而详细的解释。

不过在介绍假设检验的Type-I和 Type-II 错误之前，不妨再复习一遍假设检验的概念和过程吧。孔子他老人家说的好，温故而知新嘛！
####  假设检验
##### 假设检验的概念
假设检验是通过观察样本数据来检验围绕总体参数的假设的领域，因为我们很少有整体的数据，所以只能从整体中进行抽样观察。

这通常是通过从假设的中性状态（称为原假设、零假设、虚无假设）开始并根据观察到的样本数据证明或反驳这一点来完成的。

-   原假设 (H0) 是假设总体数据中的现状（无关系或无差异）的中性假设。
-   H1 是 H0 的备选项，称为备择假设也被称为对立假设。

假设检验的基本思想是概率性质的反证法。根据所考察问题的要求提出原假设和备择假设，为了检验原假设是否正确，先假定原假设是正确的情况下，构造一个小概率事件，然后根据抽取的样本去检验这个小概率事件是否发生。

##### 假设检验过程

假设 H0 → 观察样本数据 → 拒绝或不拒绝 H0

我们假设中性 H0 为真，并在观察到的数据中寻找“拒绝”或“不拒绝”H0 的证据。根据观察到的样本数据，我们计算观察到的统计量和观察到的 P 值；例如：从我们观察到的样本中获得的假设 H0 为真的概率。

> 如果代入到前文所讲的女士品茶的故事中就是：
> - 原假设H0：这位女士没有鉴别能力。
> - 下一步计算，原假设H0为真时，事件（奶茶被女士凭运气分辨出的概率），算出来的概率即为P值。
> - 再下一步，将计算出的P值与预先设定的显著性水平（也可以称为Alpha 值，一般为0.05，有时可以设为0.10或0.01）进行比较。
> - 最后一步，根据比较结果，选择是接受原假设还是拒绝原假设。

> 当然咯，倒数第二步的比较过程也是有技巧的哦
> 技巧如下：
> - 观察到的 P 值 ≤ 预选 Alpha 级别 → 拒绝 H0
> - 观察到的 P 值 > 预选的 Alpha 级别 → 不拒绝 H0
> 
> 如果这个时候你在仔细思考一下女士品茶的故事，我想，你一定会回味无穷，你品，你细品。


将该观察到的 P 值与预先确定的显著性水平（或 Alpha 值）进行比较。 此 Alpha 值充当阈值，超过该阈值会认为观察到的结果具有统计显著性。基于观察到的 P 值与预先选择的阈值 alpha 值的比较，就可以就假设的 H0 得出结论：

-   观察到的 P 值 ≤ 预选 Alpha 级别 → 拒绝 H0
-   观察到的 P 值 > 预选的 Alpha 级别 → 不拒绝 H0

**由于观察到的 P 值是一个概率，因此总是有可能对“拒绝”或“不拒绝”原假设做出错误的判断。**

在下图中，左侧是假设的原假设 (H0) 总体分布，右侧是备择假设 (H1) 总体分布。（两者都是未知的和假设的，因为没有整体的数据，只是根据抽样的样本判断）。观察到的样本将位于这些分布的某个位置，基于此我们将得出关于我们的零假设 (H0) 的结论。

我们假设中性 H0 为真，并在观察到的数据中寻找“拒绝”或“不拒绝”H0 的证据。根据观察到的样本数据，我们计算观察到的统计量和观察到的 P 值；例如：从我们观察到的样本中获得的假设 H0 为真的概率（代入到女士品茶的故事就是计算“这位女士没有鉴别能力”时，事件奶茶被鉴别出来的概率）。

然后将该观察到的 P 值与预先确定的显著性水平（或 Alpha 值）进行比较。 此 Alpha 值充当阈值，超过该阈值会认为观察到的结果具有统计显着性。基于观察到的 P 值与预先选择的阈值 alpha 值的比较，就可以就假设的 H0 得出结论：

>-   观察到的 P 值 ≤ 预选 Alpha 级别 → 拒绝 H0
>带入到女士品茶的故事，P值≤ 0.05→ 拒绝 H0→ 这位女士有鉴别能力

>-   观察到的 P 值 > 预选的 Alpha 级别 → 不拒绝 H0
>带入到女士品茶的故事，P值> 0.05→ 不拒绝 H0→接受H1→ 这位女士没有鉴别能力


**由于观察到的 P 值是一个概率，因此总是有可能对“拒绝”或“不拒绝”原假设做出错误的判断。**

在下图中，左侧是假设的原假设 (H0) 总体分布，右侧是备择假设 (H1) 总体分布。（两者都是未知的和假设的，因为没有整体的数据，只是根据抽样的样本判断）。观察到的样本将位于这些分布的某个位置，基于此我们将得出关于我们的零假设 (H0) 的结论。

![[Pasted image 20230819160354.png]]

如果分布没有重叠，我们将永远不会在结论中观察到错误。 但是在实际情况中，它们几乎总是重叠的。Type-I和 Type-II 错误发生在这两个分布重叠的地方。

需要说明的是：对于原假设， 我们可以根据在数据中观察到的证据“拒绝它”，也可以“不拒绝它”，

- “拒绝它”“是因为观察到的数据带来了足够的重要证据，
- 不拒绝它”是因为观察到的数据没有带来足够的重要证据。

#### 假设检验：可能性
实际上，H0 只有两个选项——它可以是 True 或 False。同样，根据观察到的数据，我们只能得出两个可能的结论——我们可以拒绝 H0 或不拒绝 H0。

其实这就变成了一个二分类的问题，H0是正确的还是错误的

1.  H0 是真，但是拒绝 H0
2.  H0 是真，不拒绝 H0
3.  H0 是假，拒绝 H0
4.  H0 是假，不拒绝 H0

（2）和（3），我们正在根据观察到的数据做出正确的结论。

（1）和 （4），我们得出了错误的结论，因为观察到的数据发现与现实背道而驰。在场景 (1) 和 (4) 中，就是本文要解释的 Type-I 和 Type-II 错误。

#### Type-I 第一类错误
Type-I错误是指当原假设实际上为真时拒绝原假设的场景。根据我们观察到的数据得出结论是观察到的结果在现实中具有统计意，但是我们认为它是无意义的。

如上所述，“拒绝”或“不拒绝”零假设取决于观察到的 P 值和预先确定的 alpha 值。所以在某些情况下，真实的原假设将被拒绝，因为观察到的 P 值将小于预先选择的 Alpha 水平。这就是Type-I错误的内容： False-Positive

对于Type-I错误场景：

-   真实情况H0 对总体为真
-   观察结论拒绝H0

对于对总体正确的原假设，如果我们反复采样，可以得到原假设分布曲线，显示所有可能观察到的样本结果的概率。

当我们观察一个样本时，我们拒绝 H0，这意味着这个观察到的样本必须位于 H0 分布曲线的最右侧，与 H1 分布曲线重叠。

![[Pasted image 20230819163037.png]]

Type-I错误的区域，称为临界区域，表示在零假设分布曲线的右尾端。这是由我们预先选择的 Alpha 值决定的。

如果我们观察到的结果落在这个区域，我们将拒绝零假设（对于这些场景，观察到的 P 值<Alpha，由于观察到的 P 值<Alpha，所以我们拒绝了H0，这是错误的行为，因为在现实中H0是正确的）。由于 H0 在现实中是正确的，我们会得出False-Positive结论。

<!-- > 未曾清贫难成人，不经打击老天真。
> 自古英雄出炼狱，从来富贵入凡尘。
> 醉生梦死谁成器，拓马长枪定乾坤。
> 挥军千里山河在，立名扬威传后人。 -->


>如果你从本笔记的开头看到了这里，我真的感到很高兴，为你高兴也为我高兴。我真的很高兴有人能够看到这里，这说明这本笔记还是有价值的。


>少年辛苦终身事，莫向光阴惰寸功。加油呀！

好的，废话不多说，各位看官老爷们，我们接着讲Type-II 第二类错误

#### ype-II 第二类错误
Type-II错误是指当原假设实际上是错误的时不拒绝它的场景。根据我们观察到的数据得出的结论是，观察到的结果在实际上并不具有统计学意义，但是我们认为它是有意义的。 Type-II错误：False-Negative

这可能由于缺乏证据而发生，即我们的研究可能没有足够的统计能力来检测一定的效应大小。

犯Type-II错误的概率用 Beta 表示。统计研究的功效（Power ）定义为，Power = 1 - Beta

所以可以通过确保的研究具有较高的统计功效来减少犯Type-II错误的机会。

对于 Type-II 错误：

-   H0 对总体为假
-   观察结论不拒绝H0

对于对总体错误的零假设，如果我们反复从总体中抽取样本，我们将得到一条备择假设分布曲线，显示所有可能观察到的样本结果的概率。

由于我们正在观察一个样本，因此我们没有证据拒绝 H0。这意味着这个观察到的样本必须位于 H1 分布曲线的最左侧，与 H0 分布曲线重叠

![[Pasted image 20230819165914.png]]

Beta 是 Type-II错误率，由左侧的阴影区域表示。 右边的剩余区域代表统计功效（Power）。

如果观察到的结果落在该区域内，将无法拒绝零假设，即使我们知道 H0 对于总体而言是错误的。所以得出一个False-Negative结论。

看到这，我已经完全理解第一类错误和第二类错误了。
但是，我还要写一些废话，以使我更好地理解。
各为看官老爷们，接下来请看几个例子
#### 几个例子
1. 测试新药以帮助治疗疾病：H0新药无效、 H1新药有效

> -   Type-I 错误 → 断定新药有效，但实际上无效。
> -   Type-II 错误 → 断定新药无效，而实际上它对治愈疾病有效。

2. 刑事审判：H0无辜、 H1有罪

> -   Type-I 错误 → 断定一个人是有罪的，而实际上他是无辜的。 （即一个无辜的人被送进监狱）
> -   Type-II 错误 → 断定一个人是无辜的，但实际上他是有罪的。 （即释放有罪的人）

> 对于第二个例子，请各位读者谨记，在后文还会继续关于“疑罪从无”的话题进行讨论。
#### I 和 II 错误之间的权衡
在假设检验中通过将观察值与预先确定的截止值 (Alpha) 进行比较来“拒绝”或“不拒绝”假设。所以考虑以下使 Alpha 越来越低的情况：

**情况1**：如果 Alpha变得更严格（即 Alpha 的值越小），在拒绝 H0 方面的限制就会更严格（即拒绝H0的概率就会更小），而在不拒绝 H0 方面的限制会更小（即不拒绝H0的概率就会更大）。这会导致不太可能拒绝 H0，更有可能不拒绝 H0。

-   在真实情况中 H0 为True的情况下，拒绝 H0 的可能性较小会导致Type-I错误比以前更少。
-   在真实情况中 H0 为 False 的情况下，更可能不拒绝 H0 将导致比以更多的 Type-II 错误。

**情况2**：如果 Alpha 级别变得不那么严格（即更高的 Alpha 值），在拒绝 H0 方面的限制将更少（即拒绝H0的概率就会更大），而在不拒绝 H0 方面的限制更大（即不拒绝H0的概率就会更小）。这会导致更有可能拒绝 H0，不太可能不拒绝 H0。

-   在真实情况中 H0 为True的情况下，更有可能拒绝 H0 将导致以更多的 Type-I错误。
-   在真实情况中 H0 为 False 的情况下，不太可能不拒绝 H0 将导致Type-II错误比以前更少。

因此**显然存在二者的权衡，因为2类的错误是相关的，当一个增加另一个减少时，反之亦然**。

如果 Alpha 增加，则 Beta 减少，如果 Beta 减少，则 Alpha 将增加。

![[Pasted image 20230819204708.png]]

哪个类的错误更糟糕呢？没有简单的答案，因为都取决于被检验的假设和做出错误结论的成本评估：如果Type-I 的成本较高，则应尽量避免如果制作Type-II成本高，也应该优先考虑。

但是通常认为Type-I误会产生更多后果，因为 Type-I错误意味着违背现状（H0）的假设，并可能导致引入新的变化，现有的状况产生更坏的影响。 而 Type-II 错误意味着无法拒绝对现状 (H0) 的假设，并且可能只会导致错失机会。

#### 总结
假设检验是数据科学中一个非常重要的概念。统计的力量使我们能够对总体做出假设，观察数据样本以使我们能够拒绝或不拒绝我们的假设并得出结论。  
假设检验有两种可能的错误——Type-I错误和Type-II错误。

假设检验过程：假设一个中性 H0 → 观察数据（将观察到的 P 值与预先确定的 alpha 水平进行比较）→ 拒绝或不拒绝 H0。

Type-I错误：False-Positive

Type-II错误：False-Negative

Type-I 和 Type-II 错误相互影响相反。减少一个总是增加另一个，反之亦然。一般来说，Type-I 错误被认为Type-II 错误更重要。但是，也要取决于被检验的假设以及围绕我们的假设得出这些错误结论的成本。

以上内容绝大部分都来自知乎作者Deepak Chopra

我在这里对Deepak Chopra表示诚挚的感谢！

### 复习一下两类错误
对于原假设提出的命题，我们需要作出判断，这种判断可以用”原假设正确“或”原假设错误“来表述。当然，这是依据样本提供的信息进行判断的，也就是由部分推断总体。因而判断有可能正确，也有可能不正确，也就是说，我们面临着犯错误的可能。所犯的错误有两种类型，
- 第I类错误是原假设H0为真却被我们拒绝了，犯这种错误的概率用$ɑ$表示，所以也称$ɑ$错误或弃真错误；
- 第II 类错误是原假设为伪我们却没有拒绝，犯这种错误的概率用$β$表示，所以也称$β$错误或取伪错误。

那么，在新生儿的例子中，$ɑ$错误和$β$错误分别意味着什么呢？

- $ɑ$错误：原假设$H_{0}:µ=3190克$是正确的，但我们做出了错误的判断，认为$H_{0}:µ≠3190克$，即在假设检验中拒绝了本来是正确的原假设，这是犯了弃真错误；

- $β$错误：原假设$H_{0}:µ=3190克$是错误的，但我们认为原假设$H_{0}:µ=3190克$是成立的，即在假设检验中没有拒绝本来是错误的原假设，这是犯了取伪错误。

由此看出：
- 当原假设$H_{0}$为真，我们却将其拒绝，犯这种错误的概率用$ɑ$表示，那么，当$H_{0}$为真，我们没有拒绝$H_{0}$，则表明做出了正确的决策，其概率自然为$1-ɑ$
- 当原假设为伪，我们却没有拒绝$H_{0}$，犯这种错误的概率用$β$表示，那么，当$H_{0}$为伪，我们拒绝$H_{0}$，这是正确的决策，其概率为$1-β$


|项目|没有拒绝$H_{0}$|拒绝$H_{0}$|
|---|---|---|
|$H_{0}$为真|$1-ɑ$(正确决策)|$ɑ$（弃真错误）|
|$H_{0}$|$β$（取伪错误）|$1-β$(正确决策)|

自然，人们希望犯这两类错误的概率越小越好。但对于一定量的样本量n，不能同时做到犯这两类错误的概率都很小。如果减少$ɑ$错误，就会增大犯$β$错误的机会。这就像在区间估计中，想要增大估计的可靠性，就会使区间变宽而降低精度；想要提高精度，就要求估计区间变得很窄，而这样，估计的可靠性就会大打折扣。

当然，使$ɑ$和$β$同时变小的办法也有，就是增大样本量。但样本量不可能没有限制，否则就会使抽样调查失去意义。因此，在假设检验中，就有一个对两类错误进行控制的问题。

一般来说，哪类错误带来的后果更严重，危害更大，在假设检验中就应当把哪类错误作为首要的控制目标。但在假设检验中，大家都在执行这样一个原则，即首先控制犯$ɑ$的错误。

这样做的原因主要有两点：
1. 大家都遵循讨一个统一的原则，论问题就比较方便。
2. 更主要的原因在于，从实用的观点看，原假设是什么常常是明确的，而备择假设是什么则常常是模糊的。

在前文所举的新生儿体重的例子中，原假设$H_{0}:µ=3190克$的数量标准是十分清楚的，而备择假设$H_{1}:µ≠3190克$的数量标准则比较模糊。我们不知道$µ>3190$克还是$µ<3190$，而且大的程度也不清楚。

显然，对于一个含义清楚的假设和一个含义模糊的假设，我们更愿意接受前者。

正是在这个背景下，我们就更关心如果$H_{0}$为真，而我们却把它拒绝了，犯这种错误的可能性有多大，而这正是$ɑ$错误所表现出来的内容。




$α$和 $β$ 的关系——$α$ 和 $β$ 的关系就像翘翘板，$α$ 小 $β$ 就大，$α$ 大 $β$ 就小。所以两类错误不可能同时发生（第一类只在 $H_{0}$为真时发生，第而类只在$H_{0}$为假时发生）。
影响 $β$ 的因素：
> * 总体参数的真值。
> * 显著性水平 $α$（当 $α$ 减少时增大）。
> * 总体标准差 $σ$（当 $σ$ 增大时增大）。
> * 样本容量 n（当 n 减少时增大）。
#### 假设检验的流程
假设检验的一般流程如下：

首先提出原假设和备择假设。在前面新生儿的例子中，原假设和备择假设分别为：

$$H_{0}:µ=3190克 ; H_{1}:µ≠3190克$$

接下来，需要确定适当的检验统计量，并计算其数值。在参数的假设检验中，如同在参数估计中一样，要借助样本统计量进行统计推断，这个统计量称为检验统计量。选择哪个统计量作为检验统计量需要考虑一些因素，例如，进行检验的样本量是多还是少，总体的标准差$σ$已知还是未知，等等。这些因素与参数估计中确定统计量所考虑的因素相同。

计算统计量类似于分数转化过程，如同把一般得分转化为标准得分。在新生儿的例子中，假定总体$σ$已知，且样本量大（经验说法是当n≧30时，称为大样本），采用$z$ 统计量，计算公式为：
$$z=\dfrac{\bar{x}-\mu_{0}}{{σ}/{\sqrt{n}}}$$
### 统计量与拒绝域
==我懒得打字了--^^--,诸君看图吧==

![[Pasted image 20230825112446.png]]
![[Pasted image 20230825112502.png]]
![[Pasted image 20230825112517.png]]

### 利用P值进行决策
前面进行检验的程序是根据检验统计量落入的区域做出是否拒绝原假设的决策。确定$α$以后，拒绝域的位置也就相应确定了，其好处是进行决策的界限清晰，但缺陷是进行决策面临的风险是笼统的。在新生儿的例子中，如果我们知道新生儿的体重标准差为80克，即$σ=80$，那么根据分布原理，当$µ_{0}=3190$,$σ=80$,$α=0.05$，$n=100$ 时，根据公式 $z=\dfrac{\bar{x}-\mu_{0}}{{σ}/{\sqrt{n}}}$ ，算得$z=2.5>1.96$。由于$z=2.5$ 落入拒绝域，我们拒绝原假设，并知道犯弃真错误的概率（面临的风险）为0.05（最少为0.05）；如果$z=2.0$ ，同样落入拒绝域，我们拒绝原假设面临犯弃真错误的概率（的风险）也是0.05（最少为0.05） 。0.05是一个通用风险概率，这是用域表示的缺陷，但根据不同的样本结果进行决策，面临的风险事实上是有差别的，为了精确地反映决策的风险度，可以来利用P值进行决策。

为了解什么是P值，让我们回到新生儿的例子。根据随机抽样测得1990年的样本均值$\bar{x}=3210克$，与1989年的总体均值3190克相差20克，20克的差异究竟是大还是小？换句话说，如果原假设成立，即1990年新生儿体重的总体均值与1989年新生儿体重的总体均值相同，那么随机抽取出n=100的样本，其均值大于3210克的概率有多大呢？我们把这个概率称为P值，也就是当原假设为真时样本观察结果或更极端结果出现的概率。如果P值很小，说明这种情况发生的概率很小，如果这种情况出现了，根据小概率原理，我们就有理由拒绝原假设。P值越小，拒绝原假设的理由就越充分。

P值是通过计算得到的，P值的大小取决于三个因素：
- 一是样本数据与原假设之间的差异，在新生儿体重的例子里这个差异是20克
- 二是样本量，这里n=100
- 三是被假设参数的总体分布。

在这个新生儿的例子中计算出的P=0.01242，这就是说，如果原假设成立，样本均值等于和大于3210克的概率只有0.01242，这是很小的，由此我们可以拒绝原假设，得到与前面$z$值检验相同的结论。

手工计算P值比较复杂，但使用计算机计算P值就很方便。如何使用计算机计算，后面有专门的介绍。

P值的长处是它反映了观察到的实际数据与原假设之间不一致的概率值，与传统的拒绝域范围相比，P值是一个具体的值，这样就提供了更多的信息。如果事先确定了显著性水平，如$α=0.05$，则在双侧检验中，P>0.025(α/2=0.025)不能拒绝原假设；反之，P<0.025则拒绝原假设。在单侧检验中，P>0.05不能拒绝原假设，P<0.05则拒绝原假设.当然，也可以直接使用P值进行决策，这时P值本身就代表了显著性水平。我们也可以使用P值，按照所需要的显著性水平进行判断和决策，具体做法就是将P值和需要的显著性水平进行比较。

### 利用P值进行决策的精简理解
如何利用假设检验解决实际问题？很重要的一个应用是在决策上。就如标题说的，利用 p 值进行决策。那么什么是 p 值?p 值 (p-value)：在一个假设检验问题中，拒绝原假设的最小显著性水平。

- 在原假设为真的条件下，检验统计量的观察值大于或等于其计算值的概率 (双侧检验为分布中检验统计量两侧面积的总和; 单侧检验为分布中检验统计量相应单侧面积）。
- 反映实际观测到的数据与原假设 H0之间的一致程度。
- 被称为观察到的（或实测的）显著性水平。
- 决策规则：若 p 值 <α，拒绝 H0。

-  p 值法步骤（以大样本均值为例），将样本统计量转换成检验统计量 z。
- - 计算 p 值：Z 为标准正态分布随机变量（p 值 =(|Z| ≥ z)(双侧),p 值 =(Z ≤ z)(左
侧),p 值 =(Z ≥ z)(右侧)）
- - 比较 p 值和 α：如果 α ≤ p 值，拒绝 H0; 如果 α <p 值，不能拒绝 H0。

-  假设检验结论的表述

假设检验的目的就在于试图找到拒绝原假设的证据，而不在于证明什么是正确的。

- 拒绝原假设时结论是清楚的。

- 当不拒绝原假设时——并未给出明确的结论，不能说原假设是正确的，也不能说它不是正确的。但也未说它不是 10。我们只能说样本提供的证据还不足以推翻原假设。

 - 假设检验步骤的总结
- - 陈述原假设和备择假设。
- - 从所研究的总体中抽出一个随机样本。
- - 确定一个适当的检验统计量，并利用样本数据算出其具体数值。
- -  确定一个适当的显著性水平，并计算出其临界值，指定拒绝域。
- - 将统计量的值与临界值进行比较，作出决策——统计量的值落在拒绝域，拒绝 H0，否则不拒绝 H0，也可以直接利用 p 值作出决策。

### 单侧检验
> 还是绕不过这个内容，本来我想偷一下懒，略去这一部分的内容，但是后面的内容需要引用单侧检验中提到的例子，只能写一下咯。

> 先看一个订购灯泡💡的例子

某批发商欲从厂家购进一批灯泡，根据合同，灯泡的使用寿命平均不得低于1000小时。
已知灯泡使用寿命服从正态分布，标准差为200小时 。在总体中随机抽取100个灯泡得知样本均值为960小时，问批发商是否应该购买这批灯泡？

> 解

这是一个单侧检验问题。显然，如果灯泡的使用寿命超过了1000小时，批发商是欢迎的，因为他用既定的价格（灯泡使用寿命为1000小时的价格）购进了更高质量的产品。因此，如果样本均值超过1000小时，他会购进这批灯泡。问题在于样本均值为960小时他是否应当购进。因为即便总体均值为1000小时，由于抽样的随机性，样本均值略小于1000小时的情况也会经常出现（换言之，现在样本均值为960小时，可能是抽样误差造成的结果，但这是一种可能，并不绝对，也就是说，也可能不是抽样误差造成的结果，而是真实的总体本就为960小时）。在这种情况下，批发商更为关注可以容忍的下限，即灯泡寿命低于什么水平时拒绝（即需要找到由于抽样误差的影响下，如果总体均值真的为1000小时时，样本均值的最小值是多少）。于是检验形式为：

$$H_{0}:µ≧1000小时 ; H_{1}:µ<1000小时 $$

> 再看一个食品重量的例子

 某种

## 7.4一个总体参数的检验
|检验统计量|用途|
|---|---|
|$z$统计量|均值和比例的检验|
|$t$统计量|均值和比例的检验|
|$χ^{2}$统计量|方差的检验|

|用途|检验统计量|
|---|---|
|均值和比例的检验|$z$统计量<br>$z$统计量|
|方差的检验|$χ^{2}$统计量|



### 检验统计量的确定
|样本量|分布|检验统计量|总体标准差$σ$|检验统计量|
|---|---|---|---|---|
|  样本量大|正态分布|$z$统计量|已知|$z=\dfrac{\bar{x}-\mu_{0}}{{σ}/{\sqrt{n}}}$|
|  样本量大|正态分布|$z$统计量|未知|$z=\dfrac{\bar{x}-\mu_{0}}{{s}/{\sqrt{n}}}$|
|  样本量大|非正态分布|$z$统计量|已知|$z=\dfrac{\bar{x}-\mu_{0}}{{σ}/{\sqrt{n}}}$|
|  样本量大|非正态分布|$z$统计量|未知|$z=\dfrac{\bar{x}-\mu_{0}}{{s}/{\sqrt{n}}}$|

|样本量|总体标准差$σ$|检验统计量|
|---|---|---|
|  样本量小|已知|$z=\dfrac{\bar{x}-\mu_{0}}{{σ}/{\sqrt{n}}}$|
|  样本量小|未知|$t=\dfrac{\bar{x}-\mu_{0}}{{s}/{\sqrt{n}}}$|



![[检验统计量的确定.svg]]

**综上所述，只有在样本量小且总体标准差$σ$未知的情况下采取$t$检验**


根据假设的不同内容和进行检验的不同条件，需要采用不同的检验统计量，在一个总体参数的检验中，用到的检验统计量主要有三个：$z$统计量，$t$统计量,$\chi^{2}$统计量。$z$统计量和$t$统计量常常用于均值和比例的检验，$\chi^{2}$统计量则用于方差的检验。选择什么统计量进行检验需要考虑一些因素，这些因素主要有样本量n的大小以及总体标准差$σ$是否已知。
#### 样本量
样本量大小是选择检验统计量的一个重要因素。

>在样本量大的条件下，
>- 如果总体为正态分布，则样本统计量服从正态分布；
>- 如果总体为非正态分布，则样本统计量渐进服从正态分布。
>
>在这些条件下，我们都可以把统计量视为正态分布，这时可以使用$z$统计量（$z$分布）。$z$统计量的计算为$z=\dfrac{\bar{x}-\mu_{0}}{{σ}/{\sqrt{n}}}$，即在总体标准差$σ$已知时有
>**$$z=\dfrac{\bar{x}-\mu_{0}}{{σ}/{\sqrt{n}}}$$** 

>实践中，当总体标准差$σ$未知时，可以用样本标准差$s$代替，上式可以写为：
>**$$z=\dfrac{\bar{x}-\mu_{0}}{{s}/{\sqrt{n}}}$$** 

> 样本量较小时，情况有些复杂。在假设总体为正态分布的前提下，要看我们是否掌握总体标准差$σ$的信息。下面进行讨论。

#### 总体标准差$σ$是否已知
>在样本量较小的情况下，
>- 如果总体标准差已知，则样本统计量服从正态分布，这时可以采用$z$统计量。
>- 如果总体标准差未知，进行检验所依赖的信息有所减少，这时只能使用样本标准差，样本统计量服从$t$分布，应采用$t$统计量。

与正态分布相比，$t$分布更为扁平，在相同概率条件下，$t$分布的临界点向两边更为扩展，临界点与中心距离更远，这意味着推断精度下降，这是总体标准差$σ$未知所要付出的代价。

**$t$统计量的计算公式为：
$$t=\dfrac{\bar{x}-\mu_{0}}{{s}/{\sqrt{n}}}$$ 
$t$统计量的自由度为$n-1$**

由上述讨论看出，样本量的大小是选择检验统计量时的一个很重要的考虑因素，在大样本情况下一般可以使用$z$统计量。

>接下来给出了经典一问，样本量n为多大才算大样本？

不的同人可能给出不同的答案，同时也与检验的对象有关。

仅就分布而言，当n较小时，$t$分布与$z$分布的差异是明显的，随着n的增大，$t$分布向$z$分布逼近，它们之间的差异逐渐缩小，$t$分布以$z$分布为极限。

>接下来，是回答经典一问的经典一答

- 当样本量n>30时，$t$分布与$z$分布非常接近，具备了用$z$分布取代$t$分布的理由。
- 所以可以说，
- - 当n<30时，如果$σ$未知，则必须使用$t$统计量
- - 在n>30时，选择$t$统计量还是$z$统计量可以根据使用者的偏好

### 总体均值的检验
#### 样本量大
> 先看一个机床加工的例题

某机床厂加工一种零件，根据经验知道，该厂加工零件的椭圆度渐进服从正态分布，其总体均值为0.081mm，今另换一种新机床进行加工，取200个零件进行检验，得到椭圆度均值为0.076mm，样本标准差为0.025mm，问新机床加工零件的椭圆度总体均值与以前有无明显差别？

解：

在这个例题中，我们所关心的是新机床加工零件的椭圆度总体均值与老机床加工零件的椭圆度是否有所不同，于是可以假设：

$$H_{0}:µ=0.081mm(没有显著差别) ; H_{1}:µ≠0.081mm(有显著差别)$$

这是一个双侧检验的问题，所以只要$µ>µ_{0}$或者$µ<µ_{0}$二者中有一个成立，就可以拒绝原假设。

由题意可知，$µ_{0}=0.081mm，s=0.025mm,\bar{x}=0.076mm$。因为n>30,故选用$z$统计量。

$$z=\dfrac{\bar{x}-\mu_{0}}{{s}/{\sqrt{n}}}=\dfrac{0.076-0.081}{{0.025}/{\sqrt{200}}}=-2.83$$ 

**通常把$α$称为显著性水平。显著性水平是一个统计专有名词，在假设检验中，它的含义是当原假设正确时却被拒绝的概率或风险，其实这就是前面假设检验中犯弃真错误的概率，它是人们根据经验的要求确定的。** 通常$α=0.05$或$α=0.01$，这表明，当做出接受原假设的决定时，其正确的概率为95%或99%。此例题中不妨取$α=0.05$，查表可以得到临界值：
$$z_{α/2}=±1.96$$
$z$的下标$α/2$表示双侧检验。

因为$|z|>|z_{α/2}|$，根据决策准则，拒绝$H_{0}$，可以认为新老机床加工零件椭圆度的均值有显著差别。

用Excel中的统计函数功能计算P值的操作步骤 #计算P值
1. 进入Excel表格界面，选择插入**下拉菜单**
2. 选择**函数**，或者直接点击功能栏中的**fx**
3. 在函数类别选择中选择“**统计**”，然后，在函数名的菜单中选择字符“**NRM.S.DIST**”，然后点击**确定**
4. 输入$z$的绝对值，Cumulative逻辑值输入1，得到一个结果记为$δ$
5.  双侧检验，计算P=2*（1-δ），得到P值；单侧检验，计算P=1-δ

> 本例中 $z$的绝对值为2.83，计算得到的函数值δ为0.997672537，这意味着在标准正态分布条件下， $z$值2.83左边的面积为0.997672537
> $z=2.83$右边和$z=-2.83$左边的面积是一样的。
> 在我们的例子中是双侧检验，故最后的P值为：
> P=2*（1-0.997672537）=0.004655
> P值远小于$α$，故拒绝$H_{0}$，得到与前面相同的结论。


让我们回到前面订购灯泡💡的例子

某批发商欲从厂家购进一批灯泡，根据合同，灯泡的使用寿命平均不得低于1000小时。  
已知灯泡使用寿命服从正态分布，标准差为200小时 。在总体中随机抽取100个灯泡得知样本均值为960小时，问批发商是否应该购买这批灯泡？

在该例中，已知$µ_{0}=1000,\bar{x}=960,σ=200,n=100$，并假设显著性水平$α=0.05$。

易知拒绝域在左侧，所以临界值为负，即$z_{α}=-1.645$，$z$的下标$α$表示单侧检验。

进行检验的过程为：

$$H_{0}:µ≧1000小时 ; H_{1}:µ<1000小时 $$
$$z=\dfrac{\bar{x}-\mu_{0}}{{s}/{\sqrt{n}}}=\dfrac{960-1000}{{200}/{\sqrt{100}}}=-2$$ 

由于$|z|>|z_{α}|$，即$z$的值位于拒绝域（熟悉的配方，有木有？），即这批灯泡的使用寿命低于1000小时，批发商不应该购买。

> **啊啊啊啊！为什么？为什么在我的旁边坐了一对情侣啊！虐狗啊！**==而我只能狠狠地敲我的键盘！！！！==
> 我已经敲了一万七千九百六十个词了！加油！路漫漫其修远兮！

如果使用P值检验，按照前述方法，即：

用Excel中的统计函数功能计算P值的操作步骤 #计算P值
1. 进入Excel表格界面，选择插入**下拉菜单**
2. 选择**函数**，或者直接点击功能栏中的**fx**
3. 在函数类别选择中选择“**统计**”，然后，在函数名的菜单中选择字符“**NRM.S.DIST**”，然后点击**确定**
4. 输入$z$的绝对值，Cumulative逻辑值输入==2==，得到一个结果记为$δ$，此时$δ=0.97725$
5.  由于此时为单侧检验，故P=1-δ=1-0.9772=0.02275

在单侧检验中，用P值直接与$α$比较，由于P（0.02275）<α(0.05)，故拒绝$H_{0}$（又是熟悉的配方）。

这进一步说明，检验的结论是建立在概率的基础上的。不能拒绝$H_{0}$并不一定保证$H_{0}$为真，只是规定的显著性水平上不能拒绝原假设。上面的例子说明能在0.95的置信水平上拒绝原假设，却不能在0.98的置信水平上拒绝原假设。

<!-- > 年少总会披上岁月的沧桑，
> 忍，才是历练；
> 累，才是生活；
> 变，才是命运；
> 做，才能拥有。
> 别怕困难险阻，少年志在四方。
> 十年运道龙困井，一朝得势入青云！ -->


#### 样本量小，$σ$已知，正态总体

<!-- > 贪财的风生水起，求爱的一事无成。
> 这个世界很现实，夏竹不爱钱，但感动她的瞬间都是钱。
> 香烟不散人间苦，唯有碎银解千愁！ -->

#### 样本量小，$σ$未知，正态总体


### 总体比例的检验

### 总体方差的检验
在假设检验中，有时不仅需要检验正态总体的均值、比例，而且需要检验正态总体的方差。例如，在产品质量检验中，质量标准是不同类型指标反映的，
- 有些属于均值类型，如尺寸、质量、抗拉强度等
- 有些属于比例类型，如产品合格率、废品率等
- 有些属于方差类型，如尺寸的方差、重量的方差、抗拉强度的方差等
这里，方差反映产品的稳定性。
- 方差大，说明产品的性能不稳定，波动大。
凡与均值有关的指标，通常也与方差有关，方差从另一个方面说明研究对象的状况。

在经济生活方面，对方差关注的例子比比皆是。例如，居民的平均收入说明了收入达到的一般水平，是衡量经济发展的一个重要指标，而收入的方差则反映了收入分配的差异情况，可以用来评价收入的合理性。

在投资方面，收益率的方差是评价投资风险的重要依据。

对方差进行检验的程序，与均值检验、比例检验是一样的，它们之间的主要区别是所使用的检验统计量不同。方差检验所使用的是$χ^{2}$统计量。对一个方差为$σ^{2}$的正态总体反复抽样，计算每一个样本方差$s^{2}$，**则$s^{2}$的分布大体如下图所示：**



由于$s^{2}=\dfrac{\sum_{}^{}(x_{i}-\bar{x})^{2}}{n-1}$，故$\sum_{}^{}(x_{i}-\bar{x})^{2}=(n-1)s^{2}$

可以证明，$\sum_{}^{}(x_{i}-\bar{x})^{2}$除以总体方差$σ^{2}$将服从$χ^{2}$分布，即
$χ^{2}=\dfrac{(n-1)s^{2}}{σ^{2}}$

> 如果你对这句话有疑问，$\sum_{}^{}(x_{i}-\bar{x})^{2}$除以总体方差$σ^{2}$将服从$χ^{2}$分布，也就是为什么$\dfrac{(n-1)s^{2}}{σ^{2}}$服从$χ^{2}$分布？

> 下面给你一个提示：
> $χ^{2}$分布（Chi-square distribution）是由赫尔默特（Helmert）和皮尔逊分别于1875年和1990年推导出来的。
> 定义如下：
> 设随机变量$X_{1}、X_{2}、X_{3}、X_{4}....X_{n}$相互独立，且$X_{i}(i=1,2,3,4,...,n)$服从标准正态分布$N(0,1)$，则它们的平方和$\sum_{i=1}^{n}X_{i}^{2}$服从自由度为n的$χ^{2}$分布。

聪明的你想必一定明白了吧。

易知，$χ^{2}$分布以正态分布为极限，在正常情况下$χ^{2}$分布是偏态分布，因此用$χ^{2}$统计量进行检验通常采用单侧检验，临界点在$χ^{2}$分布右侧斜尾方向。
## 7.5两个总体参数的检验
在许多情况下人们需要比较两个总体的参数，看它们是否由显著差别。例如，在相同年龄组中，高学历和低学历的职工收入是否有明显差异；同一种教学反复，在不同的年级或不同内容的课程中是否会产生不同的效果；等等。对此，可以利用两个总体参数的检验寻找答案。

### 检验统计量的确定

![[检验统计量的确定2.svg|950]]


由上图可知，除了方差比检验选择F统计量，均值之差检验时$σ^{2}$未知且样本量小时选择$t$统计量，其余情况皆选择$z$统计量。


两个总体参数检验的主要内容有：
- 两个总体均值之差的检验
- 两个总体比例之差的检验
- 两个总体方差比的检验

与一个总体参数检验类似，两个总体参数的检验也涉及检验统计量的选择问题。
选择什么检验统计量取决于被检验参数的抽样分布，而抽样分布与样本量大小和总体方差$σ^{2}$是否已知都有关系。

#### 两个总体均值之差的检验
> **两个总体均值之差的检验中可能出现的情况有：**

> 1. 总体方差$σ^{2}_{1}$，$σ^{2}_{2}$已知或未知

- 在$σ^{2}_{1}$，$σ^{2}_{2}$已知的条件下，由抽样分布理论可知，样本量服从$z$分布
- 在$σ^{2}_{1}$，$σ^{2}_{2}$未知的条件下，样本统计量服从$t$分布

故：
- 当$σ^{2}_{1}$，$σ^{2}_{2}$已知时，可以使用$z$检验
-  当$σ^{2}_{1}$，$σ^{2}_{2}$未知时，可以使用$t$检验

> 2. n($n_{1}$,$n_{2}$)较大或较小

- 当样本量$n_{1}$,$n_{2}$都较大时，如果总体方差$σ^{2}_{1}$和$σ^{2}_{2}$未知，可以用样本方差$s^{2}_{1}$，$s^{2}_{2}$，替代，这时，样本统计量近似服从$z$分布，采用$z$作为检验统计量是可行的。
- 当样本量$n_{1}$或$n_{2}$不大时，如果$σ^{2}_{1}$和$σ^{2}_{2}$未知，就应该采用$t$作为检验统计量。
#### 两个总体比例之差的检验
> 两个总体比例之差的检验中，一般采用$z$统计量
> > 其理由与总体比例的检验中采用$z$统计量的理由相同
> > 即：
> > 如果一个事件只有两种结果，称为二项分布。可以证明，在样本量大的情况下，若np>5,nq>5，则 可以把二项分布问题转化为正态分布问题近似地去求解。
> > 这就是说，在总体比例检验中，通常采用$z$统计量。一般而言，在有关比例问题的调查中往往使用大样本量，因为小样本量的结果是极不稳定的。
> > >例如：
> > >随机抽取10个人，如果支持者有4人，支持率为40%；如果支持者有5人，支持率则为50%，样本中一个人的态度差异导致调查结果相差10个百分点，这种不稳定性是我们不愿意看到的
> > 
> > 所以在有关比例问题的调查中往往使用大样本量，因为小样本量的结果是极不稳定的。

#### 两个总体方差比的检验
两个总体方差比的检验中，此时样本统计量（还记得样本统计量的概念吗？样本统计量是指根据研究目的不同，构造的样本函数，这是人为地生生造出来的，这里的样本统计量为$\dfrac{s^{2}_{1}/σ^{2}_{1}}{s^{2}_{2}/σ^{2}_{2}}$）服从自由度为$n_{1}-1$和$n_{2}-1$的$F$分布，在这种情况下使用$F$作为检验统计量。

> 如果你对这句话有疑问，$\dfrac{s^{2}_{1}/σ^{2}_{1}}{s^{2}_{2}/σ^{2}_{2}}$服从自由度为$n_{1}-1$和$n_{2}-1$的$F$分布，那么你需要先理解
> $\sum_{}^{}(x_{i}-\bar{x})^{2}$除以总体方差$σ^{2}$将服从$χ^{2}$分布，也就是$\dfrac{(n-1)s^{2}}{σ^{2}}$服从$χ^{2}$分布

> 下面给你两个提示：
> $χ^{2}$分布（Chi-square distribution）是由赫尔默特（Helmert）和皮尔逊分别于1875年和1990年推导出来的。
>  $χ^{2}$分布定义如下：
> 设随机变量$X_{1}、X_{2}、X_{3}、X_{4}....X_{n}$相互独立，且$X_{i}(i=1,2,3,4,...,n)$服从标准正态分布$N(0,1)$，则它们的平方和$\sum_{i=1}^{n}X_{i}^{2}$服从自由度为n的$χ^{2}$分布。
> 
> $F$分布（F distribution）是统计学家Fisher首先提出来的。$F$分布有着广泛的应用，在方差分析、回归方程的显著性检验中有着重要的地位。
> $F$分布的定义如下：
> 设随机变量Y和Z互相独立，且Y和Z分别服从自由度为m和n的 $χ^{2}$分布，随机变量X有如下表达式：
> $$X=\dfrac{Y/m}{Z/n}=\dfrac{nY}{mZ}$$
> 则称X服从第一自由度为m，第二自由度为n的F分布，记为$F(m,n)$，简记为$X~F(m,n)$。

>将上面的$F$分布的定义换一种表达方式则为：
设随机变量Y和Z互相独立，且$X_{1}$和$X_{2}$分别服从自由度为$n_{1}$和$n_{2}$的 $χ^{2}$分布，随机变量X有如下表达式：
> $$X=\dfrac{X_{1}/n_{1}}{X_{2}/n_{2}}=\dfrac{n_{2}X_{1}}{n_{1}X_{2}}$$
> 则称X服从第一自由度为$n_{1}$，第二自由度为$n_{2}$的F分布，记为$F(n_{1},n_{2})$，简记为$X ~ F(n_{1},n_{2})$。

> 由$\dfrac{(n-1)s^{2}}{σ^{2}}$服从$χ^{2}$分布可知，$\dfrac{(n_{1}-1)s^{2}_{1}}{σ^{2}_{1}}$和$\dfrac{(n_{2}-1)s^{2}_{2}}{σ^{2}_{2}}$也服从$χ^{2}$分布，不妨将其记为$X_{1}$和$X_{2}$，那么，$X=\dfrac{X_{1}/n_{1}}{X_{2}/n_{2}}=\dfrac{n_{2}X_{1}}{n_{1}X_{2}}=\dfrac{n_{2}(n_{1}-1)X_{1}}{n_{1}(n_{2}-1)X_{2}}≈\dfrac{X_{1}}{X_{2}}=\dfrac{{s^{2}_{1}}/{σ^{2}_{1}}}{{s^{2}_{2}}/{σ^{2}_{2}}}$服从自由度为$n_{1}-1$和$n_{2}-1$的$F$分布，
> >事实上，在现实中，$n_{1}$和$n_{2}$的值常常相等，比如，我们在实验组中取50个样本，在对照组中取50个样本，那么$n_{1}$和$n_{2}$的值就是相等的，上面公式中的约等于号则改为等于号。

#### 两个总体比例之差的检验的具体讨论





## 两个总体参数的检验
### 独立大样本两总体均值之差检验
#### 假定条件：
- 两个样本是独立的随机样本。
-  大样本 (n1≥ 30 和 n2≥ 30)。
#### 检验统计量：
##### $σ^{2}_{1}$, $σ^{2}_{2}$已知：

##### $σ^{2}_{1}$, $σ^{2}_{2}$未知：




### 正态总体独立小样本均值之差检验（$σ^{2}_{1}$, $σ^{2}_{2}$已知）
#### 假定条件：
-  两个独立的小样本。
- 两个总体都是正态分布。
- $σ^{2}_{1}$, $σ^{2}_{2}$已知


#### 检验统计量：




### 正态总体独立小样本均值之差检验 ($σ^{2}_{1}$, $σ^{2}_{2}$未知但 $σ^{2}_{1}= σ^{2}_{2}$)
#### 假定条件：
- 两个独立的小样本。
- 两个总体都是正态分布。
- $σ^{2}_{1}$, $σ^{2}_{2}$未知但相等，即 $σ^{2}_{1}= σ^{2}_{2}$


#### 检验统计量：




### 两个总体均值之差的检验 ($σ^{2}_{1}$, $σ^{2}_{2}$未知且不相等 $σ^{2}_{1̸}= σ^{2}_{2}$)

#### 假定条件：
- 两个总体都是正态分布。
- $σ^{2}_{1}$, $σ^{2}_{2}$未知且不相等 $σ^{2}_{1̸}= σ^{2}_{2}$


#### 检验统计量：



### 两个总体均值之差的检验 ($σ^{2}_{1}$, $σ^{2}_{2}$未知且不相等 $σ^{2}1̸= σ^{2}_{2}$)

#### 假定条件：


#### 检验统计量：



### 两个总体均值之差的检验 (匹配样本)

#### 假定条件：


#### 检验统计量：



### 两个总体比例之差的检验

#### 假定条件：


#### 检验统计量：



### 两个总体方差比的检验 (F 检验)

#### 假定条件：


#### 检验统计量：























