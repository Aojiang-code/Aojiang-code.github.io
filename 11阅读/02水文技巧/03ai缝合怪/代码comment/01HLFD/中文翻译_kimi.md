这篇文章是关于一种名为HLNet的图像恢复和增强方法，该方法基于高频和低频的分解。以下是文章的翻译摘要：
**标题：**基于高低频分解的括号图像恢复和增强
**作者：**陈庚庚1† 戴克新2† 杨康振2 胡桃1,2 陈相宇3 杨永庆4 董伟1 吴鹏2 张燕宁2 * 1西安建筑科技大学 2西北工业大学 3澳门大学 4中国科学院西安光学精密机械研究所
摘要： 在现实世界的场景中，由于一系列图像退化，获取高质量、清晰的内容照片是具有挑战性的。虽然在合成高质量图像方面取得了显著进展，但以前的图像恢复和增强方法常常忽略了不同退化的特征。他们应用相同的结构来解决各种类型的退化，导致不理想的恢复结果。受高频/低频信息适用于不同退化的概念启发，我们引入了HLNet，一种基于高低频分解的括号图像恢复和增强方法。具体来说，我们使用了两个模块进行特征提取：共享权重模块和非共享权重模块。在共享权重模块中，我们使用SCConv从不同的退化中提取公共特征。在非共享权重模块中，我们引入了高低频分解块（HLFDB），它采用不同的方法处理高频和低频信息，使模型能够更有效地处理不同的退化。与其他网络相比，我们的方法考虑了不同退化的特征，从而实现了更高质量的图像恢复。
1. 引言 在现实世界的场景中，各种图像退化的存在使得捕捉高质量、清晰的内容照片变得具有挑战性。低曝光会导致噪声增加，尤其是在黑暗区域，可能会导致细节丢失。同样，高曝光图像中的明亮区域可能会因曝光过度而丢失细节。尽管提出了许多单图像恢复方法，例如去噪[1, 5, 17, 28, 51, 53]、去模糊[7, 32, 36, 40, 51]、超分辨率[10, 26, 29]和高动态范围图像重建[15, 25]，但它们的表现受到单张图像中信息不足的限制。
由于单张图像恢复和增强的局限性，例如信息不足和曝光时间的影响，越来越多的方法正在使用多帧进行恢复。突发图像恢复方法[13, 14]使用多张连续的帧进行超分辨率和去噪，而多曝光HDR成像[22, 30, 37, 38, 45–50]从具有不同曝光的LDR图像重建HDR图像。然而，这些方法只考虑了单一退化场景，忽略了其他退化情况。最近，TMRNet[55]在统一图像恢复和增强任务的框架设计中提出了一个可行的解决方案。它采用多曝光图像作为输入，并逐步将非参考帧与参考帧混合。尽管他们考虑了不同退化的共性和特殊性问题，使用共享权重模块和非共享权重模块，但在处理不同退化的特征时使用了相同的结构，忽略了不同退化的一些特征。为了解决上述问题，我们提出了HLNet，它考虑了各种退化的特征。与TMRNet类似，我们的模型使用共享权重模块和非共享权重模块来提取特征。在共享权重模块中，我们引入了空间通道增强块（SCEB），它使用SCConv同时考虑空间和通道信息，有效地提取不同退化的公共特征。在非共享权重模块中，不同的退化适合用不同的频率信息进行处理。例如，去噪和去模糊通常需要增强高频信息以恢复图像细节和纹理，超分辨率需要在恢复低频信息的基础上添加高频细节，而HDR重建需要从不同帧中捕获低频信息。因此，我们提出了高低频分解块（HLFDB）。具体来说，在HLFDB中，高频特征可以捕获详细的局部信息，使它们更适合去噪和去模糊增强。因此，我们通过多个卷积块提取局部特征图，并通过密集连接机制在多帧之间增强高频细节。低频特征可以捕获图像中的大部分结构信息和全局特征，使它们更适合超分辨率和多曝光HDR重建任务。因此，我们采用多级通道自注意力来学习长期依赖关系，并使用基于小波变换的尺度特征融合方法，以避免下采样过程中结构信息的丢失。因此，我们的模型在图像恢复和增强方面充分考虑了不同退化的特征，实现了更好的性能。
主要贡献总结如下：
我们提出了SCEB，它使用SCConv同时考虑空间和通道信息，有效地提取不同退化的公共特征。
我们提出了HLFDB，它充分考虑了不同退化需要不同的高低频信息，有效地解决了同时恢复这些退化的挑战。
HLNet在指标和视觉质量方面都超越了以前的最先进（SOTA）模型，在括号图像恢复和增强挑战赛的第二赛道中获得了第四名。
2. 相关工作 突发图像恢复 突发图像是指在短时间内连续拍摄的一系列图像。在这些图像序列中，可能存在轻微的变化，例如相机移动、物体运动或照明条件的变化。突发图像恢复通常涉及几个主要类别：去噪、去模糊、超分辨率。许多关注去噪的方法已经在文献[16, 18, 19, 33, 35, 43, 44]中广泛研究。在某些方法中，采用了递归全卷积深度神经网络[16]，而其他一些则选择空间变化核估计[33, 35, 43, 44]。值得注意的是，在[18]中，额外利用了偏移估计来解决由于大量物体运动引起的挑战。在[19]中提出了一个两阶段训练方案，顺序对齐在块级别和像素级别，以实现图像帧之间的稳健对齐。一些方法探索了突发图像超分辨率[2, 12, 34, 42]的潜力；[42]和[34]都采用了变换器架构；然而，[42]不同之处在于省略了像素级对齐，选择基于结构几何的简单单应性对齐。[12]的核心概念是生成一系列伪突发特征，无缝地融合所有输入突发帧的互补信息，以实现有效的信息交换。
多帧HDR恢复 多帧HDR恢复涉及从多个低动态范围（LDR）帧创建高动态范围（HDR）图像。在经典的HDR恢复方法中，Debevec等人[9]首先提出了将多个LDR图像合并成单个HDR图像的想法。随后，许多方法采用了将其他帧与参考帧对齐的方法，包括光流、能量优化、秩最小化等。Zhang和Cham[54]使用图像梯度重新校准运动区域权重。Bogoni[4]计算了对齐目的的流矢量。Sen等人[39]采用了基于块的能量最小化方法来优化后续对齐和重建。然而，这些方法在面对前景物体的显著移动或过曝或欠曝区域的过度像素丢失时表现不佳。随着深度学习的发展，深度方法也被应用于多帧HDR融合领域。an等人[45]提出了一种注意力引导的图像融合方法，减少了鬼影伪影的出现。SCTNet[41]利用空间注意力和通道注意力模块，旨在同时利用动态和静态上下文信息以更好地生成图像。然而，这些方法只能处理单个退化图像。
3. 提出的方法 在这项研究中，受到多曝光图像的协作潜力和高频低频信息适用于不同退化类型的启发，我们提出了一种通过高频低频分解合成和增强图像的方法。目标是实现清晰、高动态范围和高分辨率的图像。具体来说，我们的输入包括五张不同曝光的原始图像，记为{R1, R2, R3, R4, R5}，然后进行处理。最初，我们输入的多曝光图像数量为5，我们将曝光时间∆ti捕获的原始图像标记为Yi，其中i ∈ {1, 2, ..., 5}且∆ti < ∆ti+1。随后，遵循多曝光HDR重建方法[20, 45, 47, 49]的指导方针，我们通过连接将伽马变换后的图像Yr与原始图像Yi合并，得到Fi，其中i ∈ {1, 2, ..., 5}。这个过程可以用以下公式表示： Yi = ∑Ri/∆ti/∆t1，Yr = ∑Ri/∆ti/∆t1γ，(1) Fi = Concat(Yi, Yr)，(2) 其中γ代表伽马校正参数，通常设置为1/2.2。最后，我们将这些连接的图像输入HLNet模型。得到的图像记为Ĥ，过程可以表示为： Ĥ = f(F1, F2, F3, F4, F5; θ)，(3) 其中f(·)代表成像函数，θ指的是网络的参数。
3.1 HLNet的概述 我们模型的主要框架如图2所示。首先进行特征对齐，受到TMRNet的启发，使用了共享权重模块和非共享权重模块进行特征提取。最后，进行上采样以获得更大尺寸的图像。在特征对齐阶段，我们选择五张输入图像中的第一张作为
参考帧，并使用光流[3]来扭曲其他帧的特征以与参考帧对齐。然后，我们使用可变形卷积网络（DCN）[8]进一步对齐特征。在特征提取阶段，我们同时使用共享权重模块和非共享权重模块。这是因为在突发和视频恢复任务中，多个输入帧中的一些退化类型通常是相似的。因此，我们在这里使用共享权重模块。共享权重不仅增强了模型的泛化能力，使其能够学习更通用的特征表示，而且还减少了模型的参数数量。相比之下，在TMRNet中，仅使用了常规卷积，没有充分考虑图像细节和上下文信息。因此，我们引入了空间通道增强块（SCEB），采用SCConv同时考虑空间和通道信息，从而有效地捕获图像细节和上下文信息。此外，仅依赖共享权重模块是不够的，因为其他退化是不同的。例如，存在曝光时间和图像模糊的差异。因此，我们引入了高低频分解块（HLFDB）来学习不同退化类型的特殊性。这个块明确地区分了特征的高频和低频信息，并根据它们的特征选择不同的方法进行特征提取。在这个阶段，每个对齐的帧图像Fi，其中i ∈ {1, 2, ..., 5}，依次输入网络。每个帧图像首先通过共享权重模块，然后通过非共享权重模块。同时，随着每个帧图像的输入，我们还输入参考帧Fb(F1)和前一帧通过非共享权重模块的输出。这个过程可以用以下公式表示： Fi+1out = HLFDB(SCEB(Concat(Fi+1, Fb, Fiout))), (4) Fi+1out表示第(i + 1)个非共享权重模块的输出。SCEB(·)代表通过空间通道增强块后的特征图，HLFDB(·)代表通过高低频分解块后的特征图。在最后阶段，获得的特征图被上采样以映射低分辨率图像或特征图到高分辨率。这个过程通过跳跃连接、特征融合和多次上采样操作实现。
3.2 空间通道增强块 在空间通道增强块中，我们使用SCConv[27]，这是一个在卷积操作中整合空间和通道维度的模块，使得更有效地捕获图像细节和上下文信息，从而有助于提取不同退化的共同特征。在我们的模块中，我们在常规卷积和SCConv之间交替，并增加残差连接。这是因为常规卷积专注于捕获局部空间特征，有效地从图像中提取纹理和形状信息。同时，SCConv考虑空间和通道信息之间的关系，使得更全面地理解上下文信息和通道间依赖性。通过两者的交替，我们确保模型不仅提取强大的局部特征，还理解它们在全局上下文中的重要性，从而实现更丰富的特征表示。这个过程可以用以下公式表示： Fout = F + SCConv(Conv(SCConv(Conv(F)))), (5) 其中Fout代表空间通道增强块的输出，Conv(·)表示3×3卷积，SCConv(·)表示空间通道卷积。
3.3 高低频分解块 为了解决图像恢复过程中不同退化特征变化的问题，我们受到ESRT[31]的启发，并认识到高频低频信息适用于不同类型的退化。高频信息通常反映图像中的局部细节，有助于恢复精细的图像细节，这对于去模糊和去噪任务是有益的。同时，低频信息通常代表图像的整体结构，有助于恢复图像背景和轮廓，这对于超分辨率重建和多帧HDR重建任务是有帮助的。因此，我们将图像的高频和低频信息分开，并根据它们的特征选择不同的方法进行特征提取。如图3所示，我们选择使用Avgpooling获取特征的低频信息。然后，通过从整体特征中减去低频信息，我们获得了特征的高频信息。随后，我们采用不同的方法从这两种信息中提取特征。这个过程可以用以下公式表示： Flow = Avgpool(F), (6) F' = Upsampling(Flow), Fhigh = F − F', (7) 其中Avgpool(·)代表平均池化，Upsampling(·)表示双线性插值上采样。Flow代表分离出的低频信息，而Fhigh代表分离出的高频信息。由于高频信息代表图像的细节，我们需要采用较小的接收场以更好地聚焦于局部图像信息以实现更精细的细节恢复。为了处理高频信息，我们提出了局部特征提取块来提取特征，包括多个小卷积核的卷积和密集连接。小卷积核允许更好地聚焦于细节区域，而残差连接则擅长探索高频信息[11, 24]。因此，这种组合对于提取高频信息非常有效。
对于图像的低频信息，它有助于恢复图像背景和轮廓。鉴于背景和轮廓信息在图像中占据了相当大的比例，拥有长距离依赖性对于它们的恢复是有益的。因此，如图4所示，我们引入了全局特征提取块。在这个模块中，我们采用多尺度特征融合来考虑长距离交互，并在特征学习中利用Transformer建立全局上下文关系。受到[52]的启发，这里实现的Transformer架构放弃了空间自注意力，转而使用通道自注意力。这是因为空间自注意力会带来无法接受的计算负担。
此外，尽管多尺度特征提取可以实现长距离依赖性，但在下采样过程中可能会丢失结构信息。受到小波变换能够对图像中的尺度信息进行建模的能力的启发[21]，我们提出了多尺度小波融合块进行多尺度信息融合。离散小波变换将大规模特征信息分离成{HH, HL, LH, LL}。我们首先将原始小尺度信息与LL融合，然后使用逆离散小波变换将合并的信息与{HH, HL, LH}融合。这种方法有助于避免在直接上采样小尺度特征图并与大规模特征图合并时丢失结构信息。总的来说，全局特征提取块对输入特征进行了三次下采样，在不同尺寸的特征图上应用通道自注意力，并最终利用多尺度小波融合块合并不同尺度的特征。
3.4 训练损失 在色调映射图像上训练网络比直接在HDR域中训练更有效，因为HDR图像通常在色调映射后显示。在HDR域中接收到HDR图像H后，我们通过µ-law变换压缩图像的范围。 T(H) = log(1 + µH) / log(1 + µ)，(8) 其中µ表示压缩程度的参数，而T(H)表示色调映射后的图像。在我们的研究中，我们将H的值限制在区间[0, 1]内，并将µ固定在5000。 L1 = ∥T(H) − T(Ĥ)∥1，(9) 其中Ĥ代表我们的HLNet模型推导出的预测结果，而H代表地面真实情况。在这种方法中，我们使用L1损失函数来计算损失。
4. 实验 4.1 实验设置 数据集。我们使用的数据集是来自括号图像恢复和增强挑战赛-第二赛道BracketIRE+任务的训练集。数据是通过张[55]提出的一种模拟过程获得的。数据集包括来自35个场景的1,335个数据对。每个数据对包括两个不同尺寸的输入，×2和×4，我们的任务使用的是×4尺寸。每个输入包括五帧不同曝光的原始图像，尺寸为(4,135,240)。在这个数据集中，来自31个场景的1,045个数据对用于训练，其余来自另外四个场景的290个数据对用于测试。评估指标。我们使用两个客观度量进行定量比较：PSNR-µ，SSIM-µ。这里，µ表示在色调映射域中计算的指标。
实现细节。在训练过程中，多次下采样操作和输入图像的尺寸小可能会影响训练效果。我们将图像裁剪到64×64的尺寸，步长为32，确保多次下采样步骤后的特征尺寸足以进行有效的特征提取。我们使用PyTorch框架，并采用AdamW优化器，其中β1 = 0.9和β2 = 0.999。在单个A100 GPU上使用BracketIRE+任务提供的合成数据集进行训练，总共训练了200个周期，需要6天。
4.2 与最先进方法的比较 为了验证我们模型的优越性，我们将其与三个HDR重建模型、两个超分辨率模型和一个统一图像恢复和增强模型进行了比较。这些模型的任务与我们的任务密切相关。HDR重建模型，AHDRNet[45]、CA-ViT[30]和Kim[23]，使用多个LDR帧重建HDR图像，与我们的任务类似。超分辨率模型，XRestormer[6]和ESRT[31]，目前是表现最好的超分辨率模型之一。统一图像恢复和增强方法的模型，TMRNet[55]，与我们的任务一致。为了消除参数差异的影响，我们将这六种方法的模型参数设置为大致相同。对于三个HDR重建方法，我们只改变了输入图像的数量，模型使用其原始的对齐和特征提取方法，并最终添加上采样以提高图像分辨率。对于两个超分辨率方法，我们只使用了其特征融合阶段的特征融合方法，对齐方法和上采样与我们的模型一致。如表1所示，我们的方法在PSNR-µ方面领先第二名0.55 dB。
总体而言，如图5(a)所示，我们方法恢复的图像在视觉上呈现出最佳效果。在细节恢复方面，我们的模型超越了其他模型，有效地恢复了原始形状，而其他模型则表现出明显的模糊。在图5(b)中，我们的方法在细节恢复方面仍然表现最佳。我们可以观察到我们图像中耳朵区域的丰富细节，而其他方法恢复的耳朵则显得模糊。此外，ESRT的结果值得称赞，这归功于它采用了高频低频分解方法，尽管略逊于我们模型的性能。在图5(c)中，只有我们的方法在棍子的边缘细节上没有表现出模糊，而所有其他方法都表现出模糊。
4.3 消融研究 为了验证我们模型中每个组件的有效性，我们在Track 2 BracketIRE+任务数据集上进行了消融实验。我们设计了四种不同的消融实验来评估不同组件的重要性，包括：(1) 移除空间通道增强块(SCEB)并用简单的残差块替换；(2) 移除高低频分解块(HLFDB)并用简单的残差块替换；(3) 修改高低频分解块中处理高低频信息的方法；(4) 修改分解高低频信息的方法。因此，总共产生了6种不同的模型。模型的具体细节将在下面详细说明，消融实验的结果如表2所示。
模型1：在共享权重模块中，我们用简单的残差块替换了SCEB模块，并将此模型命名为HLNet-NoSCEB。
模型2：在非共享权重模块中，我们用简单的残差块替换了HLFDB模块，并将此模型命名为HLNet-NoHLFDB。
模型3：在HLFDB模块中，处理高低频信息时，我们对两者都使用了局部特征提取块，此模型被命名为HLNet-LL。
模型4：在HLFDB模块中，处理高低频信息时，我们对两者都使用了全局特征提取块，此模型被命名为HLNet-GG。
模型5：在HLFDB模块中，处理高低频信息时，我们使用了ESRT中处理高低频信息的方法来处理特征，此模型被命名为HLNet-ESRT。
模型6：在HLFDB模块中，我们用小波变换方法替换了之前使用平均池化分解高低频信息的方法，此模型被命名为HLNet-Wavelet。
没有空间通道增强块。为了验证空间通道增强块的有效性，我们用常规残差块替换了它。参考表2，我们观察到与我们的模型相比，PSNR-µ指标下降了0.25dB。基于这个结果，我们得出结论，SCConv通过考虑空间和通道信息之间的关系，可以捕获更全面的上下文信息和通道间依赖性。捕获上下文信息和通道依赖性的能力对于提取不同退化的共同特征非常有益。
没有高低频分解块。为了验证高低频分解块的有效性，我们用常规残差块替换了它。参考表2，我们观察到这个模块至关重要，因为移除它导致PSNR-µ指标下降了0.69dB，这是不可接受的。这进一步证实了这个模块的重要性。此外，我们还可以在视觉上感知到这个模块在细节恢复方面的优势。如图6所示，移除高低频分解块显著减少了结果图像中的细节。手部区域有严重的模糊。然而，有了高低频分解块，手部区域得到了很好的恢复。
改变HLFDB模块中处理高低频信息的方法。为了验证在HLFDB模块中使用卷积处理高频信息和使用Transformer处理低频信息的合理性和有效性，我们设计了三组实验：第一组，高频和低频信息都用卷积处理；第二组，高频和低频信息都用Transformer处理；第三组，我们使用了ESRT中处理高低频信息的方法来处理特征。从表2中，我们观察到这三种方法都产生了较差的结果。因此，我们得出结论，根据高低频信息的不同特征用不同的方法处理它们是合理且有效的。
使用小波变换来分解高低频信息。为了验证使用平均池化来分解高低频信息的有效性，我们进行了一个使用小波变换来分解高低频信息的实验。从表2中，我们可以看到，尽管使用小波变换来分解高低频信息的方法不如使用平均池化来分解的表现好。这是因为当选择了不恰当的小波基函数时，小波变换可能会导致图像中重要细节的丢失，影响最终图像质量。
4.4 NTIRE 2024挑战赛括号图像恢复和增强第二赛道BracketIRE+任务的结果 我们参加了NTIRE 2024挑战赛括号图像恢复和增强第二赛道BracketIRE+任务，并获得了第四名。结果如表3所示。我们的PSNR得分比基线模型TMRNet高出0.75dB。
5. 结论 在本文中，我们提出了一种名为HLNet的方法，该方法基于高频低频分解用于括号图像恢复和增强。通常，图像恢复需要低频信息，而图像增强需要高频信息。因此，为了统一解决不同的退化问题，我们提出了一种基于高频低频分解的方法，它可以同时为退化图像提供所需的高频和低频信息。
参考文献 [1] Abdelrahman Abdelhamed, Mahmoud Afifi, Radu Timofte, 和 Michael S Brown. Ntire 2020挑战赛：真实图像去噪：数据集、方法和结果。在IEEE/CVF计算机视觉与模式识别研讨会的会议录中，第496-497页，2020年。
[2] Goutam Bhat, Martin Danelljan, Luc Van Gool, 和 Radu Timofte. 深度突发超分辨率。在IEEE/CVF计算机视觉与模式识别会议录中，第9209-9218页，2021年。
[3] Goutam Bhat, Martin Danelljan, Luc Van Gool, 和 Radu Timofte. 深度突发超分辨率。在IEEE/CVF计算机视觉与模式识别会议录中，第9209-9218页，2021年。
[4] Luca Bogoni. 通过融合扩展单色和彩色图像的动态范围。在第15届国际会议的模式识别会议录中，第7-12页。IEEE，2000年。
[5] Tim Brooks, Ben Mildenhall, Tianfan Xue, Jiawen Chen, Dillon Sharlet, 和 Jonathan T Barron. 为学习原始去噪处理图像。在IEEE/CVF计算机视觉与模式识别会议录中，第11036-11045页，2019年。
[6] Xiangyu Chen, Zheyuan Li, Yuandong Pu, Yihao Liu, Jiantao Zhou, Yu Qiao, 和 Chao Dong. 图像恢复网络的比较研究，用于一般骨干网络设计。arXiv预印本arXiv:2310.11881，2023年。
[7] Sung-Jin Cho, Seo-Won Ji, Jun-Pyo Hong, Seung-Won Jung, 和 Sung-Jea Ko. 在单图像去模糊中重新思考粗到细的方法。在IEEE/CVF国际计算机视觉会议录中，第4641-4650页，2021年。
[8] Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li, Guodong Zhang, Han Hu, 和 Yichen Wei. 可变形卷积网络。在IEEE国际计算机视觉会议录中，第764-773页，2017年。
[9] Paul E Debevec 和 Jitendra Malik. 从照片中恢复高动态范围辐射图。在Seminal Graphics Papers: Pushing the Boundaries, Volume 2中，第643-652页。
[10] Chao Dong, Chen Change Loy, Kaiming He, 和 Xiaoou Tang. 使用深度卷积网络进行图像超分辨率。IEEE模式分析与机器智能会刊，38(2):295-307，2015年。
[11] Jiangxin Dong, Jinshan Pan, Zhongbao Yang, 和 Jinhui Tang. 多尺度残差低通滤波器网络用于图像去模糊。在IEEE/CVF国际计算机视觉会议录中，第12345-12354页，2023年。
[12] Akshay Dudhane, Syed Waqas Zamir, Salman Khan, Fahad Shahbaz Khan, 和 Ming-Hsuan Yang. 突发图像恢复和增强。在IEEE/CVF计算机视觉与模式识别会议录中，第5759-5768页，2022年。
[13] Akshay Dudhane, Syed Waqas Zamir, Salman Khan, Fahad Shahbaz Khan, 和 Ming-Hsuan Yang. 突发图像恢复和增强。在IEEE/CVF计算机视觉与模式识别会议录中，第5759-5768页，2022年。
[14] Akshay Dudhane, Syed Waqas Zamir, Salman Khan, Fahad Shahbaz Khan, 和 Ming-Hsuan Yang. Burstormer:突发图像恢复和增强变换器。在2023 IEEE/CVF计算机视觉与模式识别会议录中，第5703-5712页。IEEE，
2023年。
[15] Gabriel Eilertsen, Joel Kronander, Gyorgy Denes, Rafał K Mantiuk, 和 Jonas Unger. 使用深度CNN从单次曝光重建HDR图像。ACM计算机图形学汇刊(TOG), 36(6):1–15，2017年。
[16] Clément Godard, Kevin Matzen, 和 Matt Uyttendaele. 深度突发去噪，2017年。
[17] Shi Guo, Zifei Yan, Kai Zhang, Wangmeng Zuo, 和 Lei Zhang. 真实照片的卷积盲去噪。在IEEE/CVF计算机视觉与模式识别会议录中，第1712–1722页，2019年。
[18] Shi Guo, Zhetong Liang, 和 Lei Zhang. 联合去噪和去马赛克，具有绿色通道先验，用于现实世界的突发图像。IEEE图像处理会刊，30: 6930–6942，2021年。
[19] Shi Guo, Xi Yang, Jianqi Ma, Gaofeng Ren, 和 Lei Zhang. 用于具有大幅移位的突发图像重建的可微分两阶段对齐方案，2022年。
[20] Tao Hu, Qingsen Yan, Yuankai Qi, 和 Yanning Zhang. 从频率视角生成HDR去鬼影的内容。arXiv预印本arXiv:2404.00849，2024年。
[21] Jun-Jie Huang 和 Pier Luigi Dragotti. Winnet:用于图像去噪的小波启发式可逆网络。IEEE图像处理会刊，31:4377–4392，2022年。
[22] Nima Khademi Kalantari, Ravi Ramamoorthi, 等人. 动态场景的深度高动态范围成像。ACM图形学汇刊，36(4):144–1，2017年。
[23] Jungwoo Kim 和 Min H Kim. 用于单次拍摄HDR成像的时间变化曝光的联合去马赛克和去鬼影。在IEEE/CVF国际计算机视觉会议录中，第12292–12301页，2023年。
[24] Jiwon Kim, Jung Kwon Lee, 和 Kyoung Mu Lee. 使用非常深的卷积网络进行准确图像超分辨率。在IEEE计算机视觉与模式识别会议录中，第1646–1654页，2016年。
[25] Bruno Lecouat, Thomas Eboli, Jean Ponce, 和 Julien Mairal. 从原始图像突发中重建HDR和超分辨率。arXiv预印本arXiv:2207.14671，2022年。
[26] Christian Ledig, Lucas Theis, Ferenc Huszàr, José Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, 等人. 使用生成对抗网络进行逼真的单图像超分辨率。在IEEE计算机视觉与模式识别会议录中，第4681–4690页，2017年。
[27] Jiafeng Li, Ying Wen, 和 Lianghua He. SCConv:用于特征冗余的空间和通道重建卷积。在IEEE/CVF计算机视觉与模式识别会议录中，第6153–6162页，2023年。
[28] Yawei Li, Yulun Zhang, Radu Timofte, Luc Van Gool, Zhijun Tu, Kunpeng Du, Hailing Wang, Hanting Chen, Wei Li, Xiaofei Wang, 等人. Ntire 2023挑战赛：图像去噪：方法和结果。在IEEE/CVF计算机视觉与模式识别会议录中，第1904–1920页，2023年。
[29] Jingyun Liang, Jiezhang Cao, Guolei Sun, Kai Zhang, Luc Van Gool, 和 Radu Timofte. 使用Swin Transformer进行图像恢复。在IEEE/CVF国际计算机视觉会议录中，第1833–1844页，2021年。
[30] Zhen Liu, Yinglong Wang, Bing Zeng, 和 Shuaicheng Liu. 具有上下文感知变换器的无鬼影高动态范围成像。在欧洲计算机视觉会议录中，第344–360页。Springer，2022年。
[31] Zhisheng Lu, Juncheng Li, Hong Liu, Chaoyan Huang, Linlin Zhang, 和 Tieyong Zeng. 用于单图像超分辨率的变换器。在IEEE/CVF计算机视觉与模式识别会议录中，第457–466页，2022年。
[32] Xintian Mao, Yiming Liu, Fengze Liu, Qingli Li, Wei Shen, 和 Yan Wang. 图像去模糊中频率选择的有趣发现。在AAAI人工智能会议录中，第1905–1913页，2023年。
[33] Talmaj Marinc, Vignesh Srinivasan, Serhan Gül, Cornelius Hellge, 和 Wojciech Samek. 用于突发图像去噪的多核预测网络。在2019 IEEE国际图像处理会议录(ICIP)中。IEEE，2019年。
[34] Nancy Mehta, Akshay Dudhane, Subrahmanyam Murala, Syed Waqas Zamir, Salman Khan, 和 Fahad Shahbaz Khan. 自适应特征整合网络，用于突发超分辨率。在IEEE/CVF计算机视觉与模式识别会议录中，第1279–1286页，2022年。
[35] Ben Mildenhall, Jonathan T. Barron, Jiawen Chen, Dillon Sharlet, Ren Ng, 和 Robert Carroll. 使用核预测网络进行突发去噪，2018年。
[36] Seungjun Nah, Tae Hyun Kim, 和 Kyoung Mu Lee. 用于动态场景去模糊的深度多尺度卷积神经网络。在IEEE计算机视觉与模式识别会议录中，第3883–3891页，2017年。
[37] Yuzhen Niu, Jianbin Wu, Wenxi Liu, Wenzhong Guo, 和 Rynson WH Lau. HDR-GAN:从具有大运动的多曝光LDR图像重建HDR图像。IEEE图像处理会刊，30:3885–3896，2021年。
[38] K Ram Prabhakar, Susmit Agrawal, Durgesh Kumar Singh, Balraj Ashwath, 和 R Venkatesh Babu. 实用且高效的高分辨率HDR去鬼影与CNN。在计算机视觉–ECCV 2020:第16届欧洲会议，格拉斯哥，英国，2020年8月23-28日，会议录，第21卷，第16部分，第497–513页。Springer，2020年。
[39] Pradeep Sen, Nima Khademi Kalantari, Maziar Yaesoubi, Soheil Darabi, Dan B Goldman, 和 Eli Shechtman. 鲁棒的基于块的HDR重建动态场景。ACM图形学汇刊，31(6):203–1，2012年。
[40] Xin Tao, Hongyun Gao, Xiaoyong Shen, Jue Wang, 和 Jiaya Jia. 用于深度图像去模糊的尺度循环网络。在IEEE计算机视觉与模式识别会议录中，第8174–8182页，2018年。
[41] Steven Tel, Zongwei Wu, Yulun Zhang, Barthélemy Heyrman, Cédric Demonceaux, Radu Timofte, 和 Dominique Ginhac. 无对齐HDR去鬼影与语义一致的变换器。arXiv预印本arXiv:2305.18135，2023年。
[42] Pengxu Wei, Yujing Sun, Xingbei Guo, Chang Liu, Guanbin Li, Jie Chen, Xiangyang Ji, 和 Liang Lin. 用于现实世界的突发图像超分辨率：基准和方法。在IEEE/CVF国际计算机视觉会议录中，第13233–13242页，2023年。
[43] Zhihao Xia, Federico Perazzi, Michaël Gharbi, Kalyan Sunkavalli, 和 Ayan Chakrabarti. 用于有效突发去噪的基础预测网络，2020年。
[44] Xiangyu Xu, Muchen Li, 和 Wenxiu Sun. 学习变形核用于图像和视频去噪，2019年。
[45] Qingsen Yan, Dong Gong, Qinfeng Shi, Anton van den Hengel, Chunhua Shen, Ian Reid, 和 Yanning Zhang. 注意力引导的网络用于无鬼影高动态范围成像。在IEEE/CVF计算机视觉与模式识别会议录中，第1751–1760页，2019年。
[46] Qingsen Yan, Lei Zhang, Yu Liu, Yu Zhu, Jinqiu Sun, Qinfeng Shi, 和 Yanning Zhang. 通过非局部网络进行深度HDR成像。IEEE图像处理会刊，29: 4308–
4322，2020年。
[47] Qingsen Yan, Dong Gong, Javen Qinfeng Shi, Anton van den Hengel, Chunhua Shen, Ian Reid, 和 Yanning Zhang. 双注意力引导网络用于无鬼影高动态范围成像。国际计算机视觉杂志，第1–19页，2022年。
[48] Qingsen Yan, Weiye Chen, Song Zhang, Yu Zhu, Jinqiu Sun, 和 Yanning Zhang. 统一HDR成像方法与像素和块级。在IEEE/CVF计算机视觉与模式识别会议录中，第22211–22220页，2023年。
[49] Qingsen Yan, Tao Hu, Yuan Sun, Hao Tang, Yu Zhu, Wei Dong, Luc Van Gool, 和 Yanning Zhang. 用条件扩散模型实现高质量HDR去鬼影。IEEE电路与系统视频技术会刊，2023年。
[50] Qingsen Yan, Song Zhang, Weiye Chen, Hao Tang, Yu Zhu, Jinqiu Sun, Luc Van Gool, 和 Yanning Zhang. SMAE:用饱和感知掩模自动编码器进行少次学习HDR去鬼影。在IEEE/CVF计算机视觉与模式识别会议录中，第5775–5784页，2023年。
[51] Syed Waqas Zamir, Aditya Arora, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, Ming-Hsuan Yang, 和 Ling Shao. CycleISP:通过改进的数据合成进行真实图像恢复。在IEEE/CVF计算机视觉与模式识别会议录中，第2696–2705页，2020年。
[52] Syed Waqas Zamir, Aditya Arora, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, 和 Ming-Hsuan Yang. Restormer:用于高分辨率图像恢复的高效变换器。在IEEE/CVF计算机视觉与模式识别会议录中，第5728–5739页，2022年。
[53] Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, 和 Lei Zhang. 超越高斯去噪器：用于图像去噪的深度CNN残差学习。IEEE图像处理会刊，26(7):3142–3155，2017年。
[54] Wei Zhang 和 Wai-Kuen Cham. 梯度导向的多曝光合成。IEEE图像处理会刊，21(4):2318–2323，2011年。
[55] Zhilu Zhang, Shuohao Zhang, Renlong Wu, Zifei Yan, 和 Wangmeng Zuo. 括号是你需要的：用多曝光图像统一图像恢复和增强任务。arXiv预印本arXiv:2401.00766，2024年。
[56] Zhilu Zhang, Shuohao Zhang, Renlong Wu, Wangmeng Zuo, Radu Timofte, 等人. Ntire 2024挑战赛：括号图像恢复和增强：数据集、方法和结果。在IEEE/CVF计算机视觉与模式识别研讨会的会议录中，2024年。
