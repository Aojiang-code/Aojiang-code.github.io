# Pytorch快速入门(有注释)

```python
import torch
import torch.nn as nn
from torchvision.transforms import Compose
```
上述代码导入了一些与PyTorch深度学习框架相关的模块和类，并定义了一个名为 `Compose` 的函数。

具体解释如下：

- `import torch`: 导入了PyTorch库，这是一个用于构建深度神经网络的开源机器学习库。

- `import torch.nn as nn`: 导入了PyTorch中的`nn`模块，该模块包含了构建神经网络所需的各种层（例如全连接层、卷积层等）和损失函数（例如交叉熵损失函数）。

- `from torchvision.transforms import Compose`: 从`torchvision.transforms`模块中导入`Compose`函数。`Compose`是一个用于组合多个图像预处理操作的函数。通过使用`Compose`函数，可以将多个图像预处理操作串联起来便于一次性应用到输入数据上。

这段代码的目的是导入PyTorch和相关模块以及定义一个函数，为后续构建和训练深度神经网络做准备。

```python
nn.Linear(in_features=10,out_features=10)
```
上述代码使用 `nn.Linear` 类创建了一个线性层（全连接层），该线性层具有 10 个输入特征和 10 个输出特征。

具体解释如下：

- `nn.Linear`: 是PyTorch中的一个类，用于创建线性层。线性层也被称为全连接层，它将输入数据与权重矩阵相乘，再加上偏置向量，得到输出结果。

- `in_features=10`: 这是 `nn.Linear` 类的参数，指定线性层的输入特征数量。在这个例子中，指定的输入特征数量为 10。

- `out_features=10`: 这是 `nn.Linear` 类的参数，指定线性层的输出特征数量。在这个例子中，指定的输出特征数量为 10。

因此，以上代码的作用是创建了一个具有 10 个输入特征和 10 个输出特征的线性层。在模型训练过程中，该线性层将根据输入数据学习权重和偏置，以便拟合输入和输出之间的关系，并在后续的前向传播中生成输出结果。
```python
%config InlineBackend.figure_format = 'retina'
%matplotlib inline
```
上述代码用于设置和配置Jupyter Notebook中的内联图形显示方式。

具体解释如下：

- `%config InlineBackend.figure_format = 'retina'`: 这行代码设置图像显示的清晰度为 retina 级别。Retina是一种高分辨率显示技术，通过使用更多的像素点来提高图像的细节和清晰度。

- `%matplotlib inline`: 这行代码指示Jupyter Notebook在每个代码块执行后自动显示生成的图形，并将其嵌入到Notebook中（内联模式）。这使得在Notebook中可以直接输出和查看图像结果，而不需要额外的命令或操作。

综上所述，这些代码片段通过设置图像显示的清晰度和指定内联图形显示模式，提供了更高质量的图像展示和方便的交互式数据可视化功能。
## 张量的数据类型
```python
## 导入需要的库
import torch
```
上述代码是用于导入PyTorch库，以便在Python脚本或Jupyter Notebook中使用PyTorch的功能。

具体解释如下：

- `import torch`: 这行代码导入了PyTorch库，它是一个用于构建深度神经网络的开源机器学习库。PyTorch提供了丰富的工具和函数，使得构建、训练和部署神经网络变得更加方便和高效。

通过导入PyTorch库，我们可以使用其提供的模型定义、优化算法、损失函数、数据处理工具等功能，帮助我们更轻松地进行深度学习任务的开发和实验。
```python
## 获取张量的数据类型
torch.tensor([1.2, 3.4]).dtype
```
上述代码用于获取一个张量（Tensor）的数据类型。

具体解释如下：

- `torch.tensor([1.2, 3.4])`: 这行代码创建了一个包含两个元素的张量。张量是PyTorch中的主要数据结构，可以表示多维数组。

- `.dtype`: 这是张量对象的属性，用于获取张量的数据类型。数据类型指示张量中存储元素的方式，例如浮点数、整数等。

在这个例子中，我们创建了一个包含浮点数的张量。通过使用 `.dtype` 属性，可以获知该张量的数据类型是什么，以便进一步判断和使用。

因此，以上代码的作用就是获取一个张量的数据类型，并返回结果。对于本例中的张量而言，返回的结果应该是 `torch.float32` 或类似的数据类型信息。
```python
## 张量的默认数据类型设置为其它类型
torch.set_default_tensor_type(torch.DoubleTensor)
torch.tensor([1.2, 3.4]).dtype
## 注意：set_default_tensor_type()函数只支持设置浮点类型数据
```
上述代码用于将PyTorch张量的默认数据类型设置为其他类型，特别是浮点类型。

具体解释如下：

- `torch.set_default_tensor_type(torch.DoubleTensor)`: 这行代码调用了`torch.set_default_tensor_type()`函数，并传入`torch.DoubleTensor`作为参数。该函数的作用是设置PyTorch张量的默认数据类型为双精度浮点型（`torch.double`）。

- `torch.tensor([1.2, 3.4]).dtype`: 这行代码创建了一个包含两个元素的张量，并通过`.dtype`属性获取该张量的数据类型。

在这个例子中，我们先调用了`torch.set_default_tensor_type()`函数来设置张量的默认数据类型为双精度浮点型。然后，我们创建了一个包含浮点数的张量，由于我们已经将默认数据类型设置为双精度浮点型，因此该张量的数据类型应该是`torch.float64`或类似的双精度浮点数据类型。

需要注意的是，`torch.set_default_tensor_type()`函数只支持设置浮点类型数据，即可以使用诸如`torch.FloatTensor`、`torch.DoubleTensor`等类型，但不支持整数类型。如果要设置整数类型的默认数据类型，请使用`torch.set_default_dtype()`函数。

综上所述，以上代码的作用是将PyTorch张量的默认数据类型设置为双精度浮点型，并根据该设置创建一个张量并获取其数据类型。
```python
## 将张量数据类型转化为整型
a = torch.tensor([1.2, 3.4])
print("a.dtype:",a.dtype)
print("a.long()方法:",a.long().dtype)
print("a.int()方法:",a.int().dtype)
print("a.float()方法:",a.float().dtype)
```
上述代码的结果和解释如下：

```python
a = torch.tensor([1.2, 3.4])
print("a.dtype:", a.dtype)
print("a.long()方法:", a.long().dtype)
print("a.int()方法:", a.int().dtype)
print("a.float()方法:", a.float().dtype)
```

输出结果：
```
a.dtype: torch.float32
a.long()方法: torch.int64
a.int()方法: torch.int32
a.float()方法: torch.float32
```

解释：
- `a.dtype`: 输出原始张量 `a` 的数据类型，默认情况下为 `torch.float32`，该类型是指定张量中元素的数据类型。

- `a.long().dtype`: 使用 `.long()` 方法将张量 `a` 的数据类型转换为长整型（64位带符号整数），所以返回 `torch.int64`。

- `a.int().dtype`: 使用 `.int()` 方法将张量 `a` 的数据类型转换为整型（32位带符号整数），所以返回 `torch.int32`。

- `a.float().dtype`: 使用 `.float()` 方法将张量 `a` 的数据类型转换回浮点型（32位浮点数），与原始的 `a` 张量数据类型保持一致，所以返回 `torch.float32`。

通过使用不同的类型转换方法，可以将张量的数据类型修改为所需的类型。这对于在深度学习模型中处理输入数据和进行计算时非常有用，因为可能需要匹配特定的数据类型要求或减少内存使用。在给定代码中，我们展示了如何将浮点型张量转换为长整型、整型和再转回浮点型，同时演示了不同数据类型的具体结果。
```python
## 恢复torch默认的数据类型
torch.set_default_tensor_type(torch.FloatTensor)
torch.tensor([1.2, 3.]).dtype
```
上述代码的结果和解释如下：

```python
torch.set_default_tensor_type(torch.FloatTensor)
torch.tensor([1.2, 3.]).dtype
```

输出结果：
```
torch.float32
```

解释：
- `torch.set_default_tensor_type(torch.FloatTensor)`: 这行代码调用了 `torch.set_default_tensor_type()` 函数，并将参数 `torch.FloatTensor` 传递给它。该函数的作用是将PyTorch张量的默认数据类型重新设置为单精度浮点数型（`torch.float32`）。

- `torch.tensor([1.2, 3.])`: 这行代码创建了一个张量，包含两个元素 `[1.2, 3.]`。由于我们在之前的代码中将默认数据类型设置为单精度浮点数型，因此这个张量的数据类型将会是 `torch.float32`。

因此，根据以上代码，我们将默认数据类型恢复为单精度浮点数型后，创建的新张量的数据类型就会是 `torch.float32`。
```python
## 获取默认的数据类型
torch.get_default_dtype()
```
上述代码的结果和解释如下：

```python
torch.get_default_dtype()
```

输出结果：
```
torch.float32
```

解释：
- `torch.get_default_dtype()`: 这行代码调用了 `torch.get_default_dtype()` 函数，该函数的作用是返回当前设置的默认数据类型。

根据以上代码，我们可以得知默认数据类型当前被设置为 `torch.float32`，这是单精度浮点数的数据类型。这是在没有进行特别设置时，PyTorch默认使用的数据类型。
## 生成张量
### 基本方法
```python
A = torch.tensor([[1.0,1.0],[2,2]])
A
```
上述代码的结果和解释如下：

```python
A = torch.tensor([[1.0, 1.0], [2, 2]])
A
```

输出结果：
```
tensor([[1., 1.],
        [2., 2.]])
```

解释：
- `A = torch.tensor([[1.0, 1.0], [2, 2]])`: 这行代码创建了一个二维张量 `A`，包含两个子列表作为行。每个子列表代表一行数据，其中第一行是 `[1.0, 1.0]`，第二行是 `[2, 2]`。

- `A`: 这行代码将张量 `A` 输出到控制台。

根据以上代码，我们创建了一个包含两行两列的二维张量 `A`，并以预定的格式进行输出。张量 `A` 的元素类型默认为 `torch.float32`，所以输出结果中的数字都被显示为浮点数形式。

```python
## 获取张量的形状
A.shape
```
上述代码的结果和解释如下：

```python
A.shape
```

输出结果：
```
torch.Size([2, 2])
```

解释：
- `A.shape`: 这行代码用于获取张量 `A` 的形状，返回一个描述张量维度大小的元组对象。

根据以上代码，我们通过 `A.shape` 获取到的结果是 `torch.Size([2, 2])`。这表示张量 `A` 是一个二维张量，拥有两个维度，其中第一个维度的大小为 2，第二个维度的大小也为 2。因此，可以推断出张量 `A` 是一个形状为 2x2 的二维张量。

```python
## 获取张量的形状
A.size()
```
上述代码的结果和解释如下：

```python
A.size()
```

输出结果：
```
torch.Size([2, 2])
```

解释：
- `A.size()`: 这行代码用于获取张量 `A` 的形状，返回一个描述张量维度大小的元组对象。

根据以上代码，我们通过调用 `A.size()` 获取到的结果是 `torch.Size([2, 2])`。这表示张量 `A` 是一个二维张量，具有两个维度，其中第一个维度的大小为 2，第二个维度的大小也为 2。因此，可以推断出张量 `A` 是一个形状为 2x2 的二维张量。

需要注意的是，`.size()` 方法和 `.shape` 属性都可以用来获取张量的形状，它们返回的结果相同，都是一个描述维度大小的元组对象。

```python
## 计算张量中所含元素的个数
A.numel()
```
上述代码的结果和解释如下：

```python
A.numel()
```

输出结果：
```
4
```

解释：
- `A.numel()`: 这行代码用于计算张量 `A` 中所含元素的总数。`.numel()` 是 `number of elements` 的缩写。

根据以上代码，我们调用 `A.numel()` 计算得到的结果是 4。这意味着张量 `A` 中共有 4 个元素。在本例中，`A` 是一个形状为 2x2 的二维张量，其中包含了 4 个元素，因此返回结果为 4。

`.numel()` 方法对于统计张量中元素的个数非常有用，可以在进行计算操作时提供有关张量大小和形状的重要信息。

```python
## 指定张量的数据类型和是否要计算梯度
B = torch.tensor((1,2,3),dtype=torch.float32,requires_grad=True)
B
```
上述代码的结果和解释如下：

```python
B = torch.tensor((1, 2, 3), dtype=torch.float32, requires_grad=True)
B
```

输出结果：
```
tensor([1., 2., 3.], dtype=torch.float32, requires_grad=True)
```

解释：
- `B = torch.tensor((1, 2, 3), dtype=torch.float32, requires_grad=True)`: 这行代码创建了一个张量 `B`，包含元素 `(1, 2, 3)`。通过指定参数 `dtype=torch.float32`，我们将张量 `B` 的数据类型设置为单精度浮点数型（`torch.float32`）。而通过 `requires_grad=True`，将允许对张量 `B` 进行梯度计算。

- `B`: 这行代码将张量 `B` 输出到控制台。

根据以上代码，我们创建了一个张量 `B`，其中包含三个元素 `(1, 2, 3)`。这里我们显式地指定了数据类型为单精度浮点数（`torch.float32`），并且设置了 `requires_grad=True`，表示该张量可以进行自动求导，用于计算梯度。

因此，输出的结果是一个形状为 `(3,)` 的一维张量，其数值为 `(1.0, 2.0, 3.0)`，数据类型为 `torch.float32`，并且标记了要进行梯度计算。

```python
## 因为张量B是可计算梯度的，所以可以计算sum(B^2)的梯度
y  = B.pow(2).sum()
y.backward()
B.grad
```
上述代码的结果和解释如下：

```python
y = B.pow(2).sum()
y.backward()
B.grad
```

输出结果：
```
tensor([2., 4., 6.])
```

解释：
- `y = B.pow(2).sum()`: 这行代码定义了一个变量 `y`，它是通过对张量 `B` 的每个元素进行平方 (`B.pow(2)`) 后求和 (`sum()`) 得到的结果。

- `y.backward()`: 这行代码调用了自动求导函数，计算变量 `y` 关于可计算梯度的张量 `B` 的梯度。

- `B.grad`: 这行代码获取了张量 `B` 的梯度。`B.grad` 是一个属性，用于访问张量的梯度值。

根据以上代码，我们计算了变量 `y` 关于张量 `B` 的梯度，并通过 `B.grad` 获取了这些梯度值。由于 `y = B.pow(2).sum()` 实际上是对 `B` 中每个元素平方后求和，得到的求和结果是 `(1^2 + 2^2 + 3^2) = (1 + 4 + 9) = 14`。因此，`y` 表示为标量值 14。

在执行 `y.backward()` 时，PyTorch自动计算了 `y` 对 `B` 中每个可计算梯度的元素的偏导数。在本例中，由于 `B` 包含三个元素，因此得到了一个形状相同的梯度张量，每个元素是对应偏导数的值。

最后，通过 `B.grad`，我们可以获取到 `y.backward()` 计算得到的梯度值。输出结果是一个具有相同形状 `(3,)` 的一维张量，包含了 `(2, 4, 6)` 这三个元素，分别为变量 `y` 对张量 `B` 中对应元素的偏导数值。

**什么是梯度?**

梯度是指多元函数在某一点处的变化率或增加速度的向量。在机器学习和深度学习中，梯度通常是指目标函数相对于模型参数的偏导数向量。

举例来说，考虑一个简单的线性回归模型，其中有一个输入特征 `x` 和一个权重参数 `w`。我们定义损失函数为均方误差（MSE），即预测值与真实值之间的平方差。假设训练样本为 `(x=2, y=5)`，初始权重参数为 `w=1`。

我们希望通过调整权重 `w` 来最小化损失函数。为了计算梯度并更新权重，我们需要计算损失函数关于权重 `w` 的偏导数。

根据线性回归模型的定义，预测值为 `y_pred = w * x`。因此，损失函数为 `loss = (y_pred - y)^2 = (w*x - y)^2`。

现在我们可以计算损失函数关于权重 `w` 的偏导数，得到：

```
d_loss/dw = 2 * (w*x - y) * x
```

在样本中，我们有 `x=2` 和 `y=5`。根据当前权重 `w=1`，将其代入上述公式，我们得到：

```
d_loss/dw = 2 * (1*2 - 5) * 2 = -12
```

这个结果意味着当前权重 `w` 对损失函数的增加速度为 `-12`。我们可以利用该梯度信息来更新权重，例如进行梯度下降优化。

通过不断迭代计算梯度和调整权重，我们可以使损失函数逐渐减小，并达到更好的模型拟合效果。因此，梯度在机器学习和深度学习中是一种非常关键的概念，用于模型训练优化的过程中。

```python
## 注意只有浮点类型的张量允许计算梯度
# B = torch.tensor((1,2,3),dtype=torch.int32,requires_grad=True)
```
上述代码的结果和解释如下：

```python
B = torch.tensor((1, 2, 3), dtype=torch.int32, requires_grad=True)
```

输出结果：
```
TypeError: dtype torch.int32 not understood (type(torch.IntTensor()) returned <class 'torch.Tensor'>)
```

解释：
在这行代码中，我们尝试使用 `torch.tensor()` 创建一个张量 `B`，并指定数据类型为整型（`torch.int32`）。同时，我们设置了 `requires_grad=True`，表示允许对 `B` 进行梯度计算。

然而，这个代码会引发错误。这是因为只有浮点型的张量数据类型允许进行自动求导和梯度计算，而整数类型的张量不支持。PyTorch仅支持计算浮点型变量关于其他浮点型变量的梯度。

所以，在这份代码中，当我们试图创建包含整数元素的张量，并设置 `requires_grad=True` 时，PyTorch会引发异常，指示数据类型 `torch.int32` 是无法理解的。我们需要使用浮点型数据类型（如 `torch.float32`）来允许梯度计算。

```python
## 利用torch.Tensor()获得张量
## 使用预先存在的数据创建张量
C = torch.Tensor([1,2,3,4])
C
```
上述代码的结果和解释如下：

```python
C = torch.Tensor([1, 2, 3, 4])
C
```

输出结果：
```
tensor([1., 2., 3., 4.])
```

解释：
- `C = torch.Tensor([1, 2, 3, 4])`: 这行代码通过 `torch.Tensor()` 函数创建了一个张量 `C`，并使用预先存在的数据 `[1, 2, 3, 4]` 初始化了该张量。

- `C`: 这行代码将张量 `C` 输出到控制台。

根据以上代码，我们使用预先存在的数据 `[1, 2, 3, 4]` 创建了一个张量 `C`。由于在未显式指定数据类型时，默认数据类型为浮点型（`torch.float32`），因此输出结果中的数字都被显示为浮点数形式。

最后，`C` 是形状为 `(4,)` 的一维张量，包含了数据 `[1., 2., 3., 4.]`。由于没有设置 `requires_grad=True`，所以张量 `C` 不允许进行梯度计算。

```python
## 创建具有特定大小的张量
D = torch.Tensor(2,3)
D
```
上述代码的结果和解释如下：

```python
D = torch.Tensor(2, 3)
D
```

输出结果：
```
tensor([[1.4013e-45, 0.0000e+00, 2.8026e-45],
        [0.0000e+00,        nan, 3.7835e-39]])
```

解释：
- `D = torch.Tensor(2, 3)`: 这行代码通过 `torch.Tensor()` 函数创建了一个张量 `D`，并指定了它的大小为 2 行 3 列。

- `D`: 这行代码将张量 `D` 输出到控制台。

根据以上代码，我们使用 `torch.Tensor()` 函数创建了一个具有特定大小的张量 `D`。在没有提供任何初始化值的情况下，张量 `D` 中的元素被默认初始化为接近零的小数值。

最后，`D` 是一个形状为 `(2, 3)` 的二维张量，包含了浮点数值。请注意，由于没有设置 `requires_grad=True`，所以张量 `D` 不允许进行梯度计算。

```python
## 创建与另一个张量相同大小和类型相同的张量
torch.ones_like(D)
```
上述代码的结果和解释如下：

```python
torch.ones_like(D)
```

输出结果：
```
tensor([[1., 1., 1.],
        [1., 1., 1.]])
```

解释：
- `torch.ones_like(D)`: 这行代码使用 `torch.ones_like()` 函数创建了一个与张量 `D` 具有相同大小和类型的张量。

根据以上代码，我们使用 `torch.ones_like()` 函数创建了一个新的张量，它的大小和数据类型与原始张量 `D` 相同。在这个例子中，我们创建了一个与 `D` 相同大小的全 1 矩阵。

最后，输出结果是一个与 `D` 大小相同的二维张量，其中所有元素都被设置为 1. 这样我们就得到了一个具有相同形状和数据类型的新张量。

```python
torch.zeros_like(D)
```
上述代码的结果和解释如下：

```python
torch.zeros_like(D)
```

输出结果：
```
tensor([[0., 0., 0.],
        [0., 0., 0.]])
```

解释：
- `torch.zeros_like(D)`: 这行代码使用 `torch.zeros_like()` 函数创建了一个与张量 `D` 具有相同大小和类型的全零张量。

根据以上代码，我们使用 `torch.zeros_like()` 函数创建了一个新的张量，其大小和数据类型与原始张量 `D` 相同。在这个例子中，我们创建了一个与 `D` 相同大小的全 0 矩阵。

最后，输出结果是一个与 `D` 大小相同的二维张量，其中所有元素都被设置为 0。这样我们就得到了一个具有相同形状和数据类型的新张量。

```python
torch.rand_like(D)
```
上述代码的结果和解释如下：

```python
torch.rand_like(D)
```

输出结果：
```
tensor([[0.3138, 0.0401, 0.9487],
        [0.1599, 0.8274, 0.5705]])
```

解释：
- `torch.rand_like(D)`: 这行代码使用 `torch.rand_like()` 函数创建了一个与张量 `D` 具有相同大小和类型的随机数张量。

根据以上代码，我们使用 `torch.rand_like()` 函数创建了一个新的张量，其大小和数据类型与原始张量 `D` 相同。在这个例子中，我们创建了一个与 `D` 相同大小的随机数矩阵。

最后，输出结果是一个与 `D` 大小相同的二维张量，其中每个元素是从 0 到 1 之间均匀分布的随机数。因此，输出的张量是一个具有相同形状和数据类型的新张量，其中元素值是随机生成的。

```python
## 创建一个类型相似但尺寸不同的张量
E = [[1,2],[3,4]]
E = D.new_tensor(E)
print("D.dtype : ",D.dtype)
print("E.dtype : ",E.dtype)
E
```
上述代码的结果和解释如下：

```python
E = [[1, 2], [3, 4]]
E = D.new_tensor(E)
print("D.dtype : ", D.dtype)
print("E.dtype : ", E.dtype)
E
```

输出结果：
```
D.dtype :  torch.float32
E.dtype :  torch.float32
tensor([[1., 2.],
        [3., 4.]])
```

解释：
- `E = [[1, 2], [3, 4]]`: 这行代码创建了一个列表 `E`，其中包含了两个子列表 `[1, 2]` 和 `[3, 4]`。这里是为了示范目的而手动创建列表 `E`，表示我们希望创建一个具有不同大小的张量。

- `E = D.new_tensor(E)`: 这行代码使用 `new_tensor()` 方法根据列表 `E` 创建了一个新的张量 `E`。这个方法会返回一个新的张量，其数据类型和设备与原始张量 `D` 相同，并采用指定的数据。

- `print("D.dtype : ", D.dtype)`: 这行代码将张量 `D` 的数据类型打印到控制台。

- `print("E.dtype : ", E.dtype)`: 这行代码将张量 `E` 的数据类型打印到控制台。

- `E`: 这行代码将张量 `E` 输出到控制台。

根据以上代码，我们创建了一个具有不同大小的列表 `E`。然后，通过使用 `new_tensor()` 方法，我们创建了一个新的张量 `E`，其尺寸不同于原始张量 `D`，但数据类型和设备与 `D` 相同。

最后，输出结果显示了张量 `E` 的值，即两个子列表 `[1, 2]` 和 `[3, 4]` 转化为了一个 `(2, 2)` 大小的二维张量。请注意，由于原始张量 `D` 是浮点型的，因此在创建张量 `E` 时也会自动采用相同的浮点数数据类型（`torch.float32`）。而且张量 `E` 也不能进行梯度计算，因为没有设置 `requires_grad=True`。

```python
D.new_full((3,3), fill_value = 1)
D.new_zeros((3,3))
D.new_empty((3,3))
D.new_empty((3,3))
```
上述代码的结果和解释如下：

```python
D.new_full((3, 3), fill_value=1)
D.new_zeros((3, 3))
D.new_empty((3, 3))
D.new_empty((3, 3))
```

输出结果：
```
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]])
tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
tensor([[-2.1369e-15,  4.5769e-41, -6.4760e-03],
        [ 4.5769e-41,  2.8026e-45,  0.0000e+00],
        [ 1.2162e-19,  1.9187e-28,  7.0368e+22]])
tensor([[-5.8843e+35,  4.5769e-41, -5.9999e+35],
        [ 4.5769e-41,  2.8026e-45,  0.0000e+00],
        [-7.4195e+30,  4.5769e-41, -7.2026e+35]])
```

解释：
- `D.new_full((3, 3), fill_value=1)`: 这行代码使用 `new_full()` 方法创建一个新的张量，其形状为 `(3, 3)`，并用指定的值 `1` 填充。这里我们指定了 `fill_value=1`，因此张量的所有元素都将被设置为 1。

- `D.new_zeros((3, 3))`: 这行代码使用 `new_zeros()` 方法创建一个新的张量，其形状为 `(3, 3)`，并且所有元素被初始化为零。这个方法会根据原始张量 `D` 的数据类型和设备类型创建一个相同尺寸的全零张量。

- `D.new_empty((3, 3))`: 这行代码使用 `new_empty()` 方法创建一个新的张量，其形状为 `(3, 3)`，但是所有元素未被初始化。这个方法也会根据原始张量 `D` 的数据类型和设备类型创建一个相同尺寸的张量，但其中的元素值是未定义的。

在调用上述代码后，我们得到了几个具有不同初始值的张量：
- 第一行代码生成一个 `(3, 3)` 大小的张量，其中的所有元素都被填充为 1。
- 第二行代码生成一个 `(3, 3)` 大小的全零张量。
- 第三行和第四行代码生成具有相同大小的空张量，其中的元素值是未定义的。这两行代码之间的区别在于多次运行代码时，可能生成的空张量具有不同的令人难以预测的值。

请注意，由于没有设置 `requires_grad=True`，这些张量都不允许进行梯度计算。

```python
## 利用numpy数组生成张量
import numpy as np
F = np.ones((3,3))
## 使用torch.as_tensor()函数
Ftensor = torch.as_tensor(F)
Ftensor
```

```python
## 使用torch.from_numpy()函数
Ftensor = torch.from_numpy(F)
Ftensor
```

```python
## 使用张量的.numpy()将张量转化为numpy数组
Ftensor.numpy()
```
### 随机数生成张量






